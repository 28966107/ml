2023-10-11 22:27:09,055 - __main__ - INFO - 4 GPUs will be used for training...
2023-10-11 22:28:14,043 - __main__ - INFO - Epoch [1/64], Step [1/2503], training loss: 7.1164703369140625, training accuracy: 0.0
2023-10-11 22:30:22,278 - __main__ - INFO - Epoch [1/64], Step [101/2503], training loss: 6.868398666381836, training accuracy: 0.00146484375
2023-10-11 22:33:19,560 - __main__ - INFO - Epoch [1/64], Step [201/2503], training loss: 6.759902000427246, training accuracy: 0.00349609375
2023-10-11 22:36:04,661 - __main__ - INFO - Epoch [1/64], Step [301/2503], training loss: 6.674746513366699, training accuracy: 0.004921875
2023-10-11 22:38:46,814 - __main__ - INFO - Epoch [1/64], Step [401/2503], training loss: 6.564925193786621, training accuracy: 0.00654296875
2023-10-11 22:41:38,443 - __main__ - INFO - Epoch [1/64], Step [501/2503], training loss: 6.53428316116333, training accuracy: 0.00822265625
2023-10-11 22:44:06,312 - __main__ - INFO - Epoch [1/64], Step [601/2503], training loss: 6.379446029663086, training accuracy: 0.00978515625
2023-10-11 22:46:31,654 - __main__ - INFO - Epoch [1/64], Step [701/2503], training loss: 6.245667457580566, training accuracy: 0.01255859375
2023-10-11 22:49:01,147 - __main__ - INFO - Epoch [1/64], Step [801/2503], training loss: 6.140166282653809, training accuracy: 0.01626953125
2023-10-11 22:51:35,153 - __main__ - INFO - Epoch [1/64], Step [901/2503], training loss: 6.117771148681641, training accuracy: 0.0195703125
2023-10-11 22:54:02,237 - __main__ - INFO - Epoch [1/64], Step [1001/2503], training loss: 5.809872150421143, training accuracy: 0.02447265625
2023-10-11 22:56:02,775 - __main__ - INFO - Epoch [1/64], Step [1101/2503], training loss: 5.909078121185303, training accuracy: 0.02890625
2023-10-11 22:58:20,984 - __main__ - INFO - Epoch [1/64], Step [1201/2503], training loss: 5.7587785720825195, training accuracy: 0.0323046875
2023-10-11 23:00:52,249 - __main__ - INFO - Epoch [1/64], Step [1301/2503], training loss: 5.607483863830566, training accuracy: 0.0385546875
2023-10-11 23:02:49,022 - __main__ - INFO - Epoch [1/64], Step [1401/2503], training loss: 5.598186492919922, training accuracy: 0.04375
2023-10-11 23:04:45,267 - __main__ - INFO - Epoch [1/64], Step [1501/2503], training loss: 5.514944076538086, training accuracy: 0.0473828125
2023-10-11 23:06:47,135 - __main__ - INFO - Epoch [1/64], Step [1601/2503], training loss: 5.568201065063477, training accuracy: 0.0530859375
2023-10-11 23:08:52,956 - __main__ - INFO - Epoch [1/64], Step [1701/2503], training loss: 5.510697364807129, training accuracy: 0.059375
2023-10-11 23:10:50,335 - __main__ - INFO - Epoch [1/64], Step [1801/2503], training loss: 5.407047271728516, training accuracy: 0.06384765625
2023-10-11 23:12:48,697 - __main__ - INFO - Epoch [1/64], Step [1901/2503], training loss: 5.256302833557129, training accuracy: 0.06955078125
2023-10-11 23:14:42,868 - __main__ - INFO - Epoch [1/64], Step [2001/2503], training loss: 5.225191116333008, training accuracy: 0.07474609375
2023-10-11 23:16:46,626 - __main__ - INFO - Epoch [1/64], Step [2101/2503], training loss: 5.162075042724609, training accuracy: 0.08296875
2023-10-11 23:18:35,753 - __main__ - INFO - Epoch [1/64], Step [2201/2503], training loss: 5.078105926513672, training accuracy: 0.08650390625
2023-10-11 23:20:30,643 - __main__ - INFO - Epoch [1/64], Step [2301/2503], training loss: 5.0878448486328125, training accuracy: 0.09375
2023-10-11 23:22:27,621 - __main__ - INFO - Epoch [1/64], Step [2401/2503], training loss: 4.87368631362915, training accuracy: 0.1008203125
2023-10-11 23:24:27,977 - __main__ - INFO - Epoch [1/64], Step [2501/2503], training loss: 4.898394584655762, training accuracy: 0.10873046875
2023-10-11 23:30:36,955 - __main__ - INFO - Epoch [2/64], accuracy: 0.1199
2023-10-11 23:30:58,892 - __main__ - INFO - Epoch [2/64], Step [1/2503], training loss: 4.935556411743164, training accuracy: 0.12253641816623821
2023-10-11 23:32:43,517 - __main__ - INFO - Epoch [2/64], Step [101/2503], training loss: 5.093407154083252, training accuracy: 0.11302734375
2023-10-11 23:34:27,304 - __main__ - INFO - Epoch [2/64], Step [201/2503], training loss: 4.8007121086120605, training accuracy: 0.121015625
2023-10-11 23:36:18,137 - __main__ - INFO - Epoch [2/64], Step [301/2503], training loss: 4.7183427810668945, training accuracy: 0.12861328125
2023-10-11 23:38:18,326 - __main__ - INFO - Epoch [2/64], Step [401/2503], training loss: 4.6395416259765625, training accuracy: 0.13494140625
2023-10-11 23:40:20,578 - __main__ - INFO - Epoch [2/64], Step [501/2503], training loss: 4.5673723220825195, training accuracy: 0.14248046875
2023-10-11 23:42:49,990 - __main__ - INFO - Epoch [2/64], Step [601/2503], training loss: 4.546652317047119, training accuracy: 0.1515234375
2023-10-11 23:45:17,011 - __main__ - INFO - Epoch [2/64], Step [701/2503], training loss: 4.34761381149292, training accuracy: 0.1565234375
2023-10-11 23:47:43,966 - __main__ - INFO - Epoch [2/64], Step [801/2503], training loss: 4.493514537811279, training accuracy: 0.16123046875
2023-10-11 23:50:21,374 - __main__ - INFO - Epoch [2/64], Step [901/2503], training loss: 4.22089147567749, training accuracy: 0.16630859375
2023-10-11 23:52:51,054 - __main__ - INFO - Epoch [2/64], Step [1001/2503], training loss: 4.376382350921631, training accuracy: 0.1761328125
2023-10-11 23:55:33,244 - __main__ - INFO - Epoch [2/64], Step [1101/2503], training loss: 4.438045501708984, training accuracy: 0.18357421875
2023-10-11 23:58:16,506 - __main__ - INFO - Epoch [2/64], Step [1201/2503], training loss: 4.190696716308594, training accuracy: 0.18658203125
2023-10-12 00:00:57,258 - __main__ - INFO - Epoch [2/64], Step [1301/2503], training loss: 4.216249465942383, training accuracy: 0.19396484375
2023-10-12 00:03:19,217 - __main__ - INFO - Epoch [2/64], Step [1401/2503], training loss: 4.18194055557251, training accuracy: 0.198671875
2023-10-12 00:05:41,081 - __main__ - INFO - Epoch [2/64], Step [1501/2503], training loss: 4.098440170288086, training accuracy: 0.20599609375
2023-10-12 00:08:03,053 - __main__ - INFO - Epoch [2/64], Step [1601/2503], training loss: 4.116067409515381, training accuracy: 0.209296875
2023-10-12 00:10:29,733 - __main__ - INFO - Epoch [2/64], Step [1701/2503], training loss: 3.7599129676818848, training accuracy: 0.2171484375
2023-10-12 00:12:50,913 - __main__ - INFO - Epoch [2/64], Step [1801/2503], training loss: 4.0415425300598145, training accuracy: 0.221171875
2023-10-12 00:15:18,105 - __main__ - INFO - Epoch [2/64], Step [1901/2503], training loss: 3.899421453475952, training accuracy: 0.2283984375
2023-10-12 00:18:01,023 - __main__ - INFO - Epoch [2/64], Step [2001/2503], training loss: 3.812819480895996, training accuracy: 0.2315625
2023-10-12 00:21:07,282 - __main__ - INFO - Epoch [2/64], Step [2101/2503], training loss: 4.028171539306641, training accuracy: 0.2365234375
2023-10-12 00:24:09,849 - __main__ - INFO - Epoch [2/64], Step [2201/2503], training loss: 3.803436517715454, training accuracy: 0.24318359375
2023-10-12 00:27:19,834 - __main__ - INFO - Epoch [2/64], Step [2301/2503], training loss: 3.7066099643707275, training accuracy: 0.2501953125
2023-10-12 00:30:34,007 - __main__ - INFO - Epoch [2/64], Step [2401/2503], training loss: 3.839407205581665, training accuracy: 0.25458984375
2023-10-12 00:33:45,818 - __main__ - INFO - Epoch [2/64], Step [2501/2503], training loss: 3.641789436340332, training accuracy: 0.26185546875
2023-10-12 00:38:39,767 - __main__ - INFO - Epoch [3/64], accuracy: 0.28056
2023-10-12 00:39:09,124 - __main__ - INFO - Epoch [3/64], Step [1/2503], training loss: 3.606436252593994, training accuracy: 0.25535561268209084
2023-10-12 00:42:09,086 - __main__ - INFO - Epoch [3/64], Step [101/2503], training loss: 3.6369125843048096, training accuracy: 0.2646484375
2023-10-12 00:45:19,873 - __main__ - INFO - Epoch [3/64], Step [201/2503], training loss: 3.537200927734375, training accuracy: 0.2708984375
2023-10-12 00:48:36,028 - __main__ - INFO - Epoch [3/64], Step [301/2503], training loss: 3.4723963737487793, training accuracy: 0.264375
2023-10-12 00:51:56,045 - __main__ - INFO - Epoch [3/64], Step [401/2503], training loss: 3.5270144939422607, training accuracy: 0.27896484375
2023-10-12 00:55:41,085 - __main__ - INFO - Epoch [3/64], Step [501/2503], training loss: 3.7024734020233154, training accuracy: 0.278359375
2023-10-12 00:58:56,440 - __main__ - INFO - Epoch [3/64], Step [601/2503], training loss: 3.542861223220825, training accuracy: 0.28544921875
2023-10-12 01:02:34,990 - __main__ - INFO - Epoch [3/64], Step [701/2503], training loss: 3.4898416996002197, training accuracy: 0.287890625
2023-10-12 01:06:11,446 - __main__ - INFO - Epoch [3/64], Step [801/2503], training loss: 3.7342445850372314, training accuracy: 0.29541015625
2023-10-12 01:10:07,637 - __main__ - INFO - Epoch [3/64], Step [901/2503], training loss: 3.379462718963623, training accuracy: 0.30029296875
2023-10-12 01:13:41,897 - __main__ - INFO - Epoch [3/64], Step [1001/2503], training loss: 3.4029762744903564, training accuracy: 0.3007421875
2023-10-12 01:17:13,054 - __main__ - INFO - Epoch [3/64], Step [1101/2503], training loss: 3.4572348594665527, training accuracy: 0.3003125
2023-10-12 01:20:43,187 - __main__ - INFO - Epoch [3/64], Step [1201/2503], training loss: 3.434722423553467, training accuracy: 0.30810546875
2023-10-12 01:24:20,280 - __main__ - INFO - Epoch [3/64], Step [1301/2503], training loss: 3.4511725902557373, training accuracy: 0.30994140625
2023-10-12 01:27:19,849 - __main__ - INFO - Epoch [3/64], Step [1401/2503], training loss: 3.231797218322754, training accuracy: 0.31259765625
2023-10-12 01:30:13,295 - __main__ - INFO - Epoch [3/64], Step [1501/2503], training loss: 3.3228540420532227, training accuracy: 0.31466796875
2023-10-12 01:32:52,094 - __main__ - INFO - Epoch [3/64], Step [1601/2503], training loss: 3.3245561122894287, training accuracy: 0.316875
2023-10-12 01:35:38,492 - __main__ - INFO - Epoch [3/64], Step [1701/2503], training loss: 3.4398880004882812, training accuracy: 0.32443359375
2023-10-12 01:38:09,959 - __main__ - INFO - Epoch [3/64], Step [1801/2503], training loss: 3.272745370864868, training accuracy: 0.3234375
2023-10-12 01:40:36,404 - __main__ - INFO - Epoch [3/64], Step [1901/2503], training loss: 3.2452118396759033, training accuracy: 0.32759765625
2023-10-12 01:43:04,532 - __main__ - INFO - Epoch [3/64], Step [2001/2503], training loss: 3.420391321182251, training accuracy: 0.33291015625
2023-10-12 01:45:37,659 - __main__ - INFO - Epoch [3/64], Step [2101/2503], training loss: 3.14640474319458, training accuracy: 0.33052734375
2023-10-12 01:48:01,330 - __main__ - INFO - Epoch [3/64], Step [2201/2503], training loss: 3.1972782611846924, training accuracy: 0.338984375
2023-10-12 01:50:30,091 - __main__ - INFO - Epoch [3/64], Step [2301/2503], training loss: 3.455219030380249, training accuracy: 0.3423828125
2023-10-12 01:52:55,712 - __main__ - INFO - Epoch [3/64], Step [2401/2503], training loss: 3.217473268508911, training accuracy: 0.34103515625
2023-10-12 01:55:06,393 - __main__ - INFO - Epoch [3/64], Step [2501/2503], training loss: 3.0757508277893066, training accuracy: 0.345625
2023-10-12 01:59:39,666 - __main__ - INFO - Epoch [4/64], accuracy: 0.35534
2023-10-12 02:00:01,876 - __main__ - INFO - Epoch [4/64], Step [1/2503], training loss: 3.2604424953460693, training accuracy: 0.35904027420736934
2023-10-12 02:01:43,383 - __main__ - INFO - Epoch [4/64], Step [101/2503], training loss: 3.0936501026153564, training accuracy: 0.3587109375
2023-10-12 02:04:03,089 - __main__ - INFO - Epoch [4/64], Step [201/2503], training loss: 3.0179316997528076, training accuracy: 0.3573046875
2023-10-12 02:06:23,472 - __main__ - INFO - Epoch [4/64], Step [301/2503], training loss: 2.8963186740875244, training accuracy: 0.360078125
2023-10-12 02:08:47,024 - __main__ - INFO - Epoch [4/64], Step [401/2503], training loss: 2.982884168624878, training accuracy: 0.3608984375
2023-10-12 02:11:06,769 - __main__ - INFO - Epoch [4/64], Step [501/2503], training loss: 2.9136290550231934, training accuracy: 0.36568359375
2023-10-12 02:13:34,580 - __main__ - INFO - Epoch [4/64], Step [601/2503], training loss: 2.83026123046875, training accuracy: 0.36140625
2023-10-12 02:15:55,412 - __main__ - INFO - Epoch [4/64], Step [701/2503], training loss: 3.0688364505767822, training accuracy: 0.36388671875
2023-10-12 02:18:25,694 - __main__ - INFO - Epoch [4/64], Step [801/2503], training loss: 2.9178171157836914, training accuracy: 0.37134765625
2023-10-12 02:20:44,988 - __main__ - INFO - Epoch [4/64], Step [901/2503], training loss: 2.9691336154937744, training accuracy: 0.36775390625
2023-10-12 02:23:13,359 - __main__ - INFO - Epoch [4/64], Step [1001/2503], training loss: 3.064462423324585, training accuracy: 0.375078125
2023-10-12 02:25:39,199 - __main__ - INFO - Epoch [4/64], Step [1101/2503], training loss: 2.990852117538452, training accuracy: 0.37546875
2023-10-12 02:28:05,313 - __main__ - INFO - Epoch [4/64], Step [1201/2503], training loss: 2.829204797744751, training accuracy: 0.37669921875
2023-10-12 02:30:37,168 - __main__ - INFO - Epoch [4/64], Step [1301/2503], training loss: 2.9438157081604004, training accuracy: 0.37080078125
2023-10-12 02:33:04,543 - __main__ - INFO - Epoch [4/64], Step [1401/2503], training loss: 2.927563428878784, training accuracy: 0.37697265625
2023-10-12 02:35:32,387 - __main__ - INFO - Epoch [4/64], Step [1501/2503], training loss: 2.7652883529663086, training accuracy: 0.38275390625
2023-10-12 02:37:55,871 - __main__ - INFO - Epoch [4/64], Step [1601/2503], training loss: 2.874591827392578, training accuracy: 0.3815625
2023-10-12 02:40:26,878 - __main__ - INFO - Epoch [4/64], Step [1701/2503], training loss: 2.8425979614257812, training accuracy: 0.38572265625
2023-10-12 02:42:58,906 - __main__ - INFO - Epoch [4/64], Step [1801/2503], training loss: 2.7967417240142822, training accuracy: 0.38388671875
2023-10-12 02:45:25,290 - __main__ - INFO - Epoch [4/64], Step [1901/2503], training loss: 3.093637704849243, training accuracy: 0.389296875
2023-10-12 02:47:52,207 - __main__ - INFO - Epoch [4/64], Step [2001/2503], training loss: 2.826663017272949, training accuracy: 0.3881640625
2023-10-12 02:50:16,932 - __main__ - INFO - Epoch [4/64], Step [2101/2503], training loss: 2.677776336669922, training accuracy: 0.3948046875
2023-10-12 02:52:52,190 - __main__ - INFO - Epoch [4/64], Step [2201/2503], training loss: 2.9505512714385986, training accuracy: 0.3965625
2023-10-12 02:55:17,748 - __main__ - INFO - Epoch [4/64], Step [2301/2503], training loss: 2.900303363800049, training accuracy: 0.39884765625
2023-10-12 02:57:42,935 - __main__ - INFO - Epoch [4/64], Step [2401/2503], training loss: 2.7719790935516357, training accuracy: 0.401328125
2023-10-12 02:59:52,471 - __main__ - INFO - Epoch [4/64], Step [2501/2503], training loss: 2.6767444610595703, training accuracy: 0.39982421875
2023-10-12 03:03:48,419 - __main__ - INFO - Epoch [5/64], accuracy: 0.41448
2023-10-12 03:04:08,116 - __main__ - INFO - Epoch [5/64], Step [1/2503], training loss: 2.6052348613739014, training accuracy: 0.42930591259640105
2023-10-12 03:05:55,207 - __main__ - INFO - Epoch [5/64], Step [101/2503], training loss: 3.054612398147583, training accuracy: 0.409609375
2023-10-12 03:08:21,515 - __main__ - INFO - Epoch [5/64], Step [201/2503], training loss: 2.743328809738159, training accuracy: 0.41185546875
2023-10-12 03:10:48,760 - __main__ - INFO - Epoch [5/64], Step [301/2503], training loss: 2.6521527767181396, training accuracy: 0.41044921875
2023-10-12 03:13:07,446 - __main__ - INFO - Epoch [5/64], Step [401/2503], training loss: 2.7454450130462646, training accuracy: 0.4123046875
2023-10-12 03:15:36,187 - __main__ - INFO - Epoch [5/64], Step [501/2503], training loss: 2.7799010276794434, training accuracy: 0.40779296875
2023-10-12 03:17:54,448 - __main__ - INFO - Epoch [5/64], Step [601/2503], training loss: 2.706324577331543, training accuracy: 0.42087890625
2023-10-12 03:20:09,985 - __main__ - INFO - Epoch [5/64], Step [701/2503], training loss: 2.71079683303833, training accuracy: 0.41568359375
2023-10-12 03:22:28,867 - __main__ - INFO - Epoch [5/64], Step [801/2503], training loss: 2.7525222301483154, training accuracy: 0.4148828125
2023-10-12 03:24:53,892 - __main__ - INFO - Epoch [5/64], Step [901/2503], training loss: 2.7342095375061035, training accuracy: 0.423984375
2023-10-12 03:27:11,264 - __main__ - INFO - Epoch [5/64], Step [1001/2503], training loss: 2.5556678771972656, training accuracy: 0.423984375
2023-10-12 03:29:31,248 - __main__ - INFO - Epoch [5/64], Step [1101/2503], training loss: 2.649087905883789, training accuracy: 0.41501953125
2023-10-12 03:31:52,258 - __main__ - INFO - Epoch [5/64], Step [1201/2503], training loss: 2.707188129425049, training accuracy: 0.4174609375
2023-10-12 03:34:18,205 - __main__ - INFO - Epoch [5/64], Step [1301/2503], training loss: 2.6825778484344482, training accuracy: 0.4242578125
2023-10-12 03:36:45,246 - __main__ - INFO - Epoch [5/64], Step [1401/2503], training loss: 2.6730945110321045, training accuracy: 0.421796875
2023-10-12 03:39:11,083 - __main__ - INFO - Epoch [5/64], Step [1501/2503], training loss: 2.649643898010254, training accuracy: 0.4278515625
2023-10-12 03:41:37,483 - __main__ - INFO - Epoch [5/64], Step [1601/2503], training loss: 2.6211326122283936, training accuracy: 0.42841796875
2023-10-12 03:44:14,772 - __main__ - INFO - Epoch [5/64], Step [1701/2503], training loss: 2.5291755199432373, training accuracy: 0.4306640625
2023-10-12 03:46:44,338 - __main__ - INFO - Epoch [5/64], Step [1801/2503], training loss: 2.7076528072357178, training accuracy: 0.4306640625
2023-10-12 03:49:14,665 - __main__ - INFO - Epoch [5/64], Step [1901/2503], training loss: 2.5729000568389893, training accuracy: 0.43271484375
2023-10-12 03:51:43,163 - __main__ - INFO - Epoch [5/64], Step [2001/2503], training loss: 2.6506385803222656, training accuracy: 0.4320703125
2023-10-12 03:54:22,125 - __main__ - INFO - Epoch [5/64], Step [2101/2503], training loss: 2.6529083251953125, training accuracy: 0.43255859375
2023-10-12 03:56:44,292 - __main__ - INFO - Epoch [5/64], Step [2201/2503], training loss: 2.571085214614868, training accuracy: 0.43365234375
2023-10-12 03:59:15,247 - __main__ - INFO - Epoch [5/64], Step [2301/2503], training loss: 2.596219778060913, training accuracy: 0.43546875
2023-10-12 04:01:49,433 - __main__ - INFO - Epoch [5/64], Step [2401/2503], training loss: 2.6369524002075195, training accuracy: 0.434375
2023-10-12 04:04:15,451 - __main__ - INFO - Epoch [5/64], Step [2501/2503], training loss: 2.761239767074585, training accuracy: 0.4401953125
2023-10-12 04:07:47,045 - __main__ - INFO - Epoch [6/64], accuracy: 0.47486
2023-10-12 04:08:09,116 - __main__ - INFO - Epoch [6/64], Step [1/2503], training loss: 2.472102403640747, training accuracy: 0.442159383033419
2023-10-12 04:09:53,735 - __main__ - INFO - Epoch [6/64], Step [101/2503], training loss: 2.4992287158966064, training accuracy: 0.44900390625
2023-10-12 04:12:18,887 - __main__ - INFO - Epoch [6/64], Step [201/2503], training loss: 2.5477545261383057, training accuracy: 0.44642578125
2023-10-12 04:14:46,969 - __main__ - INFO - Epoch [6/64], Step [301/2503], training loss: 2.33608341217041, training accuracy: 0.45302734375
2023-10-12 04:17:22,786 - __main__ - INFO - Epoch [6/64], Step [401/2503], training loss: 2.37192440032959, training accuracy: 0.44740234375
2023-10-12 04:19:44,182 - __main__ - INFO - Epoch [6/64], Step [501/2503], training loss: 2.5671541690826416, training accuracy: 0.448046875
2023-10-12 04:22:09,219 - __main__ - INFO - Epoch [6/64], Step [601/2503], training loss: 2.489447832107544, training accuracy: 0.44671875
2023-10-12 04:24:28,312 - __main__ - INFO - Epoch [6/64], Step [701/2503], training loss: 2.5481441020965576, training accuracy: 0.45134765625
2023-10-12 04:26:57,368 - __main__ - INFO - Epoch [6/64], Step [801/2503], training loss: 2.4378724098205566, training accuracy: 0.45306640625
2023-10-12 04:29:24,463 - __main__ - INFO - Epoch [6/64], Step [901/2503], training loss: 2.4250903129577637, training accuracy: 0.45732421875
2023-10-12 04:31:48,287 - __main__ - INFO - Epoch [6/64], Step [1001/2503], training loss: 2.5936942100524902, training accuracy: 0.4558203125
2023-10-12 04:34:09,893 - __main__ - INFO - Epoch [6/64], Step [1101/2503], training loss: 2.6540422439575195, training accuracy: 0.45671875
2023-10-12 04:36:32,181 - __main__ - INFO - Epoch [6/64], Step [1201/2503], training loss: 2.4759321212768555, training accuracy: 0.45490234375
2023-10-12 04:38:54,995 - __main__ - INFO - Epoch [6/64], Step [1301/2503], training loss: 2.410676956176758, training accuracy: 0.4549609375
2023-10-12 04:41:17,906 - __main__ - INFO - Epoch [6/64], Step [1401/2503], training loss: 2.7202091217041016, training accuracy: 0.450390625
2023-10-12 04:43:36,293 - __main__ - INFO - Epoch [6/64], Step [1501/2503], training loss: 2.5240707397460938, training accuracy: 0.451015625
2023-10-12 04:46:07,059 - __main__ - INFO - Epoch [6/64], Step [1601/2503], training loss: 2.5327510833740234, training accuracy: 0.45720703125
2023-10-12 04:48:28,233 - __main__ - INFO - Epoch [6/64], Step [1701/2503], training loss: 2.529958724975586, training accuracy: 0.4606640625
2023-10-12 04:50:50,960 - __main__ - INFO - Epoch [6/64], Step [1801/2503], training loss: 2.4218544960021973, training accuracy: 0.4596875
2023-10-12 04:53:17,351 - __main__ - INFO - Epoch [6/64], Step [1901/2503], training loss: 2.334686279296875, training accuracy: 0.46099609375
2023-10-12 04:55:46,997 - __main__ - INFO - Epoch [6/64], Step [2001/2503], training loss: 2.5482592582702637, training accuracy: 0.46447265625
2023-10-12 04:58:13,200 - __main__ - INFO - Epoch [6/64], Step [2101/2503], training loss: 2.5054242610931396, training accuracy: 0.4661328125
2023-10-12 05:00:44,891 - __main__ - INFO - Epoch [6/64], Step [2201/2503], training loss: 2.348762273788452, training accuracy: 0.4680078125
2023-10-12 05:03:02,353 - __main__ - INFO - Epoch [6/64], Step [2301/2503], training loss: 2.476508378982544, training accuracy: 0.46634765625
2023-10-12 05:05:30,094 - __main__ - INFO - Epoch [6/64], Step [2401/2503], training loss: 2.430392265319824, training accuracy: 0.46310546875
2023-10-12 05:07:42,094 - __main__ - INFO - Epoch [6/64], Step [2501/2503], training loss: 2.3647584915161133, training accuracy: 0.4653125
2023-10-12 05:11:31,519 - __main__ - INFO - Epoch [7/64], accuracy: 0.4978
2023-10-12 05:11:51,379 - __main__ - INFO - Epoch [7/64], Step [1/2503], training loss: 2.3620312213897705, training accuracy: 0.455012853470437
2023-10-12 05:13:32,530 - __main__ - INFO - Epoch [7/64], Step [101/2503], training loss: 2.1976635456085205, training accuracy: 0.47923828125
2023-10-12 05:15:08,141 - __main__ - INFO - Epoch [7/64], Step [201/2503], training loss: 2.337834358215332, training accuracy: 0.47857421875
2023-10-12 05:16:54,071 - __main__ - INFO - Epoch [7/64], Step [301/2503], training loss: 2.2805166244506836, training accuracy: 0.47509765625
2023-10-12 05:18:52,853 - __main__ - INFO - Epoch [7/64], Step [401/2503], training loss: 2.389456272125244, training accuracy: 0.47783203125
2023-10-12 05:20:39,987 - __main__ - INFO - Epoch [7/64], Step [501/2503], training loss: 2.3406982421875, training accuracy: 0.4791015625
2023-10-12 05:22:33,966 - __main__ - INFO - Epoch [7/64], Step [601/2503], training loss: 2.365546464920044, training accuracy: 0.473046875
2023-10-12 05:24:18,583 - __main__ - INFO - Epoch [7/64], Step [701/2503], training loss: 2.5652530193328857, training accuracy: 0.47748046875
2023-10-12 05:26:10,661 - __main__ - INFO - Epoch [7/64], Step [801/2503], training loss: 2.404278039932251, training accuracy: 0.4799609375
2023-10-12 05:28:10,315 - __main__ - INFO - Epoch [7/64], Step [901/2503], training loss: 2.347724199295044, training accuracy: 0.4815625
2023-10-12 05:30:04,794 - __main__ - INFO - Epoch [7/64], Step [1001/2503], training loss: 2.4194040298461914, training accuracy: 0.48357421875
2023-10-12 05:31:59,397 - __main__ - INFO - Epoch [7/64], Step [1101/2503], training loss: 2.25917911529541, training accuracy: 0.4833984375
2023-10-12 05:33:59,322 - __main__ - INFO - Epoch [7/64], Step [1201/2503], training loss: 2.3412771224975586, training accuracy: 0.4834765625
2023-10-12 05:35:56,161 - __main__ - INFO - Epoch [7/64], Step [1301/2503], training loss: 2.5689785480499268, training accuracy: 0.47986328125
2023-10-12 05:38:02,626 - __main__ - INFO - Epoch [7/64], Step [1401/2503], training loss: 2.1042888164520264, training accuracy: 0.48458984375
2023-10-12 05:40:00,083 - __main__ - INFO - Epoch [7/64], Step [1501/2503], training loss: 2.0941426753997803, training accuracy: 0.483359375
2023-10-12 05:41:58,714 - __main__ - INFO - Epoch [7/64], Step [1601/2503], training loss: 2.382901906967163, training accuracy: 0.48556640625
2023-10-12 05:43:57,483 - __main__ - INFO - Epoch [7/64], Step [1701/2503], training loss: 2.3487062454223633, training accuracy: 0.485234375
2023-10-12 05:46:05,440 - __main__ - INFO - Epoch [7/64], Step [1801/2503], training loss: 2.340070962905884, training accuracy: 0.48412109375
2023-10-12 05:47:56,380 - __main__ - INFO - Epoch [7/64], Step [1901/2503], training loss: 2.3619489669799805, training accuracy: 0.47693359375
2023-10-12 05:49:51,384 - __main__ - INFO - Epoch [7/64], Step [2001/2503], training loss: 2.404967784881592, training accuracy: 0.48830078125
2023-10-12 05:51:48,736 - __main__ - INFO - Epoch [7/64], Step [2101/2503], training loss: 2.419609308242798, training accuracy: 0.486875
2023-10-12 05:53:57,865 - __main__ - INFO - Epoch [7/64], Step [2201/2503], training loss: 2.2491135597229004, training accuracy: 0.48525390625
2023-10-12 05:55:52,611 - __main__ - INFO - Epoch [7/64], Step [2301/2503], training loss: 2.3156931400299072, training accuracy: 0.488046875
2023-10-12 05:57:48,366 - __main__ - INFO - Epoch [7/64], Step [2401/2503], training loss: 2.3410372734069824, training accuracy: 0.48822265625
2023-10-12 05:59:51,185 - __main__ - INFO - Epoch [7/64], Step [2501/2503], training loss: 2.163302183151245, training accuracy: 0.48919921875
2023-10-12 06:04:18,973 - __main__ - INFO - Epoch [8/64], accuracy: 0.52506
2023-10-12 06:04:43,204 - __main__ - INFO - Epoch [8/64], Step [1/2503], training loss: 2.1878790855407715, training accuracy: 0.4987146529562982
2023-10-12 06:06:34,988 - __main__ - INFO - Epoch [8/64], Step [101/2503], training loss: 2.3271291255950928, training accuracy: 0.49798828125
2023-10-12 06:08:40,606 - __main__ - INFO - Epoch [8/64], Step [201/2503], training loss: 2.2663731575012207, training accuracy: 0.49787109375
2023-10-12 06:10:41,202 - __main__ - INFO - Epoch [8/64], Step [301/2503], training loss: 2.3229129314422607, training accuracy: 0.50015625
2023-10-12 06:12:50,588 - __main__ - INFO - Epoch [8/64], Step [401/2503], training loss: 2.327903985977173, training accuracy: 0.49896484375
2023-10-12 06:14:53,334 - __main__ - INFO - Epoch [8/64], Step [501/2503], training loss: 2.2577812671661377, training accuracy: 0.49826171875
2023-10-12 06:16:54,304 - __main__ - INFO - Epoch [8/64], Step [601/2503], training loss: 2.2538414001464844, training accuracy: 0.4961328125
2023-10-12 06:19:07,302 - __main__ - INFO - Epoch [8/64], Step [701/2503], training loss: 2.2199368476867676, training accuracy: 0.50173828125
2023-10-12 06:21:17,943 - __main__ - INFO - Epoch [8/64], Step [801/2503], training loss: 2.277646064758301, training accuracy: 0.4959375
2023-10-12 06:23:22,101 - __main__ - INFO - Epoch [8/64], Step [901/2503], training loss: 2.468750476837158, training accuracy: 0.50326171875
2023-10-12 06:25:22,754 - __main__ - INFO - Epoch [8/64], Step [1001/2503], training loss: 2.180209159851074, training accuracy: 0.50322265625
2023-10-12 06:27:18,519 - __main__ - INFO - Epoch [8/64], Step [1101/2503], training loss: 2.205444097518921, training accuracy: 0.5015625
2023-10-12 06:29:17,630 - __main__ - INFO - Epoch [8/64], Step [1201/2503], training loss: 2.206660747528076, training accuracy: 0.5012109375
2023-10-12 06:31:13,051 - __main__ - INFO - Epoch [8/64], Step [1301/2503], training loss: 2.420560121536255, training accuracy: 0.50181640625
2023-10-12 06:33:10,020 - __main__ - INFO - Epoch [8/64], Step [1401/2503], training loss: 2.3800857067108154, training accuracy: 0.50423828125
2023-10-12 06:35:33,200 - __main__ - INFO - Epoch [8/64], Step [1501/2503], training loss: 2.3543508052825928, training accuracy: 0.4987890625
2023-10-12 06:38:09,192 - __main__ - INFO - Epoch [8/64], Step [1601/2503], training loss: 2.2070865631103516, training accuracy: 0.5015625
2023-10-12 06:40:43,188 - __main__ - INFO - Epoch [8/64], Step [1701/2503], training loss: 1.9897642135620117, training accuracy: 0.5016796875
2023-10-12 06:43:12,293 - __main__ - INFO - Epoch [8/64], Step [1801/2503], training loss: 2.391496419906616, training accuracy: 0.5016796875
2023-10-12 06:45:50,620 - __main__ - INFO - Epoch [8/64], Step [1901/2503], training loss: 2.2885704040527344, training accuracy: 0.50787109375
2023-10-12 06:48:23,120 - __main__ - INFO - Epoch [8/64], Step [2001/2503], training loss: 2.072591543197632, training accuracy: 0.5048828125
2023-10-12 06:50:59,413 - __main__ - INFO - Epoch [8/64], Step [2101/2503], training loss: 2.5217084884643555, training accuracy: 0.504609375
2023-10-12 06:53:40,154 - __main__ - INFO - Epoch [8/64], Step [2201/2503], training loss: 2.1701900959014893, training accuracy: 0.50189453125
2023-10-12 06:56:19,273 - __main__ - INFO - Epoch [8/64], Step [2301/2503], training loss: 2.317568778991699, training accuracy: 0.5065625
2023-10-12 06:58:52,297 - __main__ - INFO - Epoch [8/64], Step [2401/2503], training loss: 2.310392379760742, training accuracy: 0.50134765625
2023-10-12 07:01:18,681 - __main__ - INFO - Epoch [8/64], Step [2501/2503], training loss: 2.233969211578369, training accuracy: 0.5076953125
2023-10-12 07:04:58,354 - __main__ - INFO - Epoch [9/64], accuracy: 0.52516
2023-10-12 07:05:20,815 - __main__ - INFO - Epoch [9/64], Step [1/2503], training loss: 2.2232213020324707, training accuracy: 0.4987146529562982
2023-10-12 07:07:23,099 - __main__ - INFO - Epoch [9/64], Step [101/2503], training loss: 2.1002588272094727, training accuracy: 0.51744140625
2023-10-12 07:09:53,435 - __main__ - INFO - Epoch [9/64], Step [201/2503], training loss: 2.215580463409424, training accuracy: 0.51349609375
2023-10-12 07:12:24,100 - __main__ - INFO - Epoch [9/64], Step [301/2503], training loss: 2.231959342956543, training accuracy: 0.51458984375
2023-10-12 07:15:05,426 - __main__ - INFO - Epoch [9/64], Step [401/2503], training loss: 2.2119877338409424, training accuracy: 0.518203125
2023-10-12 07:17:31,226 - __main__ - INFO - Epoch [9/64], Step [501/2503], training loss: 2.082758665084839, training accuracy: 0.51671875
2023-10-12 07:20:03,154 - __main__ - INFO - Epoch [9/64], Step [601/2503], training loss: 2.0327272415161133, training accuracy: 0.5185546875
2023-10-12 07:22:31,001 - __main__ - INFO - Epoch [9/64], Step [701/2503], training loss: 1.9961726665496826, training accuracy: 0.514453125
2023-10-12 07:25:08,022 - __main__ - INFO - Epoch [9/64], Step [801/2503], training loss: 2.138523817062378, training accuracy: 0.51744140625
2023-10-12 07:27:35,168 - __main__ - INFO - Epoch [9/64], Step [901/2503], training loss: 2.061807870864868, training accuracy: 0.51677734375
2023-10-12 07:30:06,110 - __main__ - INFO - Epoch [9/64], Step [1001/2503], training loss: 2.5248210430145264, training accuracy: 0.516171875
2023-10-12 07:32:39,518 - __main__ - INFO - Epoch [9/64], Step [1101/2503], training loss: 2.321096181869507, training accuracy: 0.51095703125
2023-10-12 07:35:06,621 - __main__ - INFO - Epoch [9/64], Step [1201/2503], training loss: 2.1619179248809814, training accuracy: 0.51490234375
2023-10-12 07:37:28,325 - __main__ - INFO - Epoch [9/64], Step [1301/2503], training loss: 2.1546499729156494, training accuracy: 0.51435546875
2023-10-12 07:40:02,528 - __main__ - INFO - Epoch [9/64], Step [1401/2503], training loss: 2.014042854309082, training accuracy: 0.5175
2023-10-12 07:42:28,218 - __main__ - INFO - Epoch [9/64], Step [1501/2503], training loss: 2.136345863342285, training accuracy: 0.51701171875
2023-10-12 07:44:52,956 - __main__ - INFO - Epoch [9/64], Step [1601/2503], training loss: 2.0879228115081787, training accuracy: 0.51787109375
2023-10-12 07:47:28,718 - __main__ - INFO - Epoch [9/64], Step [1701/2503], training loss: 2.0578792095184326, training accuracy: 0.52052734375
2023-10-12 07:50:07,829 - __main__ - INFO - Epoch [9/64], Step [1801/2503], training loss: 2.0470688343048096, training accuracy: 0.51646484375
2023-10-12 07:52:38,269 - __main__ - INFO - Epoch [9/64], Step [1901/2503], training loss: 2.1756675243377686, training accuracy: 0.519140625
2023-10-12 07:55:07,752 - __main__ - INFO - Epoch [9/64], Step [2001/2503], training loss: 2.016385316848755, training accuracy: 0.51958984375
2023-10-12 07:57:37,732 - __main__ - INFO - Epoch [9/64], Step [2101/2503], training loss: 2.1447126865386963, training accuracy: 0.51912109375
2023-10-12 08:00:17,157 - __main__ - INFO - Epoch [9/64], Step [2201/2503], training loss: 2.2449021339416504, training accuracy: 0.52068359375
2023-10-12 08:02:43,690 - __main__ - INFO - Epoch [9/64], Step [2301/2503], training loss: 2.272000789642334, training accuracy: 0.52275390625
2023-10-12 08:05:13,548 - __main__ - INFO - Epoch [9/64], Step [2401/2503], training loss: 2.147690773010254, training accuracy: 0.5226953125
2023-10-12 08:07:28,841 - __main__ - INFO - Epoch [9/64], Step [2501/2503], training loss: 2.0919888019561768, training accuracy: 0.51849609375
2023-10-12 08:11:27,874 - __main__ - INFO - Epoch [10/64], accuracy: 0.56012
2023-10-12 08:11:50,832 - __main__ - INFO - Epoch [10/64], Step [1/2503], training loss: 2.063676357269287, training accuracy: 0.5329905741216795
2023-10-12 08:13:44,673 - __main__ - INFO - Epoch [10/64], Step [101/2503], training loss: 2.226506233215332, training accuracy: 0.53193359375
2023-10-12 08:15:43,698 - __main__ - INFO - Epoch [10/64], Step [201/2503], training loss: 2.058523178100586, training accuracy: 0.52720703125
2023-10-12 08:17:35,226 - __main__ - INFO - Epoch [10/64], Step [301/2503], training loss: 2.1629319190979004, training accuracy: 0.53158203125
2023-10-12 08:19:39,500 - __main__ - INFO - Epoch [10/64], Step [401/2503], training loss: 2.0590853691101074, training accuracy: 0.53296875
2023-10-12 08:21:44,545 - __main__ - INFO - Epoch [10/64], Step [501/2503], training loss: 2.2827067375183105, training accuracy: 0.53103515625
2023-10-12 08:23:42,891 - __main__ - INFO - Epoch [10/64], Step [601/2503], training loss: 2.1381115913391113, training accuracy: 0.53302734375
2023-10-12 08:25:44,696 - __main__ - INFO - Epoch [10/64], Step [701/2503], training loss: 2.1304566860198975, training accuracy: 0.530234375
2023-10-12 08:27:50,355 - __main__ - INFO - Epoch [10/64], Step [801/2503], training loss: 2.2117421627044678, training accuracy: 0.5273828125
2023-10-12 08:29:55,780 - __main__ - INFO - Epoch [10/64], Step [901/2503], training loss: 2.033674955368042, training accuracy: 0.52890625
2023-10-12 08:32:00,371 - __main__ - INFO - Epoch [10/64], Step [1001/2503], training loss: 2.2509865760803223, training accuracy: 0.53625
2023-10-12 08:34:01,343 - __main__ - INFO - Epoch [10/64], Step [1101/2503], training loss: 2.078490734100342, training accuracy: 0.52626953125
2023-10-12 08:36:06,708 - __main__ - INFO - Epoch [10/64], Step [1201/2503], training loss: 2.1067564487457275, training accuracy: 0.52951171875
2023-10-12 08:38:21,099 - __main__ - INFO - Epoch [10/64], Step [1301/2503], training loss: 2.000516891479492, training accuracy: 0.530703125
2023-10-12 08:41:07,512 - __main__ - INFO - Epoch [10/64], Step [1401/2503], training loss: 2.1583311557769775, training accuracy: 0.52810546875
2023-10-12 08:43:32,444 - __main__ - INFO - Epoch [10/64], Step [1501/2503], training loss: 2.1334986686706543, training accuracy: 0.52986328125
2023-10-12 08:45:52,187 - __main__ - INFO - Epoch [10/64], Step [1601/2503], training loss: 2.0221705436706543, training accuracy: 0.528359375
2023-10-12 08:48:32,114 - __main__ - INFO - Epoch [10/64], Step [1701/2503], training loss: 2.192296266555786, training accuracy: 0.53462890625
2023-10-12 08:51:01,422 - __main__ - INFO - Epoch [10/64], Step [1801/2503], training loss: 2.0979607105255127, training accuracy: 0.5357421875
2023-10-12 08:53:28,526 - __main__ - INFO - Epoch [10/64], Step [1901/2503], training loss: 2.1203525066375732, training accuracy: 0.5266015625
2023-10-12 08:56:02,389 - __main__ - INFO - Epoch [10/64], Step [2001/2503], training loss: 2.0289788246154785, training accuracy: 0.53158203125
2023-10-12 08:58:32,039 - __main__ - INFO - Epoch [10/64], Step [2101/2503], training loss: 1.995308756828308, training accuracy: 0.53060546875
2023-10-12 09:00:59,428 - __main__ - INFO - Epoch [10/64], Step [2201/2503], training loss: 2.046752691268921, training accuracy: 0.531484375
2023-10-12 09:03:38,378 - __main__ - INFO - Epoch [10/64], Step [2301/2503], training loss: 1.9309782981872559, training accuracy: 0.533359375
2023-10-12 09:06:15,635 - __main__ - INFO - Epoch [10/64], Step [2401/2503], training loss: 2.000516891479492, training accuracy: 0.53287109375
2023-10-12 09:08:47,105 - __main__ - INFO - Epoch [10/64], Step [2501/2503], training loss: 2.004500150680542, training accuracy: 0.53345703125
2023-10-12 09:13:28,628 - __main__ - INFO - Epoch [11/64], accuracy: 0.56532
2023-10-12 09:13:50,894 - __main__ - INFO - Epoch [11/64], Step [1/2503], training loss: 2.013381242752075, training accuracy: 0.5586975149957155
2023-10-12 09:15:59,689 - __main__ - INFO - Epoch [11/64], Step [101/2503], training loss: 2.123452663421631, training accuracy: 0.53857421875
2023-10-12 09:18:36,294 - __main__ - INFO - Epoch [11/64], Step [201/2503], training loss: 2.0389928817749023, training accuracy: 0.54439453125
2023-10-12 09:21:12,342 - __main__ - INFO - Epoch [11/64], Step [301/2503], training loss: 2.055419445037842, training accuracy: 0.54181640625
2023-10-12 09:23:43,067 - __main__ - INFO - Epoch [11/64], Step [401/2503], training loss: 1.9003180265426636, training accuracy: 0.54130859375
2023-10-12 09:26:29,806 - __main__ - INFO - Epoch [11/64], Step [501/2503], training loss: 1.9653756618499756, training accuracy: 0.5437109375
2023-10-12 09:29:03,737 - __main__ - INFO - Epoch [11/64], Step [601/2503], training loss: 1.9371837377548218, training accuracy: 0.5409765625
2023-10-12 09:31:37,152 - __main__ - INFO - Epoch [11/64], Step [701/2503], training loss: 2.0015273094177246, training accuracy: 0.54251953125
2023-10-12 09:34:23,997 - __main__ - INFO - Epoch [11/64], Step [801/2503], training loss: 1.935704231262207, training accuracy: 0.54474609375
2023-10-12 09:37:07,217 - __main__ - INFO - Epoch [11/64], Step [901/2503], training loss: 2.1140623092651367, training accuracy: 0.54302734375
2023-10-12 09:39:47,766 - __main__ - INFO - Epoch [11/64], Step [1001/2503], training loss: 1.9586412906646729, training accuracy: 0.54369140625
2023-10-12 09:42:33,362 - __main__ - INFO - Epoch [11/64], Step [1101/2503], training loss: 2.03259539604187, training accuracy: 0.54126953125
2023-10-12 09:45:22,632 - __main__ - INFO - Epoch [11/64], Step [1201/2503], training loss: 2.1316542625427246, training accuracy: 0.5382421875
2023-10-12 09:48:13,849 - __main__ - INFO - Epoch [11/64], Step [1301/2503], training loss: 2.079040765762329, training accuracy: 0.54123046875
2023-10-12 09:50:55,882 - __main__ - INFO - Epoch [11/64], Step [1401/2503], training loss: 1.9513899087905884, training accuracy: 0.54451171875
2023-10-12 09:53:44,349 - __main__ - INFO - Epoch [11/64], Step [1501/2503], training loss: 2.1436238288879395, training accuracy: 0.53837890625
2023-10-12 09:56:45,938 - __main__ - INFO - Epoch [11/64], Step [1601/2503], training loss: 2.120450973510742, training accuracy: 0.54369140625
2023-10-12 09:59:36,716 - __main__ - INFO - Epoch [11/64], Step [1701/2503], training loss: 2.034919500350952, training accuracy: 0.541640625
2023-10-12 10:02:43,414 - __main__ - INFO - Epoch [11/64], Step [1801/2503], training loss: 2.1314878463745117, training accuracy: 0.544921875
2023-10-12 10:05:48,496 - __main__ - INFO - Epoch [11/64], Step [1901/2503], training loss: 2.050096035003662, training accuracy: 0.54140625
2023-10-12 10:09:07,899 - __main__ - INFO - Epoch [11/64], Step [2001/2503], training loss: 2.0225110054016113, training accuracy: 0.542421875
2023-10-12 10:12:06,091 - __main__ - INFO - Epoch [11/64], Step [2101/2503], training loss: 1.8926029205322266, training accuracy: 0.538046875
2023-10-12 10:15:13,208 - __main__ - INFO - Epoch [11/64], Step [2201/2503], training loss: 2.1184914112091064, training accuracy: 0.545
2023-10-12 10:18:12,454 - __main__ - INFO - Epoch [11/64], Step [2301/2503], training loss: 2.1154913902282715, training accuracy: 0.54216796875
2023-10-12 10:21:34,471 - __main__ - INFO - Epoch [11/64], Step [2401/2503], training loss: 1.8997844457626343, training accuracy: 0.54087890625
2023-10-12 10:24:23,053 - __main__ - INFO - Epoch [11/64], Step [2501/2503], training loss: 1.945470929145813, training accuracy: 0.54375
2023-10-12 10:30:24,406 - __main__ - INFO - Epoch [12/64], accuracy: 0.58086
2023-10-12 10:30:59,719 - __main__ - INFO - Epoch [12/64], Step [1/2503], training loss: 2.010668992996216, training accuracy: 0.5492716366752356
2023-10-12 10:33:24,197 - __main__ - INFO - Epoch [12/64], Step [101/2503], training loss: 2.038238048553467, training accuracy: 0.554296875
2023-10-12 10:35:58,233 - __main__ - INFO - Epoch [12/64], Step [201/2503], training loss: 1.8215607404708862, training accuracy: 0.5500390625
2023-10-12 10:38:23,334 - __main__ - INFO - Epoch [12/64], Step [301/2503], training loss: 2.0694103240966797, training accuracy: 0.55443359375
2023-10-12 10:41:12,412 - __main__ - INFO - Epoch [12/64], Step [401/2503], training loss: 2.079545736312866, training accuracy: 0.55015625
2023-10-12 10:43:49,950 - __main__ - INFO - Epoch [12/64], Step [501/2503], training loss: 1.9079327583312988, training accuracy: 0.5523046875
2023-10-12 10:46:22,935 - __main__ - INFO - Epoch [12/64], Step [601/2503], training loss: 1.8995671272277832, training accuracy: 0.55052734375
2023-10-12 10:49:20,343 - __main__ - INFO - Epoch [12/64], Step [701/2503], training loss: 1.686025619506836, training accuracy: 0.55087890625
2023-10-12 10:52:45,523 - __main__ - INFO - Epoch [12/64], Step [801/2503], training loss: 2.0336084365844727, training accuracy: 0.55185546875
2023-10-12 10:55:57,629 - __main__ - INFO - Epoch [12/64], Step [901/2503], training loss: 2.0246164798736572, training accuracy: 0.54833984375
2023-10-12 10:59:14,698 - __main__ - INFO - Epoch [12/64], Step [1001/2503], training loss: 1.8802664279937744, training accuracy: 0.5540625
2023-10-12 11:02:19,163 - __main__ - INFO - Epoch [12/64], Step [1101/2503], training loss: 1.6818950176239014, training accuracy: 0.55359375
2023-10-12 11:05:56,823 - __main__ - INFO - Epoch [12/64], Step [1201/2503], training loss: 1.863278865814209, training accuracy: 0.54892578125
2023-10-12 11:09:01,680 - __main__ - INFO - Epoch [12/64], Step [1301/2503], training loss: 1.9049168825149536, training accuracy: 0.553984375
2023-10-12 11:11:54,016 - __main__ - INFO - Epoch [12/64], Step [1401/2503], training loss: 1.9612233638763428, training accuracy: 0.54990234375
2023-10-12 11:14:43,576 - __main__ - INFO - Epoch [12/64], Step [1501/2503], training loss: 1.9967271089553833, training accuracy: 0.55392578125
2023-10-12 11:17:41,046 - __main__ - INFO - Epoch [12/64], Step [1601/2503], training loss: 1.7056193351745605, training accuracy: 0.5558984375
2023-10-12 11:20:28,796 - __main__ - INFO - Epoch [12/64], Step [1701/2503], training loss: 1.9424492120742798, training accuracy: 0.5534765625
2023-10-12 11:23:16,390 - __main__ - INFO - Epoch [12/64], Step [1801/2503], training loss: 2.085245370864868, training accuracy: 0.548203125
2023-10-12 11:25:56,644 - __main__ - INFO - Epoch [12/64], Step [1901/2503], training loss: 2.0054211616516113, training accuracy: 0.55328125
2023-10-12 11:28:57,110 - __main__ - INFO - Epoch [12/64], Step [2001/2503], training loss: 1.8398964405059814, training accuracy: 0.55005859375
2023-10-12 11:31:48,616 - __main__ - INFO - Epoch [12/64], Step [2101/2503], training loss: 1.8703068494796753, training accuracy: 0.55234375
2023-10-12 11:34:36,823 - __main__ - INFO - Epoch [12/64], Step [2201/2503], training loss: 1.8504570722579956, training accuracy: 0.55013671875
2023-10-12 11:37:27,718 - __main__ - INFO - Epoch [12/64], Step [2301/2503], training loss: 1.933082103729248, training accuracy: 0.55416015625
2023-10-12 11:40:42,094 - __main__ - INFO - Epoch [12/64], Step [2401/2503], training loss: 1.8735586404800415, training accuracy: 0.5541015625
2023-10-12 11:43:14,351 - __main__ - INFO - Epoch [12/64], Step [2501/2503], training loss: 1.9568973779678345, training accuracy: 0.5544921875
2023-10-12 11:48:24,348 - __main__ - INFO - Epoch [13/64], accuracy: 0.5914
2023-10-12 11:48:54,363 - __main__ - INFO - Epoch [13/64], Step [1/2503], training loss: 1.8242517709732056, training accuracy: 0.5561268209083119
2023-10-12 11:51:42,603 - __main__ - INFO - Epoch [13/64], Step [101/2503], training loss: 1.865413784980774, training accuracy: 0.562578125
2023-10-12 11:54:28,757 - __main__ - INFO - Epoch [13/64], Step [201/2503], training loss: 1.784124732017517, training accuracy: 0.56130859375
2023-10-12 11:57:28,612 - __main__ - INFO - Epoch [13/64], Step [301/2503], training loss: 1.885450005531311, training accuracy: 0.5630859375
2023-10-12 12:00:42,014 - __main__ - INFO - Epoch [13/64], Step [401/2503], training loss: 2.071369171142578, training accuracy: 0.56001953125
2023-10-12 12:03:43,874 - __main__ - INFO - Epoch [13/64], Step [501/2503], training loss: 1.8890715837478638, training accuracy: 0.5626171875
2023-10-12 12:06:31,920 - __main__ - INFO - Epoch [13/64], Step [601/2503], training loss: 1.87688410282135, training accuracy: 0.56060546875
2023-10-12 12:09:24,941 - __main__ - INFO - Epoch [13/64], Step [701/2503], training loss: 1.9132180213928223, training accuracy: 0.5636328125
2023-10-12 12:12:13,888 - __main__ - INFO - Epoch [13/64], Step [801/2503], training loss: 1.9831398725509644, training accuracy: 0.56185546875
2023-10-12 12:15:06,600 - __main__ - INFO - Epoch [13/64], Step [901/2503], training loss: 1.8775203227996826, training accuracy: 0.5576171875
2023-10-12 12:17:49,022 - __main__ - INFO - Epoch [13/64], Step [1001/2503], training loss: 1.9331042766571045, training accuracy: 0.5659375
2023-10-12 12:20:37,200 - __main__ - INFO - Epoch [13/64], Step [1101/2503], training loss: 2.091230630874634, training accuracy: 0.56197265625
2023-10-12 12:23:28,635 - __main__ - INFO - Epoch [13/64], Step [1201/2503], training loss: 1.93696928024292, training accuracy: 0.5623046875
2023-10-12 12:26:33,638 - __main__ - INFO - Epoch [13/64], Step [1301/2503], training loss: 2.0199718475341797, training accuracy: 0.5582421875
2023-10-12 12:29:21,689 - __main__ - INFO - Epoch [13/64], Step [1401/2503], training loss: 1.967839002609253, training accuracy: 0.56037109375
2023-10-12 12:32:09,029 - __main__ - INFO - Epoch [13/64], Step [1501/2503], training loss: 1.937801718711853, training accuracy: 0.56125
2023-10-12 12:34:59,818 - __main__ - INFO - Epoch [13/64], Step [1601/2503], training loss: 1.8244274854660034, training accuracy: 0.55875
2023-10-12 12:38:00,302 - __main__ - INFO - Epoch [13/64], Step [1701/2503], training loss: 2.147280216217041, training accuracy: 0.56349609375
2023-10-12 12:40:39,503 - __main__ - INFO - Epoch [13/64], Step [1801/2503], training loss: 1.8876774311065674, training accuracy: 0.55861328125
2023-10-12 12:43:27,368 - __main__ - INFO - Epoch [13/64], Step [1901/2503], training loss: 2.0087156295776367, training accuracy: 0.56298828125
2023-10-12 12:46:03,790 - __main__ - INFO - Epoch [13/64], Step [2001/2503], training loss: 1.9898933172225952, training accuracy: 0.55865234375
2023-10-12 12:48:59,921 - __main__ - INFO - Epoch [13/64], Step [2101/2503], training loss: 2.01834774017334, training accuracy: 0.56046875
2023-10-12 12:51:42,765 - __main__ - INFO - Epoch [13/64], Step [2201/2503], training loss: 1.8224334716796875, training accuracy: 0.5603125
2023-10-12 12:54:29,967 - __main__ - INFO - Epoch [13/64], Step [2301/2503], training loss: 1.8975939750671387, training accuracy: 0.56294921875
2023-10-12 12:57:16,412 - __main__ - INFO - Epoch [13/64], Step [2401/2503], training loss: 2.0506832599639893, training accuracy: 0.55712890625
2023-10-12 13:00:11,279 - __main__ - INFO - Epoch [13/64], Step [2501/2503], training loss: 1.945298671722412, training accuracy: 0.56375
2023-10-12 13:05:04,003 - __main__ - INFO - Epoch [14/64], accuracy: 0.54586
2023-10-12 13:05:28,510 - __main__ - INFO - Epoch [14/64], Step [1/2503], training loss: 1.825416088104248, training accuracy: 0.5861182519280206
2023-10-12 13:07:50,073 - __main__ - INFO - Epoch [14/64], Step [101/2503], training loss: 1.9635562896728516, training accuracy: 0.568984375
2023-10-12 13:10:17,105 - __main__ - INFO - Epoch [14/64], Step [201/2503], training loss: 2.016948938369751, training accuracy: 0.568046875
2023-10-12 13:12:55,553 - __main__ - INFO - Epoch [14/64], Step [301/2503], training loss: 1.9670484066009521, training accuracy: 0.57107421875
2023-10-12 13:15:41,060 - __main__ - INFO - Epoch [14/64], Step [401/2503], training loss: 1.8545981645584106, training accuracy: 0.57341796875
2023-10-12 13:18:15,543 - __main__ - INFO - Epoch [14/64], Step [501/2503], training loss: 1.9937077760696411, training accuracy: 0.5735546875
2023-10-12 13:20:51,245 - __main__ - INFO - Epoch [14/64], Step [601/2503], training loss: 1.8630222082138062, training accuracy: 0.57080078125
2023-10-12 13:23:28,560 - __main__ - INFO - Epoch [14/64], Step [701/2503], training loss: 1.7590651512145996, training accuracy: 0.5727734375
2023-10-12 13:26:03,383 - __main__ - INFO - Epoch [14/64], Step [801/2503], training loss: 1.8457411527633667, training accuracy: 0.5710546875
2023-10-12 13:28:38,898 - __main__ - INFO - Epoch [14/64], Step [901/2503], training loss: 1.7305324077606201, training accuracy: 0.5694921875
2023-10-12 13:31:13,427 - __main__ - INFO - Epoch [14/64], Step [1001/2503], training loss: 1.9103130102157593, training accuracy: 0.5721875
2023-10-12 13:33:52,932 - __main__ - INFO - Epoch [14/64], Step [1101/2503], training loss: 1.8971604108810425, training accuracy: 0.57046875
2023-10-12 13:36:31,504 - __main__ - INFO - Epoch [14/64], Step [1201/2503], training loss: 1.972516655921936, training accuracy: 0.56861328125
2023-10-12 13:39:01,500 - __main__ - INFO - Epoch [14/64], Step [1301/2503], training loss: 1.945487141609192, training accuracy: 0.56560546875
2023-10-12 13:41:49,734 - __main__ - INFO - Epoch [14/64], Step [1401/2503], training loss: 1.928757667541504, training accuracy: 0.56720703125
2023-10-12 13:44:22,108 - __main__ - INFO - Epoch [14/64], Step [1501/2503], training loss: 1.9029700756072998, training accuracy: 0.56435546875
2023-10-12 13:46:57,112 - __main__ - INFO - Epoch [14/64], Step [1601/2503], training loss: 1.8534436225891113, training accuracy: 0.56697265625
2023-10-12 13:49:26,853 - __main__ - INFO - Epoch [14/64], Step [1701/2503], training loss: 1.890637993812561, training accuracy: 0.5626171875
2023-10-12 13:52:08,732 - __main__ - INFO - Epoch [14/64], Step [1801/2503], training loss: 1.8964155912399292, training accuracy: 0.56505859375
2023-10-12 13:54:38,602 - __main__ - INFO - Epoch [14/64], Step [1901/2503], training loss: 2.0498294830322266, training accuracy: 0.56833984375
2023-10-12 13:57:12,366 - __main__ - INFO - Epoch [14/64], Step [2001/2503], training loss: 2.016958713531494, training accuracy: 0.5659375
2023-10-12 13:59:53,006 - __main__ - INFO - Epoch [14/64], Step [2101/2503], training loss: 1.7951239347457886, training accuracy: 0.56953125
2023-10-12 14:02:28,929 - __main__ - INFO - Epoch [14/64], Step [2201/2503], training loss: 2.139265537261963, training accuracy: 0.56779296875
2023-10-12 14:05:04,231 - __main__ - INFO - Epoch [14/64], Step [2301/2503], training loss: 2.4226279258728027, training accuracy: 0.4974609375
2023-10-12 14:07:39,558 - __main__ - INFO - Epoch [14/64], Step [2401/2503], training loss: 2.2115092277526855, training accuracy: 0.50228515625
2023-10-12 14:10:13,454 - __main__ - INFO - Epoch [14/64], Step [2501/2503], training loss: 1.989929437637329, training accuracy: 0.53533203125
2023-10-12 14:14:50,656 - __main__ - INFO - Epoch [15/64], accuracy: 0.58662
2023-10-12 14:15:16,351 - __main__ - INFO - Epoch [15/64], Step [1/2503], training loss: 2.0338282585144043, training accuracy: 0.5372750642673522
2023-10-12 14:17:32,400 - __main__ - INFO - Epoch [15/64], Step [101/2503], training loss: 2.0789635181427, training accuracy: 0.5559765625
2023-10-12 14:20:15,172 - __main__ - INFO - Epoch [15/64], Step [201/2503], training loss: 1.9017502069473267, training accuracy: 0.5612109375
2023-10-12 14:22:46,084 - __main__ - INFO - Epoch [15/64], Step [301/2503], training loss: 1.975191354751587, training accuracy: 0.56322265625
2023-10-12 14:25:26,805 - __main__ - INFO - Epoch [15/64], Step [401/2503], training loss: 1.8729594945907593, training accuracy: 0.567109375
2023-10-12 14:28:06,516 - __main__ - INFO - Epoch [15/64], Step [501/2503], training loss: 1.923422932624817, training accuracy: 0.570625
2023-10-12 14:30:39,974 - __main__ - INFO - Epoch [15/64], Step [601/2503], training loss: 2.046855926513672, training accuracy: 0.5694140625
2023-10-12 14:33:21,882 - __main__ - INFO - Epoch [15/64], Step [701/2503], training loss: 1.8343815803527832, training accuracy: 0.57255859375
2023-10-12 14:36:07,731 - __main__ - INFO - Epoch [15/64], Step [801/2503], training loss: 1.8637992143630981, training accuracy: 0.57224609375
2023-10-12 14:38:43,849 - __main__ - INFO - Epoch [15/64], Step [901/2503], training loss: 1.7157354354858398, training accuracy: 0.573984375
2023-10-12 14:41:37,143 - __main__ - INFO - Epoch [15/64], Step [1001/2503], training loss: 1.8363051414489746, training accuracy: 0.574296875
2023-10-12 14:44:19,577 - __main__ - INFO - Epoch [15/64], Step [1101/2503], training loss: 1.910749077796936, training accuracy: 0.57298828125
2023-10-12 14:47:07,371 - __main__ - INFO - Epoch [15/64], Step [1201/2503], training loss: 1.864147663116455, training accuracy: 0.574140625
2023-10-12 14:50:01,020 - __main__ - INFO - Epoch [15/64], Step [1301/2503], training loss: 1.973846673965454, training accuracy: 0.578359375
2023-10-12 14:52:47,750 - __main__ - INFO - Epoch [15/64], Step [1401/2503], training loss: 1.8622069358825684, training accuracy: 0.57052734375
2023-10-12 14:55:38,790 - __main__ - INFO - Epoch [15/64], Step [1501/2503], training loss: 1.7928340435028076, training accuracy: 0.57890625
2023-10-12 14:58:20,671 - __main__ - INFO - Epoch [15/64], Step [1601/2503], training loss: 1.7880357503890991, training accuracy: 0.580390625
2023-10-12 15:01:26,754 - __main__ - INFO - Epoch [15/64], Step [1701/2503], training loss: 1.8150005340576172, training accuracy: 0.575390625
2023-10-12 15:04:15,577 - __main__ - INFO - Epoch [15/64], Step [1801/2503], training loss: 1.8400706052780151, training accuracy: 0.5746875
2023-10-12 15:07:09,874 - __main__ - INFO - Epoch [15/64], Step [1901/2503], training loss: 1.8296884298324585, training accuracy: 0.5728515625
2023-10-12 15:09:58,931 - __main__ - INFO - Epoch [15/64], Step [2001/2503], training loss: 1.8740566968917847, training accuracy: 0.5753515625
2023-10-12 15:13:06,962 - __main__ - INFO - Epoch [15/64], Step [2101/2503], training loss: 1.6818283796310425, training accuracy: 0.5710546875
2023-10-12 15:15:57,438 - __main__ - INFO - Epoch [15/64], Step [2201/2503], training loss: 2.0212583541870117, training accuracy: 0.57509765625
2023-10-12 15:18:46,583 - __main__ - INFO - Epoch [15/64], Step [2301/2503], training loss: 1.8085275888442993, training accuracy: 0.5787890625
2023-10-12 15:21:27,192 - __main__ - INFO - Epoch [15/64], Step [2401/2503], training loss: 1.7716116905212402, training accuracy: 0.573359375
2023-10-12 15:24:14,980 - __main__ - INFO - Epoch [15/64], Step [2501/2503], training loss: 1.970233678817749, training accuracy: 0.57416015625
2023-10-12 15:28:18,574 - __main__ - INFO - Epoch [16/64], accuracy: 0.61204
2023-10-12 15:28:43,482 - __main__ - INFO - Epoch [16/64], Step [1/2503], training loss: 1.6521594524383545, training accuracy: 0.6049700085689803
2023-10-12 15:30:58,931 - __main__ - INFO - Epoch [16/64], Step [101/2503], training loss: 1.6552443504333496, training accuracy: 0.60333984375
2023-10-12 15:33:43,714 - __main__ - INFO - Epoch [16/64], Step [201/2503], training loss: 1.6735481023788452, training accuracy: 0.6099609375
2023-10-12 15:36:33,315 - __main__ - INFO - Epoch [16/64], Step [301/2503], training loss: 1.49922776222229, training accuracy: 0.61400390625
2023-10-12 15:39:51,007 - __main__ - INFO - Epoch [16/64], Step [401/2503], training loss: 1.542297124862671, training accuracy: 0.61791015625
2023-10-12 15:42:39,897 - __main__ - INFO - Epoch [16/64], Step [501/2503], training loss: 1.7611721754074097, training accuracy: 0.61466796875
2023-10-12 15:45:41,609 - __main__ - INFO - Epoch [16/64], Step [601/2503], training loss: 1.4960373640060425, training accuracy: 0.619765625
2023-10-12 15:48:31,279 - __main__ - INFO - Epoch [16/64], Step [701/2503], training loss: 1.5006799697875977, training accuracy: 0.62220703125
2023-10-12 15:51:50,730 - __main__ - INFO - Epoch [16/64], Step [801/2503], training loss: 1.677186131477356, training accuracy: 0.62111328125
2023-10-12 15:54:53,087 - __main__ - INFO - Epoch [16/64], Step [901/2503], training loss: 1.6561700105667114, training accuracy: 0.6165234375
2023-10-12 15:57:52,421 - __main__ - INFO - Epoch [16/64], Step [1001/2503], training loss: 1.5460693836212158, training accuracy: 0.6244140625
2023-10-12 16:00:51,903 - __main__ - INFO - Epoch [16/64], Step [1101/2503], training loss: 1.7088528871536255, training accuracy: 0.625078125
2023-10-12 16:03:59,528 - __main__ - INFO - Epoch [16/64], Step [1201/2503], training loss: 1.7371468544006348, training accuracy: 0.62330078125
2023-10-12 16:07:07,745 - __main__ - INFO - Epoch [16/64], Step [1301/2503], training loss: 1.7777209281921387, training accuracy: 0.62380859375
2023-10-12 16:09:51,568 - __main__ - INFO - Epoch [16/64], Step [1401/2503], training loss: 1.5679539442062378, training accuracy: 0.62623046875
2023-10-12 16:12:44,705 - __main__ - INFO - Epoch [16/64], Step [1501/2503], training loss: 1.5643627643585205, training accuracy: 0.62603515625
2023-10-12 16:15:48,951 - __main__ - INFO - Epoch [16/64], Step [1601/2503], training loss: 1.5488370656967163, training accuracy: 0.62453125
2023-10-12 16:18:50,132 - __main__ - INFO - Epoch [16/64], Step [1701/2503], training loss: 1.5701451301574707, training accuracy: 0.62771484375
2023-10-12 16:21:24,574 - __main__ - INFO - Epoch [16/64], Step [1801/2503], training loss: 1.415087342262268, training accuracy: 0.6281640625
2023-10-12 16:24:08,297 - __main__ - INFO - Epoch [16/64], Step [1901/2503], training loss: 1.6170084476470947, training accuracy: 0.627890625
2023-10-12 16:27:03,599 - __main__ - INFO - Epoch [16/64], Step [2001/2503], training loss: 1.5882680416107178, training accuracy: 0.62658203125
2023-10-12 16:30:12,352 - __main__ - INFO - Epoch [16/64], Step [2101/2503], training loss: 1.6434650421142578, training accuracy: 0.62650390625
2023-10-12 16:33:12,529 - __main__ - INFO - Epoch [16/64], Step [2201/2503], training loss: 1.6215626001358032, training accuracy: 0.62818359375
2023-10-12 16:36:19,666 - __main__ - INFO - Epoch [16/64], Step [2301/2503], training loss: 1.6308244466781616, training accuracy: 0.6316015625
2023-10-12 16:39:18,340 - __main__ - INFO - Epoch [16/64], Step [2401/2503], training loss: 1.428504228591919, training accuracy: 0.62982421875
2023-10-12 16:42:31,623 - __main__ - INFO - Epoch [16/64], Step [2501/2503], training loss: 1.5225666761398315, training accuracy: 0.627734375
2023-10-12 16:48:39,582 - __main__ - INFO - Epoch [17/64], accuracy: 0.65316
2023-10-12 16:49:06,447 - __main__ - INFO - Epoch [17/64], Step [1/2503], training loss: 1.596509337425232, training accuracy: 0.6358183376178235
2023-10-12 16:51:07,706 - __main__ - INFO - Epoch [17/64], Step [101/2503], training loss: 1.6043541431427002, training accuracy: 0.638125
2023-10-12 16:53:21,463 - __main__ - INFO - Epoch [17/64], Step [201/2503], training loss: 1.6659497022628784, training accuracy: 0.630234375
2023-10-12 16:55:39,031 - __main__ - INFO - Epoch [17/64], Step [301/2503], training loss: 1.4692683219909668, training accuracy: 0.6284765625
2023-10-12 16:58:03,606 - __main__ - INFO - Epoch [17/64], Step [401/2503], training loss: 1.6649519205093384, training accuracy: 0.63755859375
2023-10-12 17:00:20,096 - __main__ - INFO - Epoch [17/64], Step [501/2503], training loss: 1.5846902132034302, training accuracy: 0.63021484375
2023-10-12 17:02:55,023 - __main__ - INFO - Epoch [17/64], Step [601/2503], training loss: 1.5857125520706177, training accuracy: 0.63033203125
2023-10-12 17:05:21,661 - __main__ - INFO - Epoch [17/64], Step [701/2503], training loss: 1.6800086498260498, training accuracy: 0.63095703125
2023-10-12 17:07:41,716 - __main__ - INFO - Epoch [17/64], Step [801/2503], training loss: 1.5932660102844238, training accuracy: 0.62966796875
2023-10-12 17:09:47,657 - __main__ - INFO - Epoch [17/64], Step [901/2503], training loss: 1.7379889488220215, training accuracy: 0.63197265625
2023-10-12 17:12:24,770 - __main__ - INFO - Epoch [17/64], Step [1001/2503], training loss: 1.5105236768722534, training accuracy: 0.63224609375
2023-10-12 17:14:59,371 - __main__ - INFO - Epoch [17/64], Step [1101/2503], training loss: 1.7144005298614502, training accuracy: 0.62740234375
2023-10-12 17:17:45,462 - __main__ - INFO - Epoch [17/64], Step [1201/2503], training loss: 1.7423111200332642, training accuracy: 0.630546875
2023-10-12 17:20:26,509 - __main__ - INFO - Epoch [17/64], Step [1301/2503], training loss: 1.8094184398651123, training accuracy: 0.63650390625
2023-10-12 17:23:25,312 - __main__ - INFO - Epoch [17/64], Step [1401/2503], training loss: 1.600329041481018, training accuracy: 0.63541015625
2023-10-12 17:26:29,642 - __main__ - INFO - Epoch [17/64], Step [1501/2503], training loss: 1.519139051437378, training accuracy: 0.63259765625
2023-10-12 17:29:32,158 - __main__ - INFO - Epoch [17/64], Step [1601/2503], training loss: 1.59207022190094, training accuracy: 0.63369140625
2023-10-12 17:32:41,584 - __main__ - INFO - Epoch [17/64], Step [1701/2503], training loss: 1.657233476638794, training accuracy: 0.63251953125
2023-10-12 17:35:27,261 - __main__ - INFO - Epoch [17/64], Step [1801/2503], training loss: 1.5695927143096924, training accuracy: 0.6336328125
2023-10-12 17:38:22,961 - __main__ - INFO - Epoch [17/64], Step [1901/2503], training loss: 1.44539213180542, training accuracy: 0.63623046875
2023-10-12 17:41:22,390 - __main__ - INFO - Epoch [17/64], Step [2001/2503], training loss: 1.7777444124221802, training accuracy: 0.63083984375
2023-10-12 17:44:31,624 - __main__ - INFO - Epoch [17/64], Step [2101/2503], training loss: 1.6944760084152222, training accuracy: 0.6312109375
2023-10-12 17:47:35,741 - __main__ - INFO - Epoch [17/64], Step [2201/2503], training loss: 1.518257975578308, training accuracy: 0.63609375
2023-10-12 17:50:30,033 - __main__ - INFO - Epoch [17/64], Step [2301/2503], training loss: 1.5474413633346558, training accuracy: 0.63552734375
2023-10-12 17:53:23,223 - __main__ - INFO - Epoch [17/64], Step [2401/2503], training loss: 1.405961513519287, training accuracy: 0.634765625
2023-10-12 17:56:13,528 - __main__ - INFO - Epoch [17/64], Step [2501/2503], training loss: 1.5259082317352295, training accuracy: 0.62927734375
2023-10-12 18:02:14,414 - __main__ - INFO - Epoch [18/64], accuracy: 0.65648
2023-10-12 18:02:48,372 - __main__ - INFO - Epoch [18/64], Step [1/2503], training loss: 1.4643299579620361, training accuracy: 0.6349614395886889
2023-10-12 18:05:17,079 - __main__ - INFO - Epoch [18/64], Step [101/2503], training loss: 1.584388256072998, training accuracy: 0.63486328125
2023-10-12 18:07:42,538 - __main__ - INFO - Epoch [18/64], Step [201/2503], training loss: 1.7169448137283325, training accuracy: 0.63703125
2023-10-12 18:10:25,453 - __main__ - INFO - Epoch [18/64], Step [301/2503], training loss: 1.5896157026290894, training accuracy: 0.63640625
2023-10-12 18:13:09,790 - __main__ - INFO - Epoch [18/64], Step [401/2503], training loss: 1.4945701360702515, training accuracy: 0.635546875
2023-10-12 18:15:37,403 - __main__ - INFO - Epoch [18/64], Step [501/2503], training loss: 1.4396936893463135, training accuracy: 0.63984375
2023-10-12 18:17:55,886 - __main__ - INFO - Epoch [18/64], Step [601/2503], training loss: 1.478489875793457, training accuracy: 0.63646484375
2023-10-12 18:20:16,894 - __main__ - INFO - Epoch [18/64], Step [701/2503], training loss: 1.553876519203186, training accuracy: 0.6375
2023-10-12 18:22:51,623 - __main__ - INFO - Epoch [18/64], Step [801/2503], training loss: 1.6594352722167969, training accuracy: 0.63955078125
2023-10-12 18:25:26,941 - __main__ - INFO - Epoch [18/64], Step [901/2503], training loss: 1.4706348180770874, training accuracy: 0.63765625
2023-10-12 18:28:00,771 - __main__ - INFO - Epoch [18/64], Step [1001/2503], training loss: 1.7601263523101807, training accuracy: 0.6378125
2023-10-12 18:30:15,669 - __main__ - INFO - Epoch [18/64], Step [1101/2503], training loss: 1.6415472030639648, training accuracy: 0.637734375
2023-10-12 18:32:33,831 - __main__ - INFO - Epoch [18/64], Step [1201/2503], training loss: 1.634704828262329, training accuracy: 0.637578125
2023-10-12 18:34:39,678 - __main__ - INFO - Epoch [18/64], Step [1301/2503], training loss: 1.4429597854614258, training accuracy: 0.6383984375
2023-10-12 18:36:42,486 - __main__ - INFO - Epoch [18/64], Step [1401/2503], training loss: 1.476423978805542, training accuracy: 0.64259765625
2023-10-12 18:38:41,496 - __main__ - INFO - Epoch [18/64], Step [1501/2503], training loss: 1.404978632926941, training accuracy: 0.63873046875
2023-10-12 18:40:49,994 - __main__ - INFO - Epoch [18/64], Step [1601/2503], training loss: 1.588688611984253, training accuracy: 0.63796875
2023-10-12 18:42:46,732 - __main__ - INFO - Epoch [18/64], Step [1701/2503], training loss: 1.7066562175750732, training accuracy: 0.6338671875
2023-10-12 18:44:52,831 - __main__ - INFO - Epoch [18/64], Step [1801/2503], training loss: 1.623038649559021, training accuracy: 0.63490234375
2023-10-12 18:46:53,178 - __main__ - INFO - Epoch [18/64], Step [1901/2503], training loss: 1.5853005647659302, training accuracy: 0.63515625
2023-10-12 18:48:58,737 - __main__ - INFO - Epoch [18/64], Step [2001/2503], training loss: 1.5914411544799805, training accuracy: 0.63912109375
2023-10-12 18:50:53,124 - __main__ - INFO - Epoch [18/64], Step [2101/2503], training loss: 1.6251190900802612, training accuracy: 0.63853515625
2023-10-12 18:53:15,850 - __main__ - INFO - Epoch [18/64], Step [2201/2503], training loss: 1.6976443529129028, training accuracy: 0.6369921875
2023-10-12 18:55:43,413 - __main__ - INFO - Epoch [18/64], Step [2301/2503], training loss: 1.4624576568603516, training accuracy: 0.6371484375
2023-10-12 18:58:12,606 - __main__ - INFO - Epoch [18/64], Step [2401/2503], training loss: 1.58189857006073, training accuracy: 0.64341796875
2023-10-12 19:00:24,753 - __main__ - INFO - Epoch [18/64], Step [2501/2503], training loss: 1.6395323276519775, training accuracy: 0.63947265625
2023-10-12 19:04:23,632 - __main__ - INFO - Epoch [19/64], accuracy: 0.66128
2023-10-12 19:04:44,278 - __main__ - INFO - Epoch [19/64], Step [1/2503], training loss: 1.710270881652832, training accuracy: 0.6212510711225364
2023-10-12 19:06:32,437 - __main__ - INFO - Epoch [19/64], Step [101/2503], training loss: 1.5904808044433594, training accuracy: 0.64294921875
2023-10-12 19:08:53,804 - __main__ - INFO - Epoch [19/64], Step [201/2503], training loss: 1.5898398160934448, training accuracy: 0.64091796875
2023-10-12 19:11:11,587 - __main__ - INFO - Epoch [19/64], Step [301/2503], training loss: 1.4729373455047607, training accuracy: 0.6398828125
2023-10-12 19:13:35,234 - __main__ - INFO - Epoch [19/64], Step [401/2503], training loss: 1.578556776046753, training accuracy: 0.64357421875
2023-10-12 19:15:51,511 - __main__ - INFO - Epoch [19/64], Step [501/2503], training loss: 1.5306854248046875, training accuracy: 0.6387890625
2023-10-12 19:18:04,795 - __main__ - INFO - Epoch [19/64], Step [601/2503], training loss: 1.4472739696502686, training accuracy: 0.64033203125
2023-10-12 19:20:17,817 - __main__ - INFO - Epoch [19/64], Step [701/2503], training loss: 1.5338165760040283, training accuracy: 0.644296875
2023-10-12 19:22:38,259 - __main__ - INFO - Epoch [19/64], Step [801/2503], training loss: 1.5272468328475952, training accuracy: 0.642265625
2023-10-12 19:24:57,546 - __main__ - INFO - Epoch [19/64], Step [901/2503], training loss: 1.4400588274002075, training accuracy: 0.64283203125
2023-10-12 19:27:16,585 - __main__ - INFO - Epoch [19/64], Step [1001/2503], training loss: 1.479640245437622, training accuracy: 0.63947265625
2023-10-12 19:29:36,259 - __main__ - INFO - Epoch [19/64], Step [1101/2503], training loss: 1.5162396430969238, training accuracy: 0.63732421875
2023-10-12 19:31:56,384 - __main__ - INFO - Epoch [19/64], Step [1201/2503], training loss: 1.5805221796035767, training accuracy: 0.640078125
2023-10-12 19:34:13,643 - __main__ - INFO - Epoch [19/64], Step [1301/2503], training loss: 1.6982378959655762, training accuracy: 0.64173828125
2023-10-12 19:36:30,640 - __main__ - INFO - Epoch [19/64], Step [1401/2503], training loss: 1.6881695985794067, training accuracy: 0.64201171875
2023-10-12 19:38:51,778 - __main__ - INFO - Epoch [19/64], Step [1501/2503], training loss: 1.5913106203079224, training accuracy: 0.6419921875
2023-10-12 19:41:11,126 - __main__ - INFO - Epoch [19/64], Step [1601/2503], training loss: 1.3546078205108643, training accuracy: 0.6416015625
2023-10-12 19:43:32,887 - __main__ - INFO - Epoch [19/64], Step [1701/2503], training loss: 1.4821414947509766, training accuracy: 0.6385546875
2023-10-12 19:45:54,388 - __main__ - INFO - Epoch [19/64], Step [1801/2503], training loss: 1.5203382968902588, training accuracy: 0.64080078125
2023-10-12 19:48:12,638 - __main__ - INFO - Epoch [19/64], Step [1901/2503], training loss: 1.5906305313110352, training accuracy: 0.639609375
2023-10-12 19:50:36,629 - __main__ - INFO - Epoch [19/64], Step [2001/2503], training loss: 1.6439414024353027, training accuracy: 0.64294921875
2023-10-12 19:53:02,291 - __main__ - INFO - Epoch [19/64], Step [2101/2503], training loss: 1.5532582998275757, training accuracy: 0.640625
2023-10-12 19:55:20,961 - __main__ - INFO - Epoch [19/64], Step [2201/2503], training loss: 1.5098426342010498, training accuracy: 0.63720703125
2023-10-12 19:57:42,768 - __main__ - INFO - Epoch [19/64], Step [2301/2503], training loss: 1.4387298822402954, training accuracy: 0.63955078125
2023-10-12 20:00:04,725 - __main__ - INFO - Epoch [19/64], Step [2401/2503], training loss: 1.594833254814148, training accuracy: 0.6404296875
2023-10-12 20:02:21,788 - __main__ - INFO - Epoch [19/64], Step [2501/2503], training loss: 1.5941091775894165, training accuracy: 0.63982421875
2023-10-12 20:05:40,498 - __main__ - INFO - Epoch [20/64], accuracy: 0.66278
2023-10-12 20:06:01,038 - __main__ - INFO - Epoch [20/64], Step [1/2503], training loss: 1.388658881187439, training accuracy: 0.6546700942587832
2023-10-12 20:07:38,898 - __main__ - INFO - Epoch [20/64], Step [101/2503], training loss: 1.6421797275543213, training accuracy: 0.64439453125
2023-10-12 20:09:11,694 - __main__ - INFO - Epoch [20/64], Step [201/2503], training loss: 1.539054274559021, training accuracy: 0.64255859375
2023-10-12 20:10:48,163 - __main__ - INFO - Epoch [20/64], Step [301/2503], training loss: 1.5188764333724976, training accuracy: 0.64423828125
2023-10-12 20:12:35,603 - __main__ - INFO - Epoch [20/64], Step [401/2503], training loss: 1.628633737564087, training accuracy: 0.64771484375
2023-10-12 20:14:46,349 - __main__ - INFO - Epoch [20/64], Step [501/2503], training loss: 1.5955820083618164, training accuracy: 0.642109375
2023-10-12 20:16:55,243 - __main__ - INFO - Epoch [20/64], Step [601/2503], training loss: 1.467314600944519, training accuracy: 0.64470703125
2023-10-12 20:19:02,932 - __main__ - INFO - Epoch [20/64], Step [701/2503], training loss: 1.6246240139007568, training accuracy: 0.6421484375
2023-10-12 20:21:20,255 - __main__ - INFO - Epoch [20/64], Step [801/2503], training loss: 1.442658543586731, training accuracy: 0.646953125
2023-10-12 20:23:34,885 - __main__ - INFO - Epoch [20/64], Step [901/2503], training loss: 1.4625085592269897, training accuracy: 0.64384765625
2023-10-12 20:25:42,965 - __main__ - INFO - Epoch [20/64], Step [1001/2503], training loss: 1.626878261566162, training accuracy: 0.64064453125
2023-10-12 20:27:57,551 - __main__ - INFO - Epoch [20/64], Step [1101/2503], training loss: 1.4331241846084595, training accuracy: 0.64595703125
2023-10-12 20:30:18,475 - __main__ - INFO - Epoch [20/64], Step [1201/2503], training loss: 1.6065998077392578, training accuracy: 0.643125
2023-10-12 20:32:33,364 - __main__ - INFO - Epoch [20/64], Step [1301/2503], training loss: 1.4947115182876587, training accuracy: 0.6425390625
2023-10-12 20:34:42,688 - __main__ - INFO - Epoch [20/64], Step [1401/2503], training loss: 1.458085060119629, training accuracy: 0.64296875
2023-10-12 20:37:06,593 - __main__ - INFO - Epoch [20/64], Step [1501/2503], training loss: 1.50205397605896, training accuracy: 0.6437109375
2023-10-12 20:39:25,260 - __main__ - INFO - Epoch [20/64], Step [1601/2503], training loss: 1.7054811716079712, training accuracy: 0.64779296875
2023-10-12 20:41:47,027 - __main__ - INFO - Epoch [20/64], Step [1701/2503], training loss: 1.6699857711791992, training accuracy: 0.64458984375
2023-10-12 20:44:00,244 - __main__ - INFO - Epoch [20/64], Step [1801/2503], training loss: 1.3831852674484253, training accuracy: 0.642265625
2023-10-12 20:46:15,612 - __main__ - INFO - Epoch [20/64], Step [1901/2503], training loss: 1.3172192573547363, training accuracy: 0.6454296875
2023-10-12 20:48:32,823 - __main__ - INFO - Epoch [20/64], Step [2001/2503], training loss: 1.5884599685668945, training accuracy: 0.64583984375
2023-10-12 20:50:49,130 - __main__ - INFO - Epoch [20/64], Step [2101/2503], training loss: 1.6206986904144287, training accuracy: 0.644375
2023-10-12 20:53:17,556 - __main__ - INFO - Epoch [20/64], Step [2201/2503], training loss: 1.6073452234268188, training accuracy: 0.64064453125
2023-10-12 20:55:36,236 - __main__ - INFO - Epoch [20/64], Step [2301/2503], training loss: 1.4617122411727905, training accuracy: 0.6435546875
2023-10-12 20:57:57,974 - __main__ - INFO - Epoch [20/64], Step [2401/2503], training loss: 1.477762222290039, training accuracy: 0.6475390625
2023-10-12 21:00:00,839 - __main__ - INFO - Epoch [20/64], Step [2501/2503], training loss: 1.5397840738296509, training accuracy: 0.64388671875
2023-10-12 21:02:51,805 - __main__ - INFO - Epoch [21/64], accuracy: 0.66416
2023-10-12 21:03:13,835 - __main__ - INFO - Epoch [21/64], Step [1/2503], training loss: 1.427024245262146, training accuracy: 0.6486718080548415
2023-10-12 21:04:45,484 - __main__ - INFO - Epoch [21/64], Step [101/2503], training loss: 1.4527056217193604, training accuracy: 0.64783203125
2023-10-12 21:06:28,580 - __main__ - INFO - Epoch [21/64], Step [201/2503], training loss: 1.4681099653244019, training accuracy: 0.64708984375
2023-10-12 21:08:14,715 - __main__ - INFO - Epoch [21/64], Step [301/2503], training loss: 1.5678925514221191, training accuracy: 0.64681640625
2023-10-12 21:09:53,317 - __main__ - INFO - Epoch [21/64], Step [401/2503], training loss: 1.449925184249878, training accuracy: 0.647421875
2023-10-12 21:11:35,574 - __main__ - INFO - Epoch [21/64], Step [501/2503], training loss: 1.6640428304672241, training accuracy: 0.64697265625
2023-10-12 21:13:20,681 - __main__ - INFO - Epoch [21/64], Step [601/2503], training loss: 1.5348913669586182, training accuracy: 0.6450390625
2023-10-12 21:14:58,732 - __main__ - INFO - Epoch [21/64], Step [701/2503], training loss: 1.5322071313858032, training accuracy: 0.64685546875
2023-10-12 21:16:49,000 - __main__ - INFO - Epoch [21/64], Step [801/2503], training loss: 1.4616161584854126, training accuracy: 0.65041015625
2023-10-12 21:18:25,183 - __main__ - INFO - Epoch [21/64], Step [901/2503], training loss: 1.5733356475830078, training accuracy: 0.64767578125
2023-10-12 21:19:57,472 - __main__ - INFO - Epoch [21/64], Step [1001/2503], training loss: 1.5592892169952393, training accuracy: 0.6494921875
2023-10-12 21:21:33,183 - __main__ - INFO - Epoch [21/64], Step [1101/2503], training loss: 1.3182035684585571, training accuracy: 0.6492578125
2023-10-12 21:23:16,658 - __main__ - INFO - Epoch [21/64], Step [1201/2503], training loss: 1.390882968902588, training accuracy: 0.65140625
2023-10-12 21:24:54,758 - __main__ - INFO - Epoch [21/64], Step [1301/2503], training loss: 1.4303371906280518, training accuracy: 0.645078125
2023-10-12 21:26:28,882 - __main__ - INFO - Epoch [21/64], Step [1401/2503], training loss: 1.3212502002716064, training accuracy: 0.6469140625
2023-10-12 21:27:58,150 - __main__ - INFO - Epoch [21/64], Step [1501/2503], training loss: 1.236669659614563, training accuracy: 0.64505859375
2023-10-12 21:29:38,249 - __main__ - INFO - Epoch [21/64], Step [1601/2503], training loss: 1.413647174835205, training accuracy: 0.64900390625
2023-10-12 21:31:06,757 - __main__ - INFO - Epoch [21/64], Step [1701/2503], training loss: 1.486518144607544, training accuracy: 0.64228515625
2023-10-12 21:32:42,877 - __main__ - INFO - Epoch [21/64], Step [1801/2503], training loss: 1.4646787643432617, training accuracy: 0.64849609375
2023-10-12 21:34:42,136 - __main__ - INFO - Epoch [21/64], Step [1901/2503], training loss: 1.5111349821090698, training accuracy: 0.64689453125
2023-10-12 21:36:54,992 - __main__ - INFO - Epoch [21/64], Step [2001/2503], training loss: 1.5728663206100464, training accuracy: 0.647265625
2023-10-12 21:39:15,271 - __main__ - INFO - Epoch [21/64], Step [2101/2503], training loss: 1.5836434364318848, training accuracy: 0.64740234375
2023-10-12 21:41:30,902 - __main__ - INFO - Epoch [21/64], Step [2201/2503], training loss: 1.6106312274932861, training accuracy: 0.64759765625
2023-10-12 21:43:44,427 - __main__ - INFO - Epoch [21/64], Step [2301/2503], training loss: 1.567510724067688, training accuracy: 0.649375
2023-10-12 21:46:07,926 - __main__ - INFO - Epoch [21/64], Step [2401/2503], training loss: 1.709952473640442, training accuracy: 0.64404296875
2023-10-12 21:48:17,145 - __main__ - INFO - Epoch [21/64], Step [2501/2503], training loss: 1.6587380170822144, training accuracy: 0.6433203125
2023-10-12 21:51:24,675 - __main__ - INFO - Epoch [22/64], accuracy: 0.66658
2023-10-12 21:51:44,308 - __main__ - INFO - Epoch [22/64], Step [1/2503], training loss: 1.3627073764801025, training accuracy: 0.6640959725792631
2023-10-12 21:53:40,595 - __main__ - INFO - Epoch [22/64], Step [101/2503], training loss: 1.4762839078903198, training accuracy: 0.64849609375
2023-10-12 21:55:57,546 - __main__ - INFO - Epoch [22/64], Step [201/2503], training loss: 1.6191883087158203, training accuracy: 0.64955078125
2023-10-12 21:58:16,047 - __main__ - INFO - Epoch [22/64], Step [301/2503], training loss: 1.4811850786209106, training accuracy: 0.64986328125
2023-10-12 22:00:31,504 - __main__ - INFO - Epoch [22/64], Step [401/2503], training loss: 1.423261284828186, training accuracy: 0.649375
2023-10-12 22:03:00,196 - __main__ - INFO - Epoch [22/64], Step [501/2503], training loss: 1.3153635263442993, training accuracy: 0.649140625
2023-10-12 22:05:19,700 - __main__ - INFO - Epoch [22/64], Step [601/2503], training loss: 1.5072100162506104, training accuracy: 0.64912109375
2023-10-12 22:07:49,241 - __main__ - INFO - Epoch [22/64], Step [701/2503], training loss: 1.4872418642044067, training accuracy: 0.65263671875
2023-10-12 22:10:21,372 - __main__ - INFO - Epoch [22/64], Step [801/2503], training loss: 1.5938529968261719, training accuracy: 0.64900390625
2023-10-12 22:13:04,075 - __main__ - INFO - Epoch [22/64], Step [901/2503], training loss: 1.5517486333847046, training accuracy: 0.64896484375
2023-10-12 22:15:33,546 - __main__ - INFO - Epoch [22/64], Step [1001/2503], training loss: 1.4311761856079102, training accuracy: 0.65373046875
2023-10-12 22:18:13,241 - __main__ - INFO - Epoch [22/64], Step [1101/2503], training loss: 1.440352439880371, training accuracy: 0.64552734375
2023-10-12 22:20:36,864 - __main__ - INFO - Epoch [22/64], Step [1201/2503], training loss: 1.5134673118591309, training accuracy: 0.649765625
2023-10-12 22:23:09,752 - __main__ - INFO - Epoch [22/64], Step [1301/2503], training loss: 1.4681257009506226, training accuracy: 0.65158203125
2023-10-12 22:25:39,557 - __main__ - INFO - Epoch [22/64], Step [1401/2503], training loss: 1.438605785369873, training accuracy: 0.6493359375
2023-10-12 22:28:08,560 - __main__ - INFO - Epoch [22/64], Step [1501/2503], training loss: 1.5494014024734497, training accuracy: 0.6490625
2023-10-12 22:30:32,582 - __main__ - INFO - Epoch [22/64], Step [1601/2503], training loss: 1.4498199224472046, training accuracy: 0.64763671875
2023-10-12 22:33:00,064 - __main__ - INFO - Epoch [22/64], Step [1701/2503], training loss: 1.4456100463867188, training accuracy: 0.6505078125
2023-10-12 22:35:56,444 - __main__ - INFO - Epoch [22/64], Step [1801/2503], training loss: 1.4358433485031128, training accuracy: 0.64796875
2023-10-12 22:38:29,793 - __main__ - INFO - Epoch [22/64], Step [1901/2503], training loss: 1.4323763847351074, training accuracy: 0.645703125
2023-10-12 22:40:50,128 - __main__ - INFO - Epoch [22/64], Step [2001/2503], training loss: 1.35398268699646, training accuracy: 0.6451171875
2023-10-12 22:43:14,970 - __main__ - INFO - Epoch [22/64], Step [2101/2503], training loss: 1.314405918121338, training accuracy: 0.650703125
2023-10-12 22:45:47,735 - __main__ - INFO - Epoch [22/64], Step [2201/2503], training loss: 1.5410993099212646, training accuracy: 0.64982421875
2023-10-12 22:48:15,789 - __main__ - INFO - Epoch [22/64], Step [2301/2503], training loss: 1.7131750583648682, training accuracy: 0.64640625
2023-10-12 22:50:47,145 - __main__ - INFO - Epoch [22/64], Step [2401/2503], training loss: 1.6162378787994385, training accuracy: 0.64810546875
2023-10-12 22:53:05,997 - __main__ - INFO - Epoch [22/64], Step [2501/2503], training loss: 1.570178747177124, training accuracy: 0.64453125
2023-10-12 22:56:47,876 - __main__ - INFO - Epoch [23/64], accuracy: 0.66734
2023-10-12 22:57:10,810 - __main__ - INFO - Epoch [23/64], Step [1/2503], training loss: 1.461977481842041, training accuracy: 0.6580976863753213
2023-10-12 22:59:00,966 - __main__ - INFO - Epoch [23/64], Step [101/2503], training loss: 1.3962726593017578, training accuracy: 0.6507421875
2023-10-12 23:01:25,243 - __main__ - INFO - Epoch [23/64], Step [201/2503], training loss: 1.4931479692459106, training accuracy: 0.65333984375
2023-10-12 23:03:44,861 - __main__ - INFO - Epoch [23/64], Step [301/2503], training loss: 1.508476972579956, training accuracy: 0.64923828125
2023-10-12 23:06:16,621 - __main__ - INFO - Epoch [23/64], Step [401/2503], training loss: 1.5383672714233398, training accuracy: 0.65306640625
2023-10-12 23:08:37,658 - __main__ - INFO - Epoch [23/64], Step [501/2503], training loss: 1.54552161693573, training accuracy: 0.65462890625
2023-10-12 23:10:57,718 - __main__ - INFO - Epoch [23/64], Step [601/2503], training loss: 1.3957605361938477, training accuracy: 0.64935546875
2023-10-12 23:13:21,165 - __main__ - INFO - Epoch [23/64], Step [701/2503], training loss: 1.4656174182891846, training accuracy: 0.64939453125
2023-10-12 23:15:52,604 - __main__ - INFO - Epoch [23/64], Step [801/2503], training loss: 1.5908422470092773, training accuracy: 0.65234375
2023-10-12 23:18:17,650 - __main__ - INFO - Epoch [23/64], Step [901/2503], training loss: 1.4262195825576782, training accuracy: 0.64845703125
2023-10-12 23:20:48,036 - __main__ - INFO - Epoch [23/64], Step [1001/2503], training loss: 1.3947076797485352, training accuracy: 0.653046875
2023-10-12 23:23:15,392 - __main__ - INFO - Epoch [23/64], Step [1101/2503], training loss: 1.3305528163909912, training accuracy: 0.6508203125
2023-10-12 23:25:37,674 - __main__ - INFO - Epoch [23/64], Step [1201/2503], training loss: 1.4886435270309448, training accuracy: 0.65185546875
2023-10-12 23:28:06,293 - __main__ - INFO - Epoch [23/64], Step [1301/2503], training loss: 1.483465313911438, training accuracy: 0.65404296875
2023-10-12 23:30:34,369 - __main__ - INFO - Epoch [23/64], Step [1401/2503], training loss: 1.5727574825286865, training accuracy: 0.64833984375
2023-10-12 23:32:58,560 - __main__ - INFO - Epoch [23/64], Step [1501/2503], training loss: 1.5202577114105225, training accuracy: 0.6516015625
2023-10-12 23:35:30,014 - __main__ - INFO - Epoch [23/64], Step [1601/2503], training loss: 1.6726467609405518, training accuracy: 0.64671875
2023-10-12 23:37:51,771 - __main__ - INFO - Epoch [23/64], Step [1701/2503], training loss: 1.5499051809310913, training accuracy: 0.6519140625
2023-10-12 23:40:23,045 - __main__ - INFO - Epoch [23/64], Step [1801/2503], training loss: 1.3347620964050293, training accuracy: 0.64794921875
2023-10-12 23:42:43,035 - __main__ - INFO - Epoch [23/64], Step [1901/2503], training loss: 1.3763067722320557, training accuracy: 0.65263671875
2023-10-12 23:45:05,140 - __main__ - INFO - Epoch [23/64], Step [2001/2503], training loss: 1.4385045766830444, training accuracy: 0.65248046875
2023-10-12 23:47:27,727 - __main__ - INFO - Epoch [23/64], Step [2101/2503], training loss: 1.4796696901321411, training accuracy: 0.6530078125
2023-10-12 23:49:58,205 - __main__ - INFO - Epoch [23/64], Step [2201/2503], training loss: 1.4539669752120972, training accuracy: 0.64861328125
2023-10-12 23:52:25,670 - __main__ - INFO - Epoch [23/64], Step [2301/2503], training loss: 1.3891584873199463, training accuracy: 0.6505078125
2023-10-12 23:55:00,709 - __main__ - INFO - Epoch [23/64], Step [2401/2503], training loss: 1.3477741479873657, training accuracy: 0.6516015625
2023-10-12 23:57:22,778 - __main__ - INFO - Epoch [23/64], Step [2501/2503], training loss: 1.7442904710769653, training accuracy: 0.6503125
2023-10-13 00:01:10,783 - __main__ - INFO - Epoch [24/64], accuracy: 0.66716
2023-10-13 00:01:34,289 - __main__ - INFO - Epoch [24/64], Step [1/2503], training loss: 1.5101673603057861, training accuracy: 0.6418166238217652
2023-10-13 00:03:23,921 - __main__ - INFO - Epoch [24/64], Step [101/2503], training loss: 1.4122158288955688, training accuracy: 0.65298828125
2023-10-13 00:05:54,245 - __main__ - INFO - Epoch [24/64], Step [201/2503], training loss: 1.4180192947387695, training accuracy: 0.6569921875
2023-10-13 00:08:17,913 - __main__ - INFO - Epoch [24/64], Step [301/2503], training loss: 1.5982362031936646, training accuracy: 0.6487109375
2023-10-13 00:10:38,786 - __main__ - INFO - Epoch [24/64], Step [401/2503], training loss: 1.3232053518295288, training accuracy: 0.65576171875
2023-10-13 00:13:02,013 - __main__ - INFO - Epoch [24/64], Step [501/2503], training loss: 1.4060406684875488, training accuracy: 0.6538671875
2023-10-13 00:15:37,168 - __main__ - INFO - Epoch [24/64], Step [601/2503], training loss: 1.5284395217895508, training accuracy: 0.65322265625
2023-10-13 00:17:58,417 - __main__ - INFO - Epoch [24/64], Step [701/2503], training loss: 1.4770346879959106, training accuracy: 0.65580078125
2023-10-13 00:20:24,445 - __main__ - INFO - Epoch [24/64], Step [801/2503], training loss: 1.355933666229248, training accuracy: 0.6526953125
2023-10-13 00:22:55,777 - __main__ - INFO - Epoch [24/64], Step [901/2503], training loss: 1.54233980178833, training accuracy: 0.65275390625
2023-10-13 00:25:17,592 - __main__ - INFO - Epoch [24/64], Step [1001/2503], training loss: 1.5567684173583984, training accuracy: 0.65099609375
2023-10-13 00:27:37,289 - __main__ - INFO - Epoch [24/64], Step [1101/2503], training loss: 1.4588907957077026, training accuracy: 0.6541015625
2023-10-13 00:29:51,343 - __main__ - INFO - Epoch [24/64], Step [1201/2503], training loss: 1.5930010080337524, training accuracy: 0.648359375
2023-10-13 00:32:18,864 - __main__ - INFO - Epoch [24/64], Step [1301/2503], training loss: 1.6375929117202759, training accuracy: 0.650859375
2023-10-13 00:34:42,368 - __main__ - INFO - Epoch [24/64], Step [1401/2503], training loss: 1.6048588752746582, training accuracy: 0.6558203125
2023-10-13 00:37:07,564 - __main__ - INFO - Epoch [24/64], Step [1501/2503], training loss: 1.50737464427948, training accuracy: 0.650234375
2023-10-13 00:39:37,266 - __main__ - INFO - Epoch [24/64], Step [1601/2503], training loss: 1.4500635862350464, training accuracy: 0.6548046875
2023-10-13 00:42:05,526 - __main__ - INFO - Epoch [24/64], Step [1701/2503], training loss: 1.47586989402771, training accuracy: 0.6522265625
2023-10-13 00:44:18,387 - __main__ - INFO - Epoch [24/64], Step [1801/2503], training loss: 1.5588322877883911, training accuracy: 0.6544921875
2023-10-13 00:46:31,811 - __main__ - INFO - Epoch [24/64], Step [1901/2503], training loss: 1.4201550483703613, training accuracy: 0.6530859375
2023-10-13 00:48:57,300 - __main__ - INFO - Epoch [24/64], Step [2001/2503], training loss: 1.5379517078399658, training accuracy: 0.65423828125
2023-10-13 00:51:16,825 - __main__ - INFO - Epoch [24/64], Step [2101/2503], training loss: 1.488276481628418, training accuracy: 0.6527734375
2023-10-13 00:53:36,262 - __main__ - INFO - Epoch [24/64], Step [2201/2503], training loss: 1.4050604104995728, training accuracy: 0.64921875
2023-10-13 00:55:59,918 - __main__ - INFO - Epoch [24/64], Step [2301/2503], training loss: 1.4711889028549194, training accuracy: 0.65009765625
2023-10-13 00:58:26,200 - __main__ - INFO - Epoch [24/64], Step [2401/2503], training loss: 1.4577068090438843, training accuracy: 0.6468359375
2023-10-13 01:00:43,927 - __main__ - INFO - Epoch [24/64], Step [2501/2503], training loss: 1.291802167892456, training accuracy: 0.651171875
2023-10-13 01:04:07,019 - __main__ - INFO - Epoch [25/64], accuracy: 0.66812
2023-10-13 01:04:28,989 - __main__ - INFO - Epoch [25/64], Step [1/2503], training loss: 1.5287609100341797, training accuracy: 0.6392459297343616
2023-10-13 01:06:18,882 - __main__ - INFO - Epoch [25/64], Step [101/2503], training loss: 1.460249662399292, training accuracy: 0.6571875
2023-10-13 01:08:40,316 - __main__ - INFO - Epoch [25/64], Step [201/2503], training loss: 1.461391568183899, training accuracy: 0.6518359375
2023-10-13 01:10:53,957 - __main__ - INFO - Epoch [25/64], Step [301/2503], training loss: 1.5535351037979126, training accuracy: 0.65533203125
2023-10-13 01:13:19,905 - __main__ - INFO - Epoch [25/64], Step [401/2503], training loss: 1.4479646682739258, training accuracy: 0.65662109375
2023-10-13 01:15:43,998 - __main__ - INFO - Epoch [25/64], Step [501/2503], training loss: 1.374875783920288, training accuracy: 0.65615234375
2023-10-13 01:17:52,842 - __main__ - INFO - Epoch [25/64], Step [601/2503], training loss: 1.4791266918182373, training accuracy: 0.65697265625
2023-10-13 01:20:15,563 - __main__ - INFO - Epoch [25/64], Step [701/2503], training loss: 1.446814775466919, training accuracy: 0.6536328125
2023-10-13 01:22:45,402 - __main__ - INFO - Epoch [25/64], Step [801/2503], training loss: 1.515690803527832, training accuracy: 0.6512890625
2023-10-13 01:25:18,348 - __main__ - INFO - Epoch [25/64], Step [901/2503], training loss: 1.4024100303649902, training accuracy: 0.6515625
2023-10-13 01:27:41,825 - __main__ - INFO - Epoch [25/64], Step [1001/2503], training loss: 1.5592758655548096, training accuracy: 0.65580078125
2023-10-13 01:30:13,557 - __main__ - INFO - Epoch [25/64], Step [1101/2503], training loss: 1.4460499286651611, training accuracy: 0.65203125
2023-10-13 01:32:49,973 - __main__ - INFO - Epoch [25/64], Step [1201/2503], training loss: 1.426220417022705, training accuracy: 0.654375
2023-10-13 01:35:25,266 - __main__ - INFO - Epoch [25/64], Step [1301/2503], training loss: 1.493978500366211, training accuracy: 0.655546875
2023-10-13 01:37:53,754 - __main__ - INFO - Epoch [25/64], Step [1401/2503], training loss: 1.4084510803222656, training accuracy: 0.65046875
2023-10-13 01:40:27,184 - __main__ - INFO - Epoch [25/64], Step [1501/2503], training loss: 1.436251163482666, training accuracy: 0.65154296875
2023-10-13 01:43:01,045 - __main__ - INFO - Epoch [25/64], Step [1601/2503], training loss: 1.5177158117294312, training accuracy: 0.65697265625
2023-10-13 01:45:44,167 - __main__ - INFO - Epoch [25/64], Step [1701/2503], training loss: 1.6100471019744873, training accuracy: 0.65248046875
2023-10-13 01:48:18,777 - __main__ - INFO - Epoch [25/64], Step [1801/2503], training loss: 1.4926115274429321, training accuracy: 0.6575
2023-10-13 01:50:48,359 - __main__ - INFO - Epoch [25/64], Step [1901/2503], training loss: 1.5057110786437988, training accuracy: 0.6566015625
2023-10-13 01:53:28,028 - __main__ - INFO - Epoch [25/64], Step [2001/2503], training loss: 1.3910077810287476, training accuracy: 0.6505078125
2023-10-13 01:56:25,375 - __main__ - INFO - Epoch [25/64], Step [2101/2503], training loss: 1.3873659372329712, training accuracy: 0.652109375
2023-10-13 01:59:13,328 - __main__ - INFO - Epoch [25/64], Step [2201/2503], training loss: 1.570033073425293, training accuracy: 0.6541796875
2023-10-13 02:01:52,103 - __main__ - INFO - Epoch [25/64], Step [2301/2503], training loss: 1.5838407278060913, training accuracy: 0.65544921875
2023-10-13 02:04:23,773 - __main__ - INFO - Epoch [25/64], Step [2401/2503], training loss: 1.4776898622512817, training accuracy: 0.65541015625
2023-10-13 02:06:42,853 - __main__ - INFO - Epoch [25/64], Step [2501/2503], training loss: 1.5692405700683594, training accuracy: 0.6537109375
2023-10-13 02:10:52,036 - __main__ - INFO - Epoch [26/64], accuracy: 0.67008
2023-10-13 02:11:16,147 - __main__ - INFO - Epoch [26/64], Step [1/2503], training loss: 1.5285860300064087, training accuracy: 0.6469580119965724
2023-10-13 02:13:12,053 - __main__ - INFO - Epoch [26/64], Step [101/2503], training loss: 1.3379572629928589, training accuracy: 0.658046875
2023-10-13 02:15:34,013 - __main__ - INFO - Epoch [26/64], Step [201/2503], training loss: 1.539739966392517, training accuracy: 0.66060546875
2023-10-13 02:18:17,142 - __main__ - INFO - Epoch [26/64], Step [301/2503], training loss: 1.4724559783935547, training accuracy: 0.6534765625
2023-10-13 02:21:01,597 - __main__ - INFO - Epoch [26/64], Step [401/2503], training loss: 1.362848162651062, training accuracy: 0.65705078125
2023-10-13 02:23:37,202 - __main__ - INFO - Epoch [26/64], Step [501/2503], training loss: 1.4102728366851807, training accuracy: 0.65611328125
2023-10-13 02:26:21,738 - __main__ - INFO - Epoch [26/64], Step [601/2503], training loss: 1.592000961303711, training accuracy: 0.65728515625
2023-10-13 02:29:02,578 - __main__ - INFO - Epoch [26/64], Step [701/2503], training loss: 1.4173812866210938, training accuracy: 0.65603515625
2023-10-13 02:31:42,769 - __main__ - INFO - Epoch [26/64], Step [801/2503], training loss: 1.5047956705093384, training accuracy: 0.656875
2023-10-13 02:34:19,566 - __main__ - INFO - Epoch [26/64], Step [901/2503], training loss: 1.537469744682312, training accuracy: 0.6616015625
2023-10-13 02:37:05,740 - __main__ - INFO - Epoch [26/64], Step [1001/2503], training loss: 1.3772631883621216, training accuracy: 0.6515625
2023-10-13 02:39:40,980 - __main__ - INFO - Epoch [26/64], Step [1101/2503], training loss: 1.5225106477737427, training accuracy: 0.66166015625
2023-10-13 02:42:17,844 - __main__ - INFO - Epoch [26/64], Step [1201/2503], training loss: 1.6266582012176514, training accuracy: 0.654453125
2023-10-13 02:44:53,684 - __main__ - INFO - Epoch [26/64], Step [1301/2503], training loss: 1.4902071952819824, training accuracy: 0.6553125
2023-10-13 02:47:33,160 - __main__ - INFO - Epoch [26/64], Step [1401/2503], training loss: 1.4295899868011475, training accuracy: 0.653359375
2023-10-13 02:50:15,016 - __main__ - INFO - Epoch [26/64], Step [1501/2503], training loss: 1.4690874814987183, training accuracy: 0.65779296875
2023-10-13 02:53:00,553 - __main__ - INFO - Epoch [26/64], Step [1601/2503], training loss: 1.3745783567428589, training accuracy: 0.6600390625
2023-10-13 02:55:44,562 - __main__ - INFO - Epoch [26/64], Step [1701/2503], training loss: 1.4743026494979858, training accuracy: 0.65537109375
2023-10-13 02:58:35,438 - __main__ - INFO - Epoch [26/64], Step [1801/2503], training loss: 1.4451650381088257, training accuracy: 0.6523046875
2023-10-13 03:01:20,524 - __main__ - INFO - Epoch [26/64], Step [1901/2503], training loss: 1.391247272491455, training accuracy: 0.65498046875
2023-10-13 03:03:57,046 - __main__ - INFO - Epoch [26/64], Step [2001/2503], training loss: 1.3734592199325562, training accuracy: 0.6572265625
2023-10-13 03:06:40,299 - __main__ - INFO - Epoch [26/64], Step [2101/2503], training loss: 1.3440780639648438, training accuracy: 0.65728515625
2023-10-13 03:09:32,714 - __main__ - INFO - Epoch [26/64], Step [2201/2503], training loss: 1.4735140800476074, training accuracy: 0.656484375
2023-10-13 03:12:17,420 - __main__ - INFO - Epoch [26/64], Step [2301/2503], training loss: 1.4093400239944458, training accuracy: 0.65607421875
2023-10-13 03:15:03,204 - __main__ - INFO - Epoch [26/64], Step [2401/2503], training loss: 1.582823634147644, training accuracy: 0.65958984375
2023-10-13 03:17:41,134 - __main__ - INFO - Epoch [26/64], Step [2501/2503], training loss: 1.5613601207733154, training accuracy: 0.6548046875
2023-10-13 03:22:15,036 - __main__ - INFO - Epoch [27/64], accuracy: 0.67192
2023-10-13 03:22:40,236 - __main__ - INFO - Epoch [27/64], Step [1/2503], training loss: 1.3502886295318604, training accuracy: 0.6546700942587832
2023-10-13 03:25:06,532 - __main__ - INFO - Epoch [27/64], Step [101/2503], training loss: 1.4568719863891602, training accuracy: 0.66111328125
2023-10-13 03:27:46,846 - __main__ - INFO - Epoch [27/64], Step [201/2503], training loss: 1.5162997245788574, training accuracy: 0.655546875
2023-10-13 03:30:25,836 - __main__ - INFO - Epoch [27/64], Step [301/2503], training loss: 1.4695615768432617, training accuracy: 0.6577734375
2023-10-13 03:33:11,783 - __main__ - INFO - Epoch [27/64], Step [401/2503], training loss: 1.4375059604644775, training accuracy: 0.655625
2023-10-13 03:35:52,848 - __main__ - INFO - Epoch [27/64], Step [501/2503], training loss: 1.507399559020996, training accuracy: 0.65662109375
2023-10-13 03:38:30,627 - __main__ - INFO - Epoch [27/64], Step [601/2503], training loss: 1.4254921674728394, training accuracy: 0.6561328125
2023-10-13 03:41:11,270 - __main__ - INFO - Epoch [27/64], Step [701/2503], training loss: 1.406162142753601, training accuracy: 0.6580859375
2023-10-13 03:43:41,388 - __main__ - INFO - Epoch [27/64], Step [801/2503], training loss: 1.3305696249008179, training accuracy: 0.65818359375
2023-10-13 03:46:29,356 - __main__ - INFO - Epoch [27/64], Step [901/2503], training loss: 1.5392576456069946, training accuracy: 0.659375
2023-10-13 03:48:58,931 - __main__ - INFO - Epoch [27/64], Step [1001/2503], training loss: 1.4947160482406616, training accuracy: 0.6589453125
2023-10-13 03:51:22,155 - __main__ - INFO - Epoch [27/64], Step [1101/2503], training loss: 1.4231637716293335, training accuracy: 0.65720703125
2023-10-13 03:54:05,598 - __main__ - INFO - Epoch [27/64], Step [1201/2503], training loss: 1.6121394634246826, training accuracy: 0.65875
2023-10-13 03:56:33,158 - __main__ - INFO - Epoch [27/64], Step [1301/2503], training loss: 1.4596079587936401, training accuracy: 0.65650390625
2023-10-13 03:59:00,598 - __main__ - INFO - Epoch [27/64], Step [1401/2503], training loss: 1.4755570888519287, training accuracy: 0.6572265625
2023-10-13 04:01:37,780 - __main__ - INFO - Epoch [27/64], Step [1501/2503], training loss: 1.363482117652893, training accuracy: 0.659140625
2023-10-13 04:04:11,836 - __main__ - INFO - Epoch [27/64], Step [1601/2503], training loss: 1.5119445323944092, training accuracy: 0.65568359375
2023-10-13 04:06:41,618 - __main__ - INFO - Epoch [27/64], Step [1701/2503], training loss: 1.3666595220565796, training accuracy: 0.65716796875
2023-10-13 04:09:16,293 - __main__ - INFO - Epoch [27/64], Step [1801/2503], training loss: 1.3816407918930054, training accuracy: 0.6626953125
2023-10-13 04:11:48,475 - __main__ - INFO - Epoch [27/64], Step [1901/2503], training loss: 1.5322179794311523, training accuracy: 0.65828125
2023-10-13 04:14:30,631 - __main__ - INFO - Epoch [27/64], Step [2001/2503], training loss: 1.4765996932983398, training accuracy: 0.66248046875
2023-10-13 04:17:03,028 - __main__ - INFO - Epoch [27/64], Step [2101/2503], training loss: 1.4983563423156738, training accuracy: 0.6555859375
2023-10-13 04:19:39,798 - __main__ - INFO - Epoch [27/64], Step [2201/2503], training loss: 1.4083200693130493, training accuracy: 0.65294921875
2023-10-13 04:22:10,381 - __main__ - INFO - Epoch [27/64], Step [2301/2503], training loss: 1.4736332893371582, training accuracy: 0.6569140625
2023-10-13 04:24:54,764 - __main__ - INFO - Epoch [27/64], Step [2401/2503], training loss: 1.3216819763183594, training accuracy: 0.6546484375
2023-10-13 04:27:07,001 - __main__ - INFO - Epoch [27/64], Step [2501/2503], training loss: 1.3751438856124878, training accuracy: 0.65400390625
2023-10-13 04:30:46,993 - __main__ - INFO - Epoch [28/64], accuracy: 0.67228
2023-10-13 04:31:09,586 - __main__ - INFO - Epoch [28/64], Step [1/2503], training loss: 1.4287163019180298, training accuracy: 0.6692373607540703
2023-10-13 04:33:18,809 - __main__ - INFO - Epoch [28/64], Step [101/2503], training loss: 1.545638918876648, training accuracy: 0.6621875
2023-10-13 04:35:45,374 - __main__ - INFO - Epoch [28/64], Step [201/2503], training loss: 1.3720533847808838, training accuracy: 0.65884765625
2023-10-13 04:38:03,815 - __main__ - INFO - Epoch [28/64], Step [301/2503], training loss: 1.4268999099731445, training accuracy: 0.663046875
2023-10-13 04:40:29,045 - __main__ - INFO - Epoch [28/64], Step [401/2503], training loss: 1.3037481307983398, training accuracy: 0.65791015625
2023-10-13 04:42:48,874 - __main__ - INFO - Epoch [28/64], Step [501/2503], training loss: 1.486640453338623, training accuracy: 0.65912109375
2023-10-13 04:45:11,324 - __main__ - INFO - Epoch [28/64], Step [601/2503], training loss: 1.570080280303955, training accuracy: 0.65869140625
2023-10-13 04:47:44,170 - __main__ - INFO - Epoch [28/64], Step [701/2503], training loss: 1.4673206806182861, training accuracy: 0.66287109375
2023-10-13 04:50:18,988 - __main__ - INFO - Epoch [28/64], Step [801/2503], training loss: 1.412010908126831, training accuracy: 0.66302734375
2023-10-13 04:52:45,531 - __main__ - INFO - Epoch [28/64], Step [901/2503], training loss: 1.5383330583572388, training accuracy: 0.6608984375
2023-10-13 04:55:16,121 - __main__ - INFO - Epoch [28/64], Step [1001/2503], training loss: 1.583138108253479, training accuracy: 0.6566796875
2023-10-13 04:57:39,908 - __main__ - INFO - Epoch [28/64], Step [1101/2503], training loss: 1.4859027862548828, training accuracy: 0.65724609375
2023-10-13 05:00:12,328 - __main__ - INFO - Epoch [28/64], Step [1201/2503], training loss: 1.6327487230300903, training accuracy: 0.658828125
2023-10-13 05:02:33,858 - __main__ - INFO - Epoch [28/64], Step [1301/2503], training loss: 1.3931102752685547, training accuracy: 0.6590625
2023-10-13 05:05:03,138 - __main__ - INFO - Epoch [28/64], Step [1401/2503], training loss: 1.487018346786499, training accuracy: 0.65865234375
2023-10-13 05:07:25,875 - __main__ - INFO - Epoch [28/64], Step [1501/2503], training loss: 1.4394935369491577, training accuracy: 0.65837890625
2023-10-13 05:09:57,037 - __main__ - INFO - Epoch [28/64], Step [1601/2503], training loss: 1.573587417602539, training accuracy: 0.6585546875
2023-10-13 05:12:23,611 - __main__ - INFO - Epoch [28/64], Step [1701/2503], training loss: 1.498816967010498, training accuracy: 0.66048828125
2023-10-13 05:14:54,678 - __main__ - INFO - Epoch [28/64], Step [1801/2503], training loss: 1.3143492937088013, training accuracy: 0.65634765625
2023-10-13 05:17:22,548 - __main__ - INFO - Epoch [28/64], Step [1901/2503], training loss: 1.6000635623931885, training accuracy: 0.65923828125
2023-10-13 05:20:01,887 - __main__ - INFO - Epoch [28/64], Step [2001/2503], training loss: 1.525349497795105, training accuracy: 0.66107421875
2023-10-13 05:22:32,914 - __main__ - INFO - Epoch [28/64], Step [2101/2503], training loss: 1.5240164995193481, training accuracy: 0.6590625
2023-10-13 05:25:02,049 - __main__ - INFO - Epoch [28/64], Step [2201/2503], training loss: 1.47621750831604, training accuracy: 0.6588671875
2023-10-13 05:27:29,860 - __main__ - INFO - Epoch [28/64], Step [2301/2503], training loss: 1.4466334581375122, training accuracy: 0.65943359375
2023-10-13 05:30:08,803 - __main__ - INFO - Epoch [28/64], Step [2401/2503], training loss: 1.4547650814056396, training accuracy: 0.6594140625
2023-10-13 05:32:29,155 - __main__ - INFO - Epoch [28/64], Step [2501/2503], training loss: 1.496974229812622, training accuracy: 0.65818359375
2023-10-13 05:36:02,130 - __main__ - INFO - Epoch [29/64], accuracy: 0.67234
2023-10-13 05:36:22,681 - __main__ - INFO - Epoch [29/64], Step [1/2503], training loss: 1.5634005069732666, training accuracy: 0.6683804627249358
2023-10-13 05:38:13,367 - __main__ - INFO - Epoch [29/64], Step [101/2503], training loss: 1.7336077690124512, training accuracy: 0.65896484375
2023-10-13 05:40:07,414 - __main__ - INFO - Epoch [29/64], Step [201/2503], training loss: 1.412086009979248, training accuracy: 0.66029296875
2023-10-13 05:42:01,396 - __main__ - INFO - Epoch [29/64], Step [301/2503], training loss: 1.4675695896148682, training accuracy: 0.66029296875
2023-10-13 05:44:31,204 - __main__ - INFO - Epoch [29/64], Step [401/2503], training loss: 1.595415472984314, training accuracy: 0.6646484375
2023-10-13 05:47:07,168 - __main__ - INFO - Epoch [29/64], Step [501/2503], training loss: 1.3389228582382202, training accuracy: 0.6598828125
2023-10-13 05:49:36,376 - __main__ - INFO - Epoch [29/64], Step [601/2503], training loss: 1.4717988967895508, training accuracy: 0.660546875
2023-10-13 05:52:01,159 - __main__ - INFO - Epoch [29/64], Step [701/2503], training loss: 1.3764920234680176, training accuracy: 0.66322265625
2023-10-13 05:54:30,298 - __main__ - INFO - Epoch [29/64], Step [801/2503], training loss: 1.427794337272644, training accuracy: 0.65861328125
2023-10-13 05:57:04,356 - __main__ - INFO - Epoch [29/64], Step [901/2503], training loss: 1.56252920627594, training accuracy: 0.6602734375
2023-10-13 05:59:28,179 - __main__ - INFO - Epoch [29/64], Step [1001/2503], training loss: 1.4196938276290894, training accuracy: 0.66248046875
2023-10-13 06:01:58,263 - __main__ - INFO - Epoch [29/64], Step [1101/2503], training loss: 1.437612771987915, training accuracy: 0.66029296875
2023-10-13 06:04:36,596 - __main__ - INFO - Epoch [29/64], Step [1201/2503], training loss: 1.4348335266113281, training accuracy: 0.6667578125
2023-10-13 06:07:10,327 - __main__ - INFO - Epoch [29/64], Step [1301/2503], training loss: 1.4670605659484863, training accuracy: 0.6610546875
2023-10-13 06:09:37,968 - __main__ - INFO - Epoch [29/64], Step [1401/2503], training loss: 1.5284792184829712, training accuracy: 0.6605859375
2023-10-13 06:12:12,861 - __main__ - INFO - Epoch [29/64], Step [1501/2503], training loss: 1.4271116256713867, training accuracy: 0.66154296875
2023-10-13 06:14:36,186 - __main__ - INFO - Epoch [29/64], Step [1601/2503], training loss: 1.4840315580368042, training accuracy: 0.66119140625
2023-10-13 06:16:59,411 - __main__ - INFO - Epoch [29/64], Step [1701/2503], training loss: 1.4969242811203003, training accuracy: 0.65884765625
2023-10-13 06:19:18,634 - __main__ - INFO - Epoch [29/64], Step [1801/2503], training loss: 1.3632266521453857, training accuracy: 0.66154296875
2023-10-13 06:21:51,062 - __main__ - INFO - Epoch [29/64], Step [1901/2503], training loss: 1.4637647867202759, training accuracy: 0.6616015625
2023-10-13 06:24:18,035 - __main__ - INFO - Epoch [29/64], Step [2001/2503], training loss: 1.488830804824829, training accuracy: 0.66087890625
2023-10-13 06:26:44,152 - __main__ - INFO - Epoch [29/64], Step [2101/2503], training loss: 1.425614595413208, training accuracy: 0.656953125
2023-10-13 06:29:10,629 - __main__ - INFO - Epoch [29/64], Step [2201/2503], training loss: 1.4175059795379639, training accuracy: 0.65923828125
2023-10-13 06:31:48,342 - __main__ - INFO - Epoch [29/64], Step [2301/2503], training loss: 1.4457347393035889, training accuracy: 0.663359375
2023-10-13 06:34:13,719 - __main__ - INFO - Epoch [29/64], Step [2401/2503], training loss: 1.4411216974258423, training accuracy: 0.65939453125
2023-10-13 06:36:19,905 - __main__ - INFO - Epoch [29/64], Step [2501/2503], training loss: 1.4743812084197998, training accuracy: 0.65873046875
2023-10-13 06:40:01,485 - __main__ - INFO - Epoch [30/64], accuracy: 0.67318
2023-10-13 06:40:22,077 - __main__ - INFO - Epoch [30/64], Step [1/2503], training loss: 1.2272309064865112, training accuracy: 0.6812339331619537
2023-10-13 06:42:24,145 - __main__ - INFO - Epoch [30/64], Step [101/2503], training loss: 1.4308204650878906, training accuracy: 0.661796875
2023-10-13 06:44:45,060 - __main__ - INFO - Epoch [30/64], Step [201/2503], training loss: 1.3111399412155151, training accuracy: 0.6657421875
2023-10-13 06:47:01,746 - __main__ - INFO - Epoch [30/64], Step [301/2503], training loss: 1.3766790628433228, training accuracy: 0.66490234375
2023-10-13 06:49:23,362 - __main__ - INFO - Epoch [30/64], Step [401/2503], training loss: 1.3671176433563232, training accuracy: 0.66123046875
2023-10-13 06:51:40,563 - __main__ - INFO - Epoch [30/64], Step [501/2503], training loss: 1.3443490266799927, training accuracy: 0.66052734375
2023-10-13 06:53:58,450 - __main__ - INFO - Epoch [30/64], Step [601/2503], training loss: 1.3751376867294312, training accuracy: 0.66203125
2023-10-13 06:56:27,536 - __main__ - INFO - Epoch [30/64], Step [701/2503], training loss: 1.472146987915039, training accuracy: 0.661640625
2023-10-13 06:58:49,474 - __main__ - INFO - Epoch [30/64], Step [801/2503], training loss: 1.3628323078155518, training accuracy: 0.6608984375
2023-10-13 07:01:24,414 - __main__ - INFO - Epoch [30/64], Step [901/2503], training loss: 1.500598669052124, training accuracy: 0.66310546875
2023-10-13 07:03:50,246 - __main__ - INFO - Epoch [30/64], Step [1001/2503], training loss: 1.2939339876174927, training accuracy: 0.66650390625
2023-10-13 07:06:33,244 - __main__ - INFO - Epoch [30/64], Step [1101/2503], training loss: 1.3966403007507324, training accuracy: 0.6625390625
2023-10-13 07:09:05,319 - __main__ - INFO - Epoch [30/64], Step [1201/2503], training loss: 1.5273343324661255, training accuracy: 0.66068359375
2023-10-13 07:11:33,074 - __main__ - INFO - Epoch [30/64], Step [1301/2503], training loss: 1.4709402322769165, training accuracy: 0.66287109375
2023-10-13 07:14:03,628 - __main__ - INFO - Epoch [30/64], Step [1401/2503], training loss: 1.370121717453003, training accuracy: 0.66234375
2023-10-13 07:16:34,077 - __main__ - INFO - Epoch [30/64], Step [1501/2503], training loss: 1.5269957780838013, training accuracy: 0.66365234375
2023-10-13 07:19:00,755 - __main__ - INFO - Epoch [30/64], Step [1601/2503], training loss: 1.4911324977874756, training accuracy: 0.66236328125
2023-10-13 07:21:32,264 - __main__ - INFO - Epoch [30/64], Step [1701/2503], training loss: 1.5431127548217773, training accuracy: 0.66283203125
2023-10-13 07:24:01,831 - __main__ - INFO - Epoch [30/64], Step [1801/2503], training loss: 1.4292747974395752, training accuracy: 0.6644140625
2023-10-13 07:26:33,701 - __main__ - INFO - Epoch [30/64], Step [1901/2503], training loss: 1.5492146015167236, training accuracy: 0.66087890625
2023-10-13 07:29:00,306 - __main__ - INFO - Epoch [30/64], Step [2001/2503], training loss: 1.5104548931121826, training accuracy: 0.659921875
2023-10-13 07:31:24,024 - __main__ - INFO - Epoch [30/64], Step [2101/2503], training loss: 1.4738624095916748, training accuracy: 0.66115234375
2023-10-13 07:33:51,640 - __main__ - INFO - Epoch [30/64], Step [2201/2503], training loss: 1.4679441452026367, training accuracy: 0.65955078125
2023-10-13 07:36:13,170 - __main__ - INFO - Epoch [30/64], Step [2301/2503], training loss: 1.4156296253204346, training accuracy: 0.6604296875
2023-10-13 07:38:41,866 - __main__ - INFO - Epoch [30/64], Step [2401/2503], training loss: 1.3766776323318481, training accuracy: 0.66189453125
2023-10-13 07:40:56,595 - __main__ - INFO - Epoch [30/64], Step [2501/2503], training loss: 1.3851600885391235, training accuracy: 0.66232421875
2023-10-13 07:44:36,867 - __main__ - INFO - Epoch [31/64], accuracy: 0.67464
2023-10-13 07:44:59,497 - __main__ - INFO - Epoch [31/64], Step [1/2503], training loss: 1.5885366201400757, training accuracy: 0.6640959725792631
2023-10-13 07:47:04,571 - __main__ - INFO - Epoch [31/64], Step [101/2503], training loss: 1.5068016052246094, training accuracy: 0.66427734375
2023-10-13 07:49:28,934 - __main__ - INFO - Epoch [31/64], Step [201/2503], training loss: 1.4316235780715942, training accuracy: 0.66779296875
2023-10-13 07:51:51,129 - __main__ - INFO - Epoch [31/64], Step [301/2503], training loss: 1.2831693887710571, training accuracy: 0.66431640625
2023-10-13 07:54:12,521 - __main__ - INFO - Epoch [31/64], Step [401/2503], training loss: 1.3733528852462769, training accuracy: 0.6658203125
2023-10-13 07:56:35,371 - __main__ - INFO - Epoch [31/64], Step [501/2503], training loss: 1.4311003684997559, training accuracy: 0.66466796875
2023-10-13 07:59:07,605 - __main__ - INFO - Epoch [31/64], Step [601/2503], training loss: 1.3078081607818604, training accuracy: 0.66947265625
2023-10-13 08:01:31,481 - __main__ - INFO - Epoch [31/64], Step [701/2503], training loss: 1.495419979095459, training accuracy: 0.66642578125
2023-10-13 08:03:54,350 - __main__ - INFO - Epoch [31/64], Step [801/2503], training loss: 1.513784408569336, training accuracy: 0.6674609375
2023-10-13 08:06:17,177 - __main__ - INFO - Epoch [31/64], Step [901/2503], training loss: 1.4418952465057373, training accuracy: 0.669609375
2023-10-13 08:08:44,672 - __main__ - INFO - Epoch [31/64], Step [1001/2503], training loss: 1.3567670583724976, training accuracy: 0.6694140625
2023-10-13 08:11:10,834 - __main__ - INFO - Epoch [31/64], Step [1101/2503], training loss: 1.364990234375, training accuracy: 0.67109375
2023-10-13 08:13:32,175 - __main__ - INFO - Epoch [31/64], Step [1201/2503], training loss: 1.4943420886993408, training accuracy: 0.6669921875
2023-10-13 08:15:56,443 - __main__ - INFO - Epoch [31/64], Step [1301/2503], training loss: 1.5006386041641235, training accuracy: 0.66732421875
2023-10-13 08:18:22,955 - __main__ - INFO - Epoch [31/64], Step [1401/2503], training loss: 1.428167700767517, training accuracy: 0.6688671875
2023-10-13 08:20:53,511 - __main__ - INFO - Epoch [31/64], Step [1501/2503], training loss: 1.5117907524108887, training accuracy: 0.668671875
2023-10-13 08:23:20,163 - __main__ - INFO - Epoch [31/64], Step [1601/2503], training loss: 1.332598328590393, training accuracy: 0.66990234375
2023-10-13 08:25:44,981 - __main__ - INFO - Epoch [31/64], Step [1701/2503], training loss: 1.3484439849853516, training accuracy: 0.66912109375
2023-10-13 08:28:16,395 - __main__ - INFO - Epoch [31/64], Step [1801/2503], training loss: 1.4502087831497192, training accuracy: 0.67318359375
2023-10-13 08:30:51,958 - __main__ - INFO - Epoch [31/64], Step [1901/2503], training loss: 1.1873778104782104, training accuracy: 0.665859375
2023-10-13 08:33:13,842 - __main__ - INFO - Epoch [31/64], Step [2001/2503], training loss: 1.518462896347046, training accuracy: 0.6656640625
2023-10-13 08:35:39,751 - __main__ - INFO - Epoch [31/64], Step [2101/2503], training loss: 1.4239109754562378, training accuracy: 0.66724609375
2023-10-13 08:38:08,434 - __main__ - INFO - Epoch [31/64], Step [2201/2503], training loss: 1.3750828504562378, training accuracy: 0.66849609375
2023-10-13 08:40:48,536 - __main__ - INFO - Epoch [31/64], Step [2301/2503], training loss: 1.5083403587341309, training accuracy: 0.66939453125
2023-10-13 08:43:16,217 - __main__ - INFO - Epoch [31/64], Step [2401/2503], training loss: 1.469923496246338, training accuracy: 0.6692578125
2023-10-13 08:45:40,708 - __main__ - INFO - Epoch [31/64], Step [2501/2503], training loss: 1.509178638458252, training accuracy: 0.66658203125
2023-10-13 08:49:17,754 - __main__ - INFO - Epoch [32/64], accuracy: 0.67884
2023-10-13 08:49:42,092 - __main__ - INFO - Epoch [32/64], Step [1/2503], training loss: 1.3097655773162842, training accuracy: 0.6700942587832048
2023-10-13 08:51:50,573 - __main__ - INFO - Epoch [32/64], Step [101/2503], training loss: 1.5945063829421997, training accuracy: 0.6693359375
2023-10-13 08:54:21,387 - __main__ - INFO - Epoch [32/64], Step [201/2503], training loss: 1.3159621953964233, training accuracy: 0.66845703125
2023-10-13 08:56:46,308 - __main__ - INFO - Epoch [32/64], Step [301/2503], training loss: 1.3823599815368652, training accuracy: 0.66927734375
2023-10-13 08:59:07,475 - __main__ - INFO - Epoch [32/64], Step [401/2503], training loss: 1.3367764949798584, training accuracy: 0.66875
2023-10-13 09:01:41,619 - __main__ - INFO - Epoch [32/64], Step [501/2503], training loss: 1.441633939743042, training accuracy: 0.6693359375
2023-10-13 09:04:14,419 - __main__ - INFO - Epoch [32/64], Step [601/2503], training loss: 1.4849920272827148, training accuracy: 0.66681640625
2023-10-13 09:06:40,900 - __main__ - INFO - Epoch [32/64], Step [701/2503], training loss: 1.4530986547470093, training accuracy: 0.66759765625
2023-10-13 09:09:17,570 - __main__ - INFO - Epoch [32/64], Step [801/2503], training loss: 1.3647964000701904, training accuracy: 0.66673828125
2023-10-13 09:11:45,944 - __main__ - INFO - Epoch [32/64], Step [901/2503], training loss: 1.3629329204559326, training accuracy: 0.67154296875
2023-10-13 09:14:17,002 - __main__ - INFO - Epoch [32/64], Step [1001/2503], training loss: 1.3014190196990967, training accuracy: 0.672265625
2023-10-13 09:16:46,341 - __main__ - INFO - Epoch [32/64], Step [1101/2503], training loss: 1.2695956230163574, training accuracy: 0.6723828125
2023-10-13 09:19:11,104 - __main__ - INFO - Epoch [32/64], Step [1201/2503], training loss: 1.262091040611267, training accuracy: 0.66626953125
2023-10-13 09:21:39,764 - __main__ - INFO - Epoch [32/64], Step [1301/2503], training loss: 1.3696383237838745, training accuracy: 0.6734375
2023-10-13 09:24:10,616 - __main__ - INFO - Epoch [32/64], Step [1401/2503], training loss: 1.453334093093872, training accuracy: 0.668984375
2023-10-13 09:26:39,582 - __main__ - INFO - Epoch [32/64], Step [1501/2503], training loss: 1.2781651020050049, training accuracy: 0.6705859375
2023-10-13 09:29:07,181 - __main__ - INFO - Epoch [32/64], Step [1601/2503], training loss: 1.2701729536056519, training accuracy: 0.66806640625
2023-10-13 09:31:41,456 - __main__ - INFO - Epoch [32/64], Step [1701/2503], training loss: 1.2283378839492798, training accuracy: 0.67044921875
2023-10-13 09:34:12,645 - __main__ - INFO - Epoch [32/64], Step [1801/2503], training loss: 1.3525588512420654, training accuracy: 0.66833984375
2023-10-13 09:36:43,079 - __main__ - INFO - Epoch [32/64], Step [1901/2503], training loss: 1.5424391031265259, training accuracy: 0.67146484375
2023-10-13 09:39:08,068 - __main__ - INFO - Epoch [32/64], Step [2001/2503], training loss: 1.2977224588394165, training accuracy: 0.66869140625
2023-10-13 09:41:47,930 - __main__ - INFO - Epoch [32/64], Step [2101/2503], training loss: 1.3943066596984863, training accuracy: 0.6671484375
2023-10-13 09:44:25,788 - __main__ - INFO - Epoch [32/64], Step [2201/2503], training loss: 1.4713852405548096, training accuracy: 0.6696484375
2023-10-13 09:46:59,596 - __main__ - INFO - Epoch [32/64], Step [2301/2503], training loss: 1.3604462146759033, training accuracy: 0.66865234375
2023-10-13 09:49:42,062 - __main__ - INFO - Epoch [32/64], Step [2401/2503], training loss: 1.4870483875274658, training accuracy: 0.6725
2023-10-13 09:52:31,177 - __main__ - INFO - Epoch [32/64], Step [2501/2503], training loss: 1.4845476150512695, training accuracy: 0.6696875
2023-10-13 09:57:03,997 - __main__ - INFO - Epoch [33/64], accuracy: 0.67986
2023-10-13 09:57:29,756 - __main__ - INFO - Epoch [33/64], Step [1/2503], training loss: 1.4821603298187256, training accuracy: 0.6872322193658955
2023-10-13 09:59:46,668 - __main__ - INFO - Epoch [33/64], Step [101/2503], training loss: 1.394899845123291, training accuracy: 0.670703125
2023-10-13 10:02:23,470 - __main__ - INFO - Epoch [33/64], Step [201/2503], training loss: 1.3831106424331665, training accuracy: 0.6672265625
2023-10-13 10:04:49,724 - __main__ - INFO - Epoch [33/64], Step [301/2503], training loss: 1.410967230796814, training accuracy: 0.67041015625
2023-10-13 10:07:33,332 - __main__ - INFO - Epoch [33/64], Step [401/2503], training loss: 1.216416597366333, training accuracy: 0.6708984375
2023-10-13 10:10:13,017 - __main__ - INFO - Epoch [33/64], Step [501/2503], training loss: 1.5999430418014526, training accuracy: 0.6684765625
2023-10-13 10:12:43,588 - __main__ - INFO - Epoch [33/64], Step [601/2503], training loss: 1.4238334894180298, training accuracy: 0.67361328125
2023-10-13 10:15:15,687 - __main__ - INFO - Epoch [33/64], Step [701/2503], training loss: 1.432334065437317, training accuracy: 0.6675390625
2023-10-13 10:17:56,745 - __main__ - INFO - Epoch [33/64], Step [801/2503], training loss: 1.261549711227417, training accuracy: 0.66841796875
2023-10-13 10:20:36,443 - __main__ - INFO - Epoch [33/64], Step [901/2503], training loss: 1.3223414421081543, training accuracy: 0.6693359375
2023-10-13 10:23:21,309 - __main__ - INFO - Epoch [33/64], Step [1001/2503], training loss: 1.4691756963729858, training accuracy: 0.669765625
2023-10-13 10:26:06,387 - __main__ - INFO - Epoch [33/64], Step [1101/2503], training loss: 1.4155528545379639, training accuracy: 0.67326171875
2023-10-13 10:29:10,530 - __main__ - INFO - Epoch [33/64], Step [1201/2503], training loss: 1.2548162937164307, training accuracy: 0.67498046875
2023-10-13 10:31:52,342 - __main__ - INFO - Epoch [33/64], Step [1301/2503], training loss: 1.4069485664367676, training accuracy: 0.67166015625
2023-10-13 10:34:35,805 - __main__ - INFO - Epoch [33/64], Step [1401/2503], training loss: 1.4128801822662354, training accuracy: 0.67162109375
2023-10-13 10:37:23,168 - __main__ - INFO - Epoch [33/64], Step [1501/2503], training loss: 1.329845905303955, training accuracy: 0.6704296875
2023-10-13 10:40:11,298 - __main__ - INFO - Epoch [33/64], Step [1601/2503], training loss: 1.3901703357696533, training accuracy: 0.6670703125
2023-10-13 10:42:51,629 - __main__ - INFO - Epoch [33/64], Step [1701/2503], training loss: 1.5124361515045166, training accuracy: 0.6697265625
2023-10-13 10:45:30,701 - __main__ - INFO - Epoch [33/64], Step [1801/2503], training loss: 1.3254731893539429, training accuracy: 0.6709375
2023-10-13 10:48:09,276 - __main__ - INFO - Epoch [33/64], Step [1901/2503], training loss: 1.4784479141235352, training accuracy: 0.66876953125
2023-10-13 10:51:04,446 - __main__ - INFO - Epoch [33/64], Step [2001/2503], training loss: 1.4711203575134277, training accuracy: 0.66947265625
2023-10-13 10:53:54,693 - __main__ - INFO - Epoch [33/64], Step [2101/2503], training loss: 1.4623003005981445, training accuracy: 0.6660546875
2023-10-13 10:56:45,432 - __main__ - INFO - Epoch [33/64], Step [2201/2503], training loss: 1.3870177268981934, training accuracy: 0.666875
2023-10-13 10:59:47,589 - __main__ - INFO - Epoch [33/64], Step [2301/2503], training loss: 1.267612099647522, training accuracy: 0.6716015625
2023-10-13 11:03:04,738 - __main__ - INFO - Epoch [33/64], Step [2401/2503], training loss: 1.423866868019104, training accuracy: 0.669609375
2023-10-13 11:05:36,720 - __main__ - INFO - Epoch [33/64], Step [2501/2503], training loss: 1.2700334787368774, training accuracy: 0.67205078125
2023-10-13 11:09:26,147 - __main__ - INFO - Epoch [34/64], accuracy: 0.67804
2023-10-13 11:09:46,976 - __main__ - INFO - Epoch [34/64], Step [1/2503], training loss: 1.3000837564468384, training accuracy: 0.6760925449871465
2023-10-13 11:12:03,721 - __main__ - INFO - Epoch [34/64], Step [101/2503], training loss: 1.5550748109817505, training accuracy: 0.6726171875
2023-10-13 11:14:38,511 - __main__ - INFO - Epoch [34/64], Step [201/2503], training loss: 1.4676909446716309, training accuracy: 0.66869140625
2023-10-13 11:17:40,990 - __main__ - INFO - Epoch [34/64], Step [301/2503], training loss: 1.461928367614746, training accuracy: 0.6681640625
2023-10-13 11:21:05,633 - __main__ - INFO - Epoch [34/64], Step [401/2503], training loss: 1.521762728691101, training accuracy: 0.67044921875
2023-10-13 11:23:56,720 - __main__ - INFO - Epoch [34/64], Step [501/2503], training loss: 1.567625880241394, training accuracy: 0.67078125
2023-10-13 11:26:47,220 - __main__ - INFO - Epoch [34/64], Step [601/2503], training loss: 1.379438042640686, training accuracy: 0.67259765625
2023-10-13 11:29:36,575 - __main__ - INFO - Epoch [34/64], Step [701/2503], training loss: 1.4269311428070068, training accuracy: 0.66935546875
2023-10-13 11:32:41,332 - __main__ - INFO - Epoch [34/64], Step [801/2503], training loss: 1.315902829170227, training accuracy: 0.66740234375
2023-10-13 11:35:37,189 - __main__ - INFO - Epoch [34/64], Step [901/2503], training loss: 1.4916434288024902, training accuracy: 0.66953125
2023-10-13 11:38:30,998 - __main__ - INFO - Epoch [34/64], Step [1001/2503], training loss: 1.4781639575958252, training accuracy: 0.67322265625
2023-10-13 11:41:27,984 - __main__ - INFO - Epoch [34/64], Step [1101/2503], training loss: 1.3894397020339966, training accuracy: 0.667890625
2023-10-13 11:44:22,339 - __main__ - INFO - Epoch [34/64], Step [1201/2503], training loss: 1.3360238075256348, training accuracy: 0.66826171875
2023-10-13 11:47:13,758 - __main__ - INFO - Epoch [34/64], Step [1301/2503], training loss: 1.349926471710205, training accuracy: 0.67064453125
2023-10-13 11:50:03,397 - __main__ - INFO - Epoch [34/64], Step [1401/2503], training loss: 1.49843430519104, training accuracy: 0.6713671875
2023-10-13 11:52:41,734 - __main__ - INFO - Epoch [34/64], Step [1501/2503], training loss: 1.3689182996749878, training accuracy: 0.67072265625
2023-10-13 11:55:38,504 - __main__ - INFO - Epoch [34/64], Step [1601/2503], training loss: 1.2846447229385376, training accuracy: 0.673515625
2023-10-13 11:58:54,012 - __main__ - INFO - Epoch [34/64], Step [1701/2503], training loss: 1.3395090103149414, training accuracy: 0.67216796875
2023-10-13 12:02:03,520 - __main__ - INFO - Epoch [34/64], Step [1801/2503], training loss: 1.4837315082550049, training accuracy: 0.67181640625
2023-10-13 12:05:10,746 - __main__ - INFO - Epoch [34/64], Step [1901/2503], training loss: 1.3150861263275146, training accuracy: 0.673125
2023-10-13 12:08:00,709 - __main__ - INFO - Epoch [34/64], Step [2001/2503], training loss: 1.3984708786010742, training accuracy: 0.6689453125
2023-10-13 12:10:54,954 - __main__ - INFO - Epoch [34/64], Step [2101/2503], training loss: 1.4584590196609497, training accuracy: 0.66970703125
2023-10-13 12:13:29,461 - __main__ - INFO - Epoch [34/64], Step [2201/2503], training loss: 1.3545727729797363, training accuracy: 0.67134765625
2023-10-13 12:16:12,098 - __main__ - INFO - Epoch [34/64], Step [2301/2503], training loss: 1.375667691230774, training accuracy: 0.67044921875
2023-10-13 12:19:05,876 - __main__ - INFO - Epoch [34/64], Step [2401/2503], training loss: 1.302036166191101, training accuracy: 0.67015625
2023-10-13 12:22:08,385 - __main__ - INFO - Epoch [34/64], Step [2501/2503], training loss: 1.4652174711227417, training accuracy: 0.6697265625
2023-10-13 12:27:37,228 - __main__ - INFO - Epoch [35/64], accuracy: 0.67812
2023-10-13 12:28:06,993 - __main__ - INFO - Epoch [35/64], Step [1/2503], training loss: 1.3230177164077759, training accuracy: 0.6649528706083976
2023-10-13 12:30:33,911 - __main__ - INFO - Epoch [35/64], Step [101/2503], training loss: 1.5105605125427246, training accuracy: 0.66779296875
2023-10-13 12:33:15,825 - __main__ - INFO - Epoch [35/64], Step [201/2503], training loss: 1.3374255895614624, training accuracy: 0.67326171875
2023-10-13 12:35:49,637 - __main__ - INFO - Epoch [35/64], Step [301/2503], training loss: 1.4197502136230469, training accuracy: 0.66771484375
2023-10-13 12:38:32,075 - __main__ - INFO - Epoch [35/64], Step [401/2503], training loss: 1.3756475448608398, training accuracy: 0.66763671875
2023-10-13 12:41:18,896 - __main__ - INFO - Epoch [35/64], Step [501/2503], training loss: 1.4680331945419312, training accuracy: 0.66994140625
2023-10-13 12:44:01,934 - __main__ - INFO - Epoch [35/64], Step [601/2503], training loss: 1.3156023025512695, training accuracy: 0.67130859375
2023-10-13 12:46:40,600 - __main__ - INFO - Epoch [35/64], Step [701/2503], training loss: 1.3621573448181152, training accuracy: 0.67216796875
2023-10-13 12:49:10,230 - __main__ - INFO - Epoch [35/64], Step [801/2503], training loss: 1.408870816230774, training accuracy: 0.66873046875
2023-10-13 12:51:39,517 - __main__ - INFO - Epoch [35/64], Step [901/2503], training loss: 1.4844539165496826, training accuracy: 0.67244140625
2023-10-13 12:54:03,460 - __main__ - INFO - Epoch [35/64], Step [1001/2503], training loss: 1.3350557088851929, training accuracy: 0.66982421875
2023-10-13 12:56:17,873 - __main__ - INFO - Epoch [35/64], Step [1101/2503], training loss: 1.35256826877594, training accuracy: 0.66806640625
2023-10-13 12:58:33,580 - __main__ - INFO - Epoch [35/64], Step [1201/2503], training loss: 1.355329155921936, training accuracy: 0.67466796875
2023-10-13 13:00:57,071 - __main__ - INFO - Epoch [35/64], Step [1301/2503], training loss: 1.4203622341156006, training accuracy: 0.667578125
2023-10-13 13:03:20,408 - __main__ - INFO - Epoch [35/64], Step [1401/2503], training loss: 1.40089750289917, training accuracy: 0.67015625
2023-10-13 13:05:51,471 - __main__ - INFO - Epoch [35/64], Step [1501/2503], training loss: 1.3993635177612305, training accuracy: 0.672578125
2023-10-13 13:08:11,056 - __main__ - INFO - Epoch [35/64], Step [1601/2503], training loss: 1.4924843311309814, training accuracy: 0.6716015625
2023-10-13 13:10:27,690 - __main__ - INFO - Epoch [35/64], Step [1701/2503], training loss: 1.3886048793792725, training accuracy: 0.669296875
2023-10-13 13:12:52,747 - __main__ - INFO - Epoch [35/64], Step [1801/2503], training loss: 1.4037446975708008, training accuracy: 0.6665625
2023-10-13 13:15:12,994 - __main__ - INFO - Epoch [35/64], Step [1901/2503], training loss: 1.277967095375061, training accuracy: 0.6706640625
2023-10-13 13:17:40,495 - __main__ - INFO - Epoch [35/64], Step [2001/2503], training loss: 1.3754546642303467, training accuracy: 0.6684765625
2023-10-13 13:20:03,227 - __main__ - INFO - Epoch [35/64], Step [2101/2503], training loss: 1.4102723598480225, training accuracy: 0.6727734375
2023-10-13 13:22:24,455 - __main__ - INFO - Epoch [35/64], Step [2201/2503], training loss: 1.523927927017212, training accuracy: 0.675625
2023-10-13 13:24:49,815 - __main__ - INFO - Epoch [35/64], Step [2301/2503], training loss: 1.4807939529418945, training accuracy: 0.67115234375
2023-10-13 13:27:15,136 - __main__ - INFO - Epoch [35/64], Step [2401/2503], training loss: 1.4234877824783325, training accuracy: 0.67341796875
2023-10-13 13:29:28,193 - __main__ - INFO - Epoch [35/64], Step [2501/2503], training loss: 1.4316810369491577, training accuracy: 0.6726953125
2023-10-13 13:32:59,115 - __main__ - INFO - Epoch [36/64], accuracy: 0.67938
2023-10-13 13:33:18,906 - __main__ - INFO - Epoch [36/64], Step [1/2503], training loss: 1.4291414022445679, training accuracy: 0.6718080548414739
2023-10-13 13:34:53,361 - __main__ - INFO - Epoch [36/64], Step [101/2503], training loss: 1.4716131687164307, training accuracy: 0.66732421875
2023-10-13 13:36:31,959 - __main__ - INFO - Epoch [36/64], Step [201/2503], training loss: 1.562088966369629, training accuracy: 0.67208984375
2023-10-13 13:38:15,179 - __main__ - INFO - Epoch [36/64], Step [301/2503], training loss: 1.4133871793746948, training accuracy: 0.670234375
2023-10-13 13:40:32,278 - __main__ - INFO - Epoch [36/64], Step [401/2503], training loss: 1.2498329877853394, training accuracy: 0.66927734375
2023-10-13 13:42:49,505 - __main__ - INFO - Epoch [36/64], Step [501/2503], training loss: 1.3915945291519165, training accuracy: 0.67158203125
2023-10-13 13:45:02,262 - __main__ - INFO - Epoch [36/64], Step [601/2503], training loss: 1.3906538486480713, training accuracy: 0.67287109375
2023-10-13 13:47:14,997 - __main__ - INFO - Epoch [36/64], Step [701/2503], training loss: 1.438291072845459, training accuracy: 0.67375
2023-10-13 13:49:21,238 - __main__ - INFO - Epoch [36/64], Step [801/2503], training loss: 1.3503572940826416, training accuracy: 0.6721484375
2023-10-13 13:51:33,485 - __main__ - INFO - Epoch [36/64], Step [901/2503], training loss: 1.5016330480575562, training accuracy: 0.6710546875
2023-10-13 13:53:48,346 - __main__ - INFO - Epoch [36/64], Step [1001/2503], training loss: 1.408894419670105, training accuracy: 0.67134765625
2023-10-13 13:55:51,651 - __main__ - INFO - Epoch [36/64], Step [1101/2503], training loss: 1.3522001504898071, training accuracy: 0.674140625
2023-10-13 13:58:01,922 - __main__ - INFO - Epoch [36/64], Step [1201/2503], training loss: 1.3220393657684326, training accuracy: 0.671875
2023-10-13 14:00:18,618 - __main__ - INFO - Epoch [36/64], Step [1301/2503], training loss: 1.4546359777450562, training accuracy: 0.672421875
2023-10-13 14:02:33,209 - __main__ - INFO - Epoch [36/64], Step [1401/2503], training loss: 1.4734468460083008, training accuracy: 0.672578125
2023-10-13 14:04:46,023 - __main__ - INFO - Epoch [36/64], Step [1501/2503], training loss: 1.3924840688705444, training accuracy: 0.6694140625
2023-10-13 14:07:02,952 - __main__ - INFO - Epoch [36/64], Step [1601/2503], training loss: 1.3493040800094604, training accuracy: 0.6730078125
2023-10-13 14:09:26,139 - __main__ - INFO - Epoch [36/64], Step [1701/2503], training loss: 1.3200808763504028, training accuracy: 0.6726953125
2023-10-13 14:11:35,125 - __main__ - INFO - Epoch [36/64], Step [1801/2503], training loss: 1.4640389680862427, training accuracy: 0.67314453125
2023-10-13 14:13:38,307 - __main__ - INFO - Epoch [36/64], Step [1901/2503], training loss: 1.51960027217865, training accuracy: 0.671328125
2023-10-13 14:15:43,666 - __main__ - INFO - Epoch [36/64], Step [2001/2503], training loss: 1.3766981363296509, training accuracy: 0.67287109375
2023-10-13 14:17:56,148 - __main__ - INFO - Epoch [36/64], Step [2101/2503], training loss: 1.3221473693847656, training accuracy: 0.6694921875
2023-10-13 14:20:01,705 - __main__ - INFO - Epoch [36/64], Step [2201/2503], training loss: 1.4539554119110107, training accuracy: 0.6712890625
2023-10-13 14:22:03,542 - __main__ - INFO - Epoch [36/64], Step [2301/2503], training loss: 1.2217826843261719, training accuracy: 0.67294921875
2023-10-13 14:24:09,841 - __main__ - INFO - Epoch [36/64], Step [2401/2503], training loss: 1.5118255615234375, training accuracy: 0.666171875
2023-10-13 14:25:56,591 - __main__ - INFO - Epoch [36/64], Step [2501/2503], training loss: 1.3038034439086914, training accuracy: 0.66728515625
2023-10-13 14:28:48,054 - __main__ - INFO - Epoch [37/64], accuracy: 0.6793
2023-10-13 14:29:03,696 - __main__ - INFO - Epoch [37/64], Step [1/2503], training loss: 1.4822365045547485, training accuracy: 0.6778063410454156
2023-10-13 14:30:22,638 - __main__ - INFO - Epoch [37/64], Step [101/2503], training loss: 1.332578420639038, training accuracy: 0.6707421875
2023-10-13 14:31:34,042 - __main__ - INFO - Epoch [37/64], Step [201/2503], training loss: 1.5230704545974731, training accuracy: 0.67123046875
2023-10-13 14:32:58,042 - __main__ - INFO - Epoch [37/64], Step [301/2503], training loss: 1.3424103260040283, training accuracy: 0.67341796875
2023-10-13 14:34:22,257 - __main__ - INFO - Epoch [37/64], Step [401/2503], training loss: 1.364387035369873, training accuracy: 0.67125
2023-10-13 14:35:48,036 - __main__ - INFO - Epoch [37/64], Step [501/2503], training loss: 1.3213368654251099, training accuracy: 0.67462890625
2023-10-13 14:37:14,428 - __main__ - INFO - Epoch [37/64], Step [601/2503], training loss: 1.4589616060256958, training accuracy: 0.6712109375
2023-10-13 14:38:41,298 - __main__ - INFO - Epoch [37/64], Step [701/2503], training loss: 1.4493621587753296, training accuracy: 0.66826171875
2023-10-13 14:40:13,787 - __main__ - INFO - Epoch [37/64], Step [801/2503], training loss: 1.5299265384674072, training accuracy: 0.6712109375
2023-10-13 14:41:39,910 - __main__ - INFO - Epoch [37/64], Step [901/2503], training loss: 1.5735487937927246, training accuracy: 0.6746875
2023-10-13 14:43:13,728 - __main__ - INFO - Epoch [37/64], Step [1001/2503], training loss: 1.3733985424041748, training accuracy: 0.67294921875
2023-10-13 14:44:43,431 - __main__ - INFO - Epoch [37/64], Step [1101/2503], training loss: 1.4560896158218384, training accuracy: 0.67220703125
2023-10-13 14:46:29,479 - __main__ - INFO - Epoch [37/64], Step [1201/2503], training loss: 1.4355244636535645, training accuracy: 0.67060546875
2023-10-13 14:48:32,124 - __main__ - INFO - Epoch [37/64], Step [1301/2503], training loss: 1.4164445400238037, training accuracy: 0.67099609375
2023-10-13 14:50:44,700 - __main__ - INFO - Epoch [37/64], Step [1401/2503], training loss: 1.3868719339370728, training accuracy: 0.6728125
2023-10-13 14:52:52,603 - __main__ - INFO - Epoch [37/64], Step [1501/2503], training loss: 1.393178939819336, training accuracy: 0.67044921875
2023-10-13 14:55:06,224 - __main__ - INFO - Epoch [37/64], Step [1601/2503], training loss: 1.300352931022644, training accuracy: 0.66935546875
2023-10-13 14:57:22,268 - __main__ - INFO - Epoch [37/64], Step [1701/2503], training loss: 1.3866255283355713, training accuracy: 0.6692578125
2023-10-13 14:59:33,839 - __main__ - INFO - Epoch [37/64], Step [1801/2503], training loss: 1.3759535551071167, training accuracy: 0.66970703125
2023-10-13 15:01:39,420 - __main__ - INFO - Epoch [37/64], Step [1901/2503], training loss: 1.3008811473846436, training accuracy: 0.66763671875
2023-10-13 15:03:55,040 - __main__ - INFO - Epoch [37/64], Step [2001/2503], training loss: 1.4324049949645996, training accuracy: 0.66966796875
2023-10-13 15:06:07,407 - __main__ - INFO - Epoch [37/64], Step [2101/2503], training loss: 1.4151479005813599, training accuracy: 0.6698046875
2023-10-13 15:08:19,114 - __main__ - INFO - Epoch [37/64], Step [2201/2503], training loss: 1.3632454872131348, training accuracy: 0.67119140625
2023-10-13 15:10:29,153 - __main__ - INFO - Epoch [37/64], Step [2301/2503], training loss: 1.2924578189849854, training accuracy: 0.67212890625
2023-10-13 15:12:52,305 - __main__ - INFO - Epoch [37/64], Step [2401/2503], training loss: 1.4950042963027954, training accuracy: 0.67044921875
2023-10-13 15:14:40,349 - __main__ - INFO - Epoch [37/64], Step [2501/2503], training loss: 1.3981157541275024, training accuracy: 0.6689453125
2023-10-13 15:17:34,107 - __main__ - INFO - Epoch [38/64], accuracy: 0.6793
2023-10-13 15:17:50,337 - __main__ - INFO - Epoch [38/64], Step [1/2503], training loss: 1.3298474550247192, training accuracy: 0.6889460154241646
2023-10-13 15:19:18,035 - __main__ - INFO - Epoch [38/64], Step [101/2503], training loss: 1.4110686779022217, training accuracy: 0.67025390625
2023-10-13 15:20:42,728 - __main__ - INFO - Epoch [38/64], Step [201/2503], training loss: 1.5833901166915894, training accuracy: 0.6719140625
2023-10-13 15:22:12,167 - __main__ - INFO - Epoch [38/64], Step [301/2503], training loss: 1.3958556652069092, training accuracy: 0.66958984375
2023-10-13 15:23:49,398 - __main__ - INFO - Epoch [38/64], Step [401/2503], training loss: 1.3703643083572388, training accuracy: 0.66880859375
2023-10-13 15:25:25,899 - __main__ - INFO - Epoch [38/64], Step [501/2503], training loss: 1.4712302684783936, training accuracy: 0.671796875
2023-10-13 15:26:58,012 - __main__ - INFO - Epoch [38/64], Step [601/2503], training loss: 1.5686272382736206, training accuracy: 0.6716796875
2023-10-13 15:28:30,539 - __main__ - INFO - Epoch [38/64], Step [701/2503], training loss: 1.4238442182540894, training accuracy: 0.66966796875
2023-10-13 15:30:09,197 - __main__ - INFO - Epoch [38/64], Step [801/2503], training loss: 1.62306547164917, training accuracy: 0.67001953125
2023-10-13 15:32:16,116 - __main__ - INFO - Epoch [38/64], Step [901/2503], training loss: 1.4158954620361328, training accuracy: 0.67291015625
2023-10-13 15:34:23,891 - __main__ - INFO - Epoch [38/64], Step [1001/2503], training loss: 1.36970055103302, training accuracy: 0.67033203125
2023-10-13 15:36:33,291 - __main__ - INFO - Epoch [38/64], Step [1101/2503], training loss: 1.416702151298523, training accuracy: 0.667890625
2023-10-13 15:38:42,898 - __main__ - INFO - Epoch [38/64], Step [1201/2503], training loss: 1.5347821712493896, training accuracy: 0.670546875
2023-10-13 15:41:05,152 - __main__ - INFO - Epoch [38/64], Step [1301/2503], training loss: 1.4073134660720825, training accuracy: 0.66798828125
2023-10-13 15:43:16,742 - __main__ - INFO - Epoch [38/64], Step [1401/2503], training loss: 1.2840064764022827, training accuracy: 0.67283203125
2023-10-13 15:45:30,334 - __main__ - INFO - Epoch [38/64], Step [1501/2503], training loss: 1.3967362642288208, training accuracy: 0.67181640625
2023-10-13 15:47:43,215 - __main__ - INFO - Epoch [38/64], Step [1601/2503], training loss: 1.4798740148544312, training accuracy: 0.6714453125
2023-10-13 15:49:54,552 - __main__ - INFO - Epoch [38/64], Step [1701/2503], training loss: 1.391132116317749, training accuracy: 0.67283203125
2023-10-13 15:52:09,648 - __main__ - INFO - Epoch [38/64], Step [1801/2503], training loss: 1.5155500173568726, training accuracy: 0.67271484375
2023-10-13 15:54:21,339 - __main__ - INFO - Epoch [38/64], Step [1901/2503], training loss: 1.4307500123977661, training accuracy: 0.67146484375
2023-10-13 15:56:32,498 - __main__ - INFO - Epoch [38/64], Step [2001/2503], training loss: 1.344590425491333, training accuracy: 0.67041015625
2023-10-13 15:58:55,333 - __main__ - INFO - Epoch [38/64], Step [2101/2503], training loss: 1.4789283275604248, training accuracy: 0.67154296875
2023-10-13 16:01:06,328 - __main__ - INFO - Epoch [38/64], Step [2201/2503], training loss: 1.4542369842529297, training accuracy: 0.6698046875
2023-10-13 16:03:20,962 - __main__ - INFO - Epoch [38/64], Step [2301/2503], training loss: 1.361332654953003, training accuracy: 0.67412109375
2023-10-13 16:05:27,590 - __main__ - INFO - Epoch [38/64], Step [2401/2503], training loss: 1.392577886581421, training accuracy: 0.67041015625
2023-10-13 16:07:23,720 - __main__ - INFO - Epoch [38/64], Step [2501/2503], training loss: 1.2986841201782227, training accuracy: 0.67353515625
2023-10-13 16:10:15,977 - __main__ - INFO - Epoch [39/64], accuracy: 0.67998
2023-10-13 16:10:33,692 - __main__ - INFO - Epoch [39/64], Step [1/2503], training loss: 1.3794536590576172, training accuracy: 0.6846615252784919
2023-10-13 16:12:14,627 - __main__ - INFO - Epoch [39/64], Step [101/2503], training loss: 1.383575201034546, training accuracy: 0.67203125
2023-10-13 16:14:22,314 - __main__ - INFO - Epoch [39/64], Step [201/2503], training loss: 1.359493613243103, training accuracy: 0.6719921875
2023-10-13 16:16:33,581 - __main__ - INFO - Epoch [39/64], Step [301/2503], training loss: 1.3338403701782227, training accuracy: 0.6728125
2023-10-13 16:18:51,400 - __main__ - INFO - Epoch [39/64], Step [401/2503], training loss: 1.502107858657837, training accuracy: 0.671875
2023-10-13 16:20:53,450 - __main__ - INFO - Epoch [39/64], Step [501/2503], training loss: 1.32054603099823, training accuracy: 0.67197265625
2023-10-13 16:22:57,811 - __main__ - INFO - Epoch [39/64], Step [601/2503], training loss: 1.1683895587921143, training accuracy: 0.6738671875
2023-10-13 16:25:09,752 - __main__ - INFO - Epoch [39/64], Step [701/2503], training loss: 1.2461354732513428, training accuracy: 0.6696484375
2023-10-13 16:27:47,288 - __main__ - INFO - Epoch [39/64], Step [801/2503], training loss: 1.3360623121261597, training accuracy: 0.67408203125
2023-10-13 16:30:45,740 - __main__ - INFO - Epoch [39/64], Step [901/2503], training loss: 1.4916603565216064, training accuracy: 0.6687109375
2023-10-13 16:33:44,693 - __main__ - INFO - Epoch [39/64], Step [1001/2503], training loss: 1.286447286605835, training accuracy: 0.67291015625
2023-10-13 16:36:57,951 - __main__ - INFO - Epoch [39/64], Step [1101/2503], training loss: 1.4169541597366333, training accuracy: 0.6715625
2023-10-13 16:40:21,498 - __main__ - INFO - Epoch [39/64], Step [1201/2503], training loss: 1.417901635169983, training accuracy: 0.67025390625
2023-10-13 16:43:47,056 - __main__ - INFO - Epoch [39/64], Step [1301/2503], training loss: 1.3630939722061157, training accuracy: 0.67197265625
2023-10-13 16:47:18,721 - __main__ - INFO - Epoch [39/64], Step [1401/2503], training loss: 1.4344266653060913, training accuracy: 0.67275390625
2023-10-13 16:50:32,220 - __main__ - INFO - Epoch [39/64], Step [1501/2503], training loss: 1.41146719455719, training accuracy: 0.6713671875
2023-10-13 16:54:30,264 - __main__ - INFO - Epoch [39/64], Step [1601/2503], training loss: 1.2512015104293823, training accuracy: 0.673125
2023-10-13 16:58:00,350 - __main__ - INFO - Epoch [39/64], Step [1701/2503], training loss: 1.4357753992080688, training accuracy: 0.673671875
2023-10-13 17:01:33,512 - __main__ - INFO - Epoch [39/64], Step [1801/2503], training loss: 1.3465632200241089, training accuracy: 0.6716015625
2023-10-13 17:05:02,931 - __main__ - INFO - Epoch [39/64], Step [1901/2503], training loss: 1.4015110731124878, training accuracy: 0.6730859375
2023-10-13 17:09:04,206 - __main__ - INFO - Epoch [39/64], Step [2001/2503], training loss: 1.512689232826233, training accuracy: 0.6679296875
2023-10-13 17:12:50,670 - __main__ - INFO - Epoch [39/64], Step [2101/2503], training loss: 1.433838963508606, training accuracy: 0.6710546875
2023-10-13 17:16:37,651 - __main__ - INFO - Epoch [39/64], Step [2201/2503], training loss: 1.4231995344161987, training accuracy: 0.67068359375
2023-10-13 17:20:39,447 - __main__ - INFO - Epoch [39/64], Step [2301/2503], training loss: 1.4534608125686646, training accuracy: 0.66978515625
2023-10-13 17:24:53,910 - __main__ - INFO - Epoch [39/64], Step [2401/2503], training loss: 1.3540157079696655, training accuracy: 0.67150390625
2023-10-13 17:28:35,959 - __main__ - INFO - Epoch [39/64], Step [2501/2503], training loss: 1.4542654752731323, training accuracy: 0.67283203125
2023-10-13 17:35:46,474 - __main__ - INFO - Epoch [40/64], accuracy: 0.67988
2023-10-13 17:36:23,684 - __main__ - INFO - Epoch [40/64], Step [1/2503], training loss: 1.4504883289337158, training accuracy: 0.6649528706083976
2023-10-13 17:39:31,970 - __main__ - INFO - Epoch [40/64], Step [101/2503], training loss: 1.367541790008545, training accuracy: 0.67271484375
2023-10-13 17:42:27,668 - __main__ - INFO - Epoch [40/64], Step [201/2503], training loss: 1.2822890281677246, training accuracy: 0.67078125
2023-10-13 17:45:16,707 - __main__ - INFO - Epoch [40/64], Step [301/2503], training loss: 1.4179021120071411, training accuracy: 0.67115234375
2023-10-13 17:47:58,706 - __main__ - INFO - Epoch [40/64], Step [401/2503], training loss: 1.338202714920044, training accuracy: 0.66984375
2023-10-13 17:50:33,719 - __main__ - INFO - Epoch [40/64], Step [501/2503], training loss: 1.4185765981674194, training accuracy: 0.67205078125
2023-10-13 17:52:50,813 - __main__ - INFO - Epoch [40/64], Step [601/2503], training loss: 1.39778733253479, training accuracy: 0.6687109375
2023-10-13 17:54:59,029 - __main__ - INFO - Epoch [40/64], Step [701/2503], training loss: 1.4567639827728271, training accuracy: 0.66724609375
2023-10-13 17:57:38,093 - __main__ - INFO - Epoch [40/64], Step [801/2503], training loss: 1.3701506853103638, training accuracy: 0.67099609375
2023-10-13 18:00:13,376 - __main__ - INFO - Epoch [40/64], Step [901/2503], training loss: 1.414381504058838, training accuracy: 0.673203125
2023-10-13 18:02:50,612 - __main__ - INFO - Epoch [40/64], Step [1001/2503], training loss: 1.3289064168930054, training accuracy: 0.67349609375
2023-10-13 18:05:19,774 - __main__ - INFO - Epoch [40/64], Step [1101/2503], training loss: 1.4626832008361816, training accuracy: 0.672734375
2023-10-13 18:07:36,590 - __main__ - INFO - Epoch [40/64], Step [1201/2503], training loss: 1.2949999570846558, training accuracy: 0.67107421875
2023-10-13 18:10:07,751 - __main__ - INFO - Epoch [40/64], Step [1301/2503], training loss: 1.46329665184021, training accuracy: 0.6741015625
2023-10-13 18:12:45,274 - __main__ - INFO - Epoch [40/64], Step [1401/2503], training loss: 1.2597384452819824, training accuracy: 0.671796875
2023-10-13 18:15:19,821 - __main__ - INFO - Epoch [40/64], Step [1501/2503], training loss: 1.4031585454940796, training accuracy: 0.67126953125
2023-10-13 18:17:51,325 - __main__ - INFO - Epoch [40/64], Step [1601/2503], training loss: 1.3592350482940674, training accuracy: 0.67015625
2023-10-13 18:20:32,286 - __main__ - INFO - Epoch [40/64], Step [1701/2503], training loss: 1.4822428226470947, training accuracy: 0.66787109375
2023-10-13 18:23:05,971 - __main__ - INFO - Epoch [40/64], Step [1801/2503], training loss: 1.3177871704101562, training accuracy: 0.6713671875
2023-10-13 18:25:38,912 - __main__ - INFO - Epoch [40/64], Step [1901/2503], training loss: 1.3721100091934204, training accuracy: 0.6758984375
2023-10-13 18:28:04,170 - __main__ - INFO - Epoch [40/64], Step [2001/2503], training loss: 1.4380170106887817, training accuracy: 0.6734765625
2023-10-13 18:30:29,654 - __main__ - INFO - Epoch [40/64], Step [2101/2503], training loss: 1.3732351064682007, training accuracy: 0.67044921875
2023-10-13 18:33:08,267 - __main__ - INFO - Epoch [40/64], Step [2201/2503], training loss: 1.3928903341293335, training accuracy: 0.67029296875
2023-10-13 18:35:34,701 - __main__ - INFO - Epoch [40/64], Step [2301/2503], training loss: 1.416663408279419, training accuracy: 0.67109375
2023-10-13 18:38:07,513 - __main__ - INFO - Epoch [40/64], Step [2401/2503], training loss: 1.477560043334961, training accuracy: 0.6736328125
2023-10-13 18:40:32,902 - __main__ - INFO - Epoch [40/64], Step [2501/2503], training loss: 1.5548086166381836, training accuracy: 0.67208984375
2023-10-13 18:45:27,873 - __main__ - INFO - Epoch [41/64], accuracy: 0.67848
2023-10-13 18:45:49,972 - __main__ - INFO - Epoch [41/64], Step [1/2503], training loss: 1.479500651359558, training accuracy: 0.6675235646958012
2023-10-13 18:47:34,392 - __main__ - INFO - Epoch [41/64], Step [101/2503], training loss: 1.5789397954940796, training accuracy: 0.670625
2023-10-13 18:49:13,217 - __main__ - INFO - Epoch [41/64], Step [201/2503], training loss: 1.1910396814346313, training accuracy: 0.67359375
2023-10-13 18:50:59,555 - __main__ - INFO - Epoch [41/64], Step [301/2503], training loss: 1.3316718339920044, training accuracy: 0.67013671875
2023-10-13 18:52:46,857 - __main__ - INFO - Epoch [41/64], Step [401/2503], training loss: 1.4717962741851807, training accuracy: 0.66716796875
2023-10-13 18:54:39,044 - __main__ - INFO - Epoch [41/64], Step [501/2503], training loss: 1.3948276042938232, training accuracy: 0.6719921875
2023-10-13 18:56:25,059 - __main__ - INFO - Epoch [41/64], Step [601/2503], training loss: 1.441191554069519, training accuracy: 0.67150390625
2023-10-13 18:58:27,081 - __main__ - INFO - Epoch [41/64], Step [701/2503], training loss: 1.2411733865737915, training accuracy: 0.67208984375
2023-10-13 19:00:55,664 - __main__ - INFO - Epoch [41/64], Step [801/2503], training loss: 1.2820146083831787, training accuracy: 0.671328125
2023-10-13 19:03:12,313 - __main__ - INFO - Epoch [41/64], Step [901/2503], training loss: 1.4128637313842773, training accuracy: 0.67357421875
2023-10-13 19:05:36,318 - __main__ - INFO - Epoch [41/64], Step [1001/2503], training loss: 1.240049958229065, training accuracy: 0.672109375
2023-10-13 19:07:59,148 - __main__ - INFO - Epoch [41/64], Step [1101/2503], training loss: 1.265896201133728, training accuracy: 0.67208984375
2023-10-13 19:10:29,289 - __main__ - INFO - Epoch [41/64], Step [1201/2503], training loss: 1.3620269298553467, training accuracy: 0.67509765625
2023-10-13 19:12:57,667 - __main__ - INFO - Epoch [41/64], Step [1301/2503], training loss: 1.393944263458252, training accuracy: 0.67236328125
2023-10-13 19:15:16,163 - __main__ - INFO - Epoch [41/64], Step [1401/2503], training loss: 1.2302510738372803, training accuracy: 0.670390625
2023-10-13 19:17:55,124 - __main__ - INFO - Epoch [41/64], Step [1501/2503], training loss: 1.2950875759124756, training accuracy: 0.6693359375
2023-10-13 19:20:22,891 - __main__ - INFO - Epoch [41/64], Step [1601/2503], training loss: 1.4617109298706055, training accuracy: 0.66994140625
2023-10-13 19:22:51,942 - __main__ - INFO - Epoch [41/64], Step [1701/2503], training loss: 1.4299650192260742, training accuracy: 0.6699609375
2023-10-13 19:25:18,367 - __main__ - INFO - Epoch [41/64], Step [1801/2503], training loss: 1.4731128215789795, training accuracy: 0.67369140625
2023-10-13 19:27:45,454 - __main__ - INFO - Epoch [41/64], Step [1901/2503], training loss: 1.4171370267868042, training accuracy: 0.66884765625
2023-10-13 19:30:10,862 - __main__ - INFO - Epoch [41/64], Step [2001/2503], training loss: 1.387288212776184, training accuracy: 0.67451171875
2023-10-13 19:32:48,672 - __main__ - INFO - Epoch [41/64], Step [2101/2503], training loss: 1.2807058095932007, training accuracy: 0.6726171875
2023-10-13 19:35:17,120 - __main__ - INFO - Epoch [41/64], Step [2201/2503], training loss: 1.3857027292251587, training accuracy: 0.666328125
2023-10-13 19:37:51,748 - __main__ - INFO - Epoch [41/64], Step [2301/2503], training loss: 1.4108890295028687, training accuracy: 0.6694140625
2023-10-13 19:40:17,740 - __main__ - INFO - Epoch [41/64], Step [2401/2503], training loss: 1.5315431356430054, training accuracy: 0.67205078125
2023-10-13 19:42:37,939 - __main__ - INFO - Epoch [41/64], Step [2501/2503], training loss: 1.4325129985809326, training accuracy: 0.671796875
2023-10-13 19:46:16,195 - __main__ - INFO - Epoch [42/64], accuracy: 0.68078
2023-10-13 19:46:35,024 - __main__ - INFO - Epoch [42/64], Step [1/2503], training loss: 1.4907739162445068, training accuracy: 0.6640959725792631
2023-10-13 19:48:34,404 - __main__ - INFO - Epoch [42/64], Step [101/2503], training loss: 1.4700193405151367, training accuracy: 0.6735546875
2023-10-13 19:50:47,424 - __main__ - INFO - Epoch [42/64], Step [201/2503], training loss: 1.227494478225708, training accuracy: 0.67451171875
2023-10-13 19:53:09,000 - __main__ - INFO - Epoch [42/64], Step [301/2503], training loss: 1.4845775365829468, training accuracy: 0.67193359375
2023-10-13 19:55:26,048 - __main__ - INFO - Epoch [42/64], Step [401/2503], training loss: 1.4253238439559937, training accuracy: 0.6763671875
2023-10-13 19:57:48,118 - __main__ - INFO - Epoch [42/64], Step [501/2503], training loss: 1.4352803230285645, training accuracy: 0.67208984375
2023-10-13 20:00:14,707 - __main__ - INFO - Epoch [42/64], Step [601/2503], training loss: 1.4493536949157715, training accuracy: 0.6713671875
2023-10-13 20:02:36,234 - __main__ - INFO - Epoch [42/64], Step [701/2503], training loss: 1.4064072370529175, training accuracy: 0.67404296875
2023-10-13 20:04:53,827 - __main__ - INFO - Epoch [42/64], Step [801/2503], training loss: 1.4473210573196411, training accuracy: 0.671484375
2023-10-13 20:07:20,899 - __main__ - INFO - Epoch [42/64], Step [901/2503], training loss: 1.1932827234268188, training accuracy: 0.67296875
2023-10-13 20:09:41,177 - __main__ - INFO - Epoch [42/64], Step [1001/2503], training loss: 1.468513011932373, training accuracy: 0.672890625
2023-10-13 20:11:59,065 - __main__ - INFO - Epoch [42/64], Step [1101/2503], training loss: 1.450112223625183, training accuracy: 0.67384765625
2023-10-13 20:14:15,363 - __main__ - INFO - Epoch [42/64], Step [1201/2503], training loss: 1.3544642925262451, training accuracy: 0.67126953125
2023-10-13 20:16:46,040 - __main__ - INFO - Epoch [42/64], Step [1301/2503], training loss: 1.371523141860962, training accuracy: 0.66970703125
2023-10-13 20:19:19,596 - __main__ - INFO - Epoch [42/64], Step [1401/2503], training loss: 1.3256702423095703, training accuracy: 0.67662109375
2023-10-13 20:21:56,753 - __main__ - INFO - Epoch [42/64], Step [1501/2503], training loss: 1.3057316541671753, training accuracy: 0.6733203125
2023-10-13 20:24:32,215 - __main__ - INFO - Epoch [42/64], Step [1601/2503], training loss: 1.3392164707183838, training accuracy: 0.6734765625
2023-10-13 20:27:09,766 - __main__ - INFO - Epoch [42/64], Step [1701/2503], training loss: 1.3113144636154175, training accuracy: 0.67451171875
2023-10-13 20:29:40,969 - __main__ - INFO - Epoch [42/64], Step [1801/2503], training loss: 1.2341668605804443, training accuracy: 0.6705859375
2023-10-13 20:32:14,596 - __main__ - INFO - Epoch [42/64], Step [1901/2503], training loss: 1.6779574155807495, training accuracy: 0.67322265625
2023-10-13 20:34:53,252 - __main__ - INFO - Epoch [42/64], Step [2001/2503], training loss: 1.4314597845077515, training accuracy: 0.6719921875
2023-10-13 20:37:34,903 - __main__ - INFO - Epoch [42/64], Step [2101/2503], training loss: 1.4299300909042358, training accuracy: 0.66986328125
2023-10-13 20:40:14,939 - __main__ - INFO - Epoch [42/64], Step [2201/2503], training loss: 1.4846618175506592, training accuracy: 0.67064453125
2023-10-13 20:43:07,366 - __main__ - INFO - Epoch [42/64], Step [2301/2503], training loss: 1.2055737972259521, training accuracy: 0.669609375
2023-10-13 20:46:09,297 - __main__ - INFO - Epoch [42/64], Step [2401/2503], training loss: 1.28944993019104, training accuracy: 0.67341796875
2023-10-13 20:48:46,800 - __main__ - INFO - Epoch [42/64], Step [2501/2503], training loss: 1.293572187423706, training accuracy: 0.6696484375
2023-10-13 20:52:49,416 - __main__ - INFO - Epoch [43/64], accuracy: 0.67874
2023-10-13 20:53:16,613 - __main__ - INFO - Epoch [43/64], Step [1/2503], training loss: 1.2935009002685547, training accuracy: 0.689802913453299
2023-10-13 20:55:51,254 - __main__ - INFO - Epoch [43/64], Step [101/2503], training loss: 1.4140737056732178, training accuracy: 0.67263671875
2023-10-13 20:58:53,724 - __main__ - INFO - Epoch [43/64], Step [201/2503], training loss: 1.316746711730957, training accuracy: 0.67162109375
2023-10-13 21:01:48,264 - __main__ - INFO - Epoch [43/64], Step [301/2503], training loss: 1.2592090368270874, training accuracy: 0.67697265625
2023-10-13 21:04:40,754 - __main__ - INFO - Epoch [43/64], Step [401/2503], training loss: 1.48958420753479, training accuracy: 0.67173828125
2023-10-13 21:07:43,687 - __main__ - INFO - Epoch [43/64], Step [501/2503], training loss: 1.2920982837677002, training accuracy: 0.67623046875
2023-10-13 21:10:38,706 - __main__ - INFO - Epoch [43/64], Step [601/2503], training loss: 1.4273103475570679, training accuracy: 0.673203125
2023-10-13 21:13:33,456 - __main__ - INFO - Epoch [43/64], Step [701/2503], training loss: 1.4634923934936523, training accuracy: 0.671484375
2023-10-13 21:16:29,340 - __main__ - INFO - Epoch [43/64], Step [801/2503], training loss: 1.5269840955734253, training accuracy: 0.67384765625
2023-10-13 21:19:15,217 - __main__ - INFO - Epoch [43/64], Step [901/2503], training loss: 1.3108363151550293, training accuracy: 0.67125
2023-10-13 21:22:09,303 - __main__ - INFO - Epoch [43/64], Step [1001/2503], training loss: 1.3685108423233032, training accuracy: 0.67400390625
2023-10-13 21:24:53,075 - __main__ - INFO - Epoch [43/64], Step [1101/2503], training loss: 1.332129955291748, training accuracy: 0.67150390625
2023-10-13 21:27:45,198 - __main__ - INFO - Epoch [43/64], Step [1201/2503], training loss: 1.4516712427139282, training accuracy: 0.6705078125
2023-10-13 21:30:38,720 - __main__ - INFO - Epoch [43/64], Step [1301/2503], training loss: 1.525366187095642, training accuracy: 0.6716015625
2023-10-13 21:33:19,809 - __main__ - INFO - Epoch [43/64], Step [1401/2503], training loss: 1.3207203149795532, training accuracy: 0.6709765625
2023-10-13 21:36:07,692 - __main__ - INFO - Epoch [43/64], Step [1501/2503], training loss: 1.2787158489227295, training accuracy: 0.669765625
2023-10-13 21:39:16,241 - __main__ - INFO - Epoch [43/64], Step [1601/2503], training loss: 1.3304592370986938, training accuracy: 0.67470703125
2023-10-13 21:42:10,714 - __main__ - INFO - Epoch [43/64], Step [1701/2503], training loss: 1.3692158460617065, training accuracy: 0.67412109375
2023-10-13 21:44:52,078 - __main__ - INFO - Epoch [43/64], Step [1801/2503], training loss: 1.3748732805252075, training accuracy: 0.67146484375
2023-10-13 21:47:32,378 - __main__ - INFO - Epoch [43/64], Step [1901/2503], training loss: 1.3328667879104614, training accuracy: 0.671328125
2023-10-13 21:50:30,677 - __main__ - INFO - Epoch [43/64], Step [2001/2503], training loss: 1.1918256282806396, training accuracy: 0.6759765625
2023-10-13 21:53:26,454 - __main__ - INFO - Epoch [43/64], Step [2101/2503], training loss: 1.2885375022888184, training accuracy: 0.672265625
2023-10-13 21:56:15,751 - __main__ - INFO - Epoch [43/64], Step [2201/2503], training loss: 1.3966398239135742, training accuracy: 0.67548828125
2023-10-13 21:59:06,225 - __main__ - INFO - Epoch [43/64], Step [2301/2503], training loss: 1.464173436164856, training accuracy: 0.66931640625
2023-10-13 22:02:05,768 - __main__ - INFO - Epoch [43/64], Step [2401/2503], training loss: 1.3453083038330078, training accuracy: 0.67583984375
2023-10-13 22:04:40,505 - __main__ - INFO - Epoch [43/64], Step [2501/2503], training loss: 1.355612874031067, training accuracy: 0.67263671875
2023-10-13 22:10:52,836 - __main__ - INFO - Epoch [44/64], accuracy: 0.6792
2023-10-13 22:11:20,571 - __main__ - INFO - Epoch [44/64], Step [1/2503], training loss: 1.3638074398040771, training accuracy: 0.6658097686375322
2023-10-13 22:14:05,420 - __main__ - INFO - Epoch [44/64], Step [101/2503], training loss: 1.1348751783370972, training accuracy: 0.67490234375
2023-10-13 22:16:52,930 - __main__ - INFO - Epoch [44/64], Step [201/2503], training loss: 1.3126699924468994, training accuracy: 0.67390625
2023-10-13 22:19:46,770 - __main__ - INFO - Epoch [44/64], Step [301/2503], training loss: 1.4741370677947998, training accuracy: 0.67451171875
2023-10-13 22:22:28,582 - __main__ - INFO - Epoch [44/64], Step [401/2503], training loss: 1.3631706237792969, training accuracy: 0.67134765625
2023-10-13 22:25:20,992 - __main__ - INFO - Epoch [44/64], Step [501/2503], training loss: 1.349047303199768, training accuracy: 0.6761328125
2023-10-13 22:28:04,181 - __main__ - INFO - Epoch [44/64], Step [601/2503], training loss: 1.294679045677185, training accuracy: 0.676953125
2023-10-13 22:30:39,483 - __main__ - INFO - Epoch [44/64], Step [701/2503], training loss: 1.287534236907959, training accuracy: 0.67142578125
2023-10-13 22:33:22,911 - __main__ - INFO - Epoch [44/64], Step [801/2503], training loss: 1.4705169200897217, training accuracy: 0.6735546875
2023-10-13 22:36:13,164 - __main__ - INFO - Epoch [44/64], Step [901/2503], training loss: 1.3320001363754272, training accuracy: 0.6709765625
2023-10-13 22:38:44,469 - __main__ - INFO - Epoch [44/64], Step [1001/2503], training loss: 1.3392741680145264, training accuracy: 0.67421875
2023-10-13 22:41:13,147 - __main__ - INFO - Epoch [44/64], Step [1101/2503], training loss: 1.551436185836792, training accuracy: 0.6690625
2023-10-13 22:43:49,939 - __main__ - INFO - Epoch [44/64], Step [1201/2503], training loss: 1.5648205280303955, training accuracy: 0.6711328125
2023-10-13 22:46:21,084 - __main__ - INFO - Epoch [44/64], Step [1301/2503], training loss: 1.444350004196167, training accuracy: 0.670859375
2023-10-13 22:49:01,038 - __main__ - INFO - Epoch [44/64], Step [1401/2503], training loss: 1.2714760303497314, training accuracy: 0.67111328125
2023-10-13 22:51:24,422 - __main__ - INFO - Epoch [44/64], Step [1501/2503], training loss: 1.2362605333328247, training accuracy: 0.67125
2023-10-13 22:53:51,026 - __main__ - INFO - Epoch [44/64], Step [1601/2503], training loss: 1.2684686183929443, training accuracy: 0.669453125
2023-10-13 22:56:27,461 - __main__ - INFO - Epoch [44/64], Step [1701/2503], training loss: 1.4370753765106201, training accuracy: 0.67236328125
2023-10-13 22:58:59,467 - __main__ - INFO - Epoch [44/64], Step [1801/2503], training loss: 1.469046950340271, training accuracy: 0.67259765625
2023-10-13 23:01:29,156 - __main__ - INFO - Epoch [44/64], Step [1901/2503], training loss: 1.3306630849838257, training accuracy: 0.67521484375
2023-10-13 23:03:51,248 - __main__ - INFO - Epoch [44/64], Step [2001/2503], training loss: 1.438623070716858, training accuracy: 0.67091796875
2023-10-13 23:06:28,475 - __main__ - INFO - Epoch [44/64], Step [2101/2503], training loss: 1.2817858457565308, training accuracy: 0.67150390625
2023-10-13 23:08:59,867 - __main__ - INFO - Epoch [44/64], Step [2201/2503], training loss: 1.603667140007019, training accuracy: 0.66966796875
2023-10-13 23:11:32,832 - __main__ - INFO - Epoch [44/64], Step [2301/2503], training loss: 1.2238528728485107, training accuracy: 0.66912109375
2023-10-13 23:13:56,779 - __main__ - INFO - Epoch [44/64], Step [2401/2503], training loss: 1.4247976541519165, training accuracy: 0.6712890625
2023-10-13 23:16:17,045 - __main__ - INFO - Epoch [44/64], Step [2501/2503], training loss: 1.4707605838775635, training accuracy: 0.67458984375
2023-10-13 23:20:59,663 - __main__ - INFO - Epoch [45/64], accuracy: 0.68002
2023-10-13 23:21:23,831 - __main__ - INFO - Epoch [45/64], Step [1/2503], training loss: 1.2925018072128296, training accuracy: 0.689802913453299
2023-10-13 23:23:15,263 - __main__ - INFO - Epoch [45/64], Step [101/2503], training loss: 1.2084895372390747, training accuracy: 0.672578125
2023-10-13 23:25:27,869 - __main__ - INFO - Epoch [45/64], Step [201/2503], training loss: 1.3194371461868286, training accuracy: 0.6741796875
2023-10-13 23:27:52,203 - __main__ - INFO - Epoch [45/64], Step [301/2503], training loss: 1.258278727531433, training accuracy: 0.6737890625
2023-10-13 23:30:24,712 - __main__ - INFO - Epoch [45/64], Step [401/2503], training loss: 1.477216362953186, training accuracy: 0.674609375
2023-10-13 23:33:03,700 - __main__ - INFO - Epoch [45/64], Step [501/2503], training loss: 1.361230731010437, training accuracy: 0.6731640625
2023-10-13 23:35:35,211 - __main__ - INFO - Epoch [45/64], Step [601/2503], training loss: 1.3367177248001099, training accuracy: 0.673515625
2023-10-13 23:38:10,799 - __main__ - INFO - Epoch [45/64], Step [701/2503], training loss: 1.3333581686019897, training accuracy: 0.67060546875
2023-10-13 23:40:48,816 - __main__ - INFO - Epoch [45/64], Step [801/2503], training loss: 1.267017126083374, training accuracy: 0.6735546875
2023-10-13 23:43:21,919 - __main__ - INFO - Epoch [45/64], Step [901/2503], training loss: 1.599630355834961, training accuracy: 0.67146484375
2023-10-13 23:45:49,824 - __main__ - INFO - Epoch [45/64], Step [1001/2503], training loss: 1.354300856590271, training accuracy: 0.67775390625
2023-10-13 23:48:11,023 - __main__ - INFO - Epoch [45/64], Step [1101/2503], training loss: 1.3898818492889404, training accuracy: 0.6740234375
2023-10-13 23:50:45,354 - __main__ - INFO - Epoch [45/64], Step [1201/2503], training loss: 1.5411828756332397, training accuracy: 0.66744140625
2023-10-13 23:53:22,098 - __main__ - INFO - Epoch [45/64], Step [1301/2503], training loss: 1.223488211631775, training accuracy: 0.67234375
2023-10-13 23:55:53,351 - __main__ - INFO - Epoch [45/64], Step [1401/2503], training loss: 1.2542966604232788, training accuracy: 0.671796875
2023-10-13 23:58:20,543 - __main__ - INFO - Epoch [45/64], Step [1501/2503], training loss: 1.4333183765411377, training accuracy: 0.67412109375
2023-10-14 00:00:50,472 - __main__ - INFO - Epoch [45/64], Step [1601/2503], training loss: 1.3894450664520264, training accuracy: 0.67318359375
2023-10-14 00:03:19,469 - __main__ - INFO - Epoch [45/64], Step [1701/2503], training loss: 1.3633546829223633, training accuracy: 0.67337890625
2023-10-14 00:05:57,217 - __main__ - INFO - Epoch [45/64], Step [1801/2503], training loss: 1.2554510831832886, training accuracy: 0.6697265625
2023-10-14 00:08:20,384 - __main__ - INFO - Epoch [45/64], Step [1901/2503], training loss: 1.5287057161331177, training accuracy: 0.67099609375
2023-10-14 00:10:59,985 - __main__ - INFO - Epoch [45/64], Step [2001/2503], training loss: 1.2963303327560425, training accuracy: 0.67134765625
2023-10-14 00:13:27,231 - __main__ - INFO - Epoch [45/64], Step [2101/2503], training loss: 1.481669306755066, training accuracy: 0.673984375
2023-10-14 00:16:11,348 - __main__ - INFO - Epoch [45/64], Step [2201/2503], training loss: 1.470126748085022, training accuracy: 0.673671875
2023-10-14 00:18:44,137 - __main__ - INFO - Epoch [45/64], Step [2301/2503], training loss: 1.3892066478729248, training accuracy: 0.6726171875
2023-10-14 00:21:06,309 - __main__ - INFO - Epoch [45/64], Step [2401/2503], training loss: 1.5982540845870972, training accuracy: 0.67111328125
2023-10-14 00:23:26,238 - __main__ - INFO - Epoch [45/64], Step [2501/2503], training loss: 1.2433054447174072, training accuracy: 0.67177734375
2023-10-14 00:27:40,038 - __main__ - INFO - Epoch [46/64], accuracy: 0.67866
2023-10-14 00:27:59,771 - __main__ - INFO - Epoch [46/64], Step [1/2503], training loss: 1.2982460260391235, training accuracy: 0.6726649528706083
2023-10-14 00:29:52,788 - __main__ - INFO - Epoch [46/64], Step [101/2503], training loss: 1.5396170616149902, training accuracy: 0.67041015625
2023-10-14 00:31:47,744 - __main__ - INFO - Epoch [46/64], Step [201/2503], training loss: 1.3492794036865234, training accuracy: 0.6726171875
2023-10-14 00:33:34,971 - __main__ - INFO - Epoch [46/64], Step [301/2503], training loss: 1.3443944454193115, training accuracy: 0.67552734375
2023-10-14 00:35:24,781 - __main__ - INFO - Epoch [46/64], Step [401/2503], training loss: 1.4103728532791138, training accuracy: 0.67345703125
2023-10-14 00:37:21,603 - __main__ - INFO - Epoch [46/64], Step [501/2503], training loss: 1.3573254346847534, training accuracy: 0.6740234375
2023-10-14 00:39:14,582 - __main__ - INFO - Epoch [46/64], Step [601/2503], training loss: 1.3769506216049194, training accuracy: 0.6704296875
2023-10-14 00:41:04,996 - __main__ - INFO - Epoch [46/64], Step [701/2503], training loss: 1.4383231401443481, training accuracy: 0.6741015625
2023-10-14 00:43:32,986 - __main__ - INFO - Epoch [46/64], Step [801/2503], training loss: 1.4522125720977783, training accuracy: 0.67201171875
2023-10-14 00:45:58,197 - __main__ - INFO - Epoch [46/64], Step [901/2503], training loss: 1.3841662406921387, training accuracy: 0.6714453125
2023-10-14 00:48:25,318 - __main__ - INFO - Epoch [46/64], Step [1001/2503], training loss: 1.4774678945541382, training accuracy: 0.67095703125
2023-10-14 00:50:51,450 - __main__ - INFO - Epoch [46/64], Step [1101/2503], training loss: 1.354493260383606, training accuracy: 0.67423828125
2023-10-14 00:53:28,429 - __main__ - INFO - Epoch [46/64], Step [1201/2503], training loss: 1.4137356281280518, training accuracy: 0.67498046875
2023-10-14 00:56:07,002 - __main__ - INFO - Epoch [46/64], Step [1301/2503], training loss: 1.52530038356781, training accuracy: 0.67611328125
2023-10-14 00:58:39,550 - __main__ - INFO - Epoch [46/64], Step [1401/2503], training loss: 1.6113481521606445, training accuracy: 0.6733203125
2023-10-14 01:01:06,268 - __main__ - INFO - Epoch [46/64], Step [1501/2503], training loss: 1.2120000123977661, training accuracy: 0.67166015625
2023-10-14 01:03:45,997 - __main__ - INFO - Epoch [46/64], Step [1601/2503], training loss: 1.3009151220321655, training accuracy: 0.67478515625
2023-10-14 01:06:18,093 - __main__ - INFO - Epoch [46/64], Step [1701/2503], training loss: 1.3858200311660767, training accuracy: 0.67294921875
2023-10-14 01:08:51,012 - __main__ - INFO - Epoch [46/64], Step [1801/2503], training loss: 1.4596095085144043, training accuracy: 0.67333984375
2023-10-14 01:11:22,238 - __main__ - INFO - Epoch [46/64], Step [1901/2503], training loss: 1.2142397165298462, training accuracy: 0.67494140625
2023-10-14 01:14:10,062 - __main__ - INFO - Epoch [46/64], Step [2001/2503], training loss: 1.2808858156204224, training accuracy: 0.6726953125
2023-10-14 01:16:42,705 - __main__ - INFO - Epoch [46/64], Step [2101/2503], training loss: 1.331376552581787, training accuracy: 0.67244140625
2023-10-14 01:19:18,328 - __main__ - INFO - Epoch [46/64], Step [2201/2503], training loss: 1.3909645080566406, training accuracy: 0.6743359375
2023-10-14 01:21:56,296 - __main__ - INFO - Epoch [46/64], Step [2301/2503], training loss: 1.3661192655563354, training accuracy: 0.675859375
2023-10-14 01:24:55,267 - __main__ - INFO - Epoch [46/64], Step [2401/2503], training loss: 1.406503677368164, training accuracy: 0.6735546875
2023-10-14 01:27:28,945 - __main__ - INFO - Epoch [46/64], Step [2501/2503], training loss: 1.3176857233047485, training accuracy: 0.67359375
2023-10-14 01:32:50,114 - __main__ - INFO - Epoch [47/64], accuracy: 0.679
2023-10-14 01:33:20,026 - __main__ - INFO - Epoch [47/64], Step [1/2503], training loss: 1.3550654649734497, training accuracy: 0.6666666666666666
2023-10-14 01:35:54,141 - __main__ - INFO - Epoch [47/64], Step [101/2503], training loss: 1.256643533706665, training accuracy: 0.671875
2023-10-14 01:38:52,858 - __main__ - INFO - Epoch [47/64], Step [201/2503], training loss: 1.2750446796417236, training accuracy: 0.6748828125
2023-10-14 01:41:43,441 - __main__ - INFO - Epoch [47/64], Step [301/2503], training loss: 1.3257979154586792, training accuracy: 0.6736328125
2023-10-14 01:44:52,418 - __main__ - INFO - Epoch [47/64], Step [401/2503], training loss: 1.320745825767517, training accuracy: 0.6771484375
2023-10-14 01:47:46,583 - __main__ - INFO - Epoch [47/64], Step [501/2503], training loss: 1.3279273509979248, training accuracy: 0.67091796875
2023-10-14 01:50:40,656 - __main__ - INFO - Epoch [47/64], Step [601/2503], training loss: 1.3310860395431519, training accuracy: 0.66720703125
2023-10-14 01:53:33,121 - __main__ - INFO - Epoch [47/64], Step [701/2503], training loss: 1.53992760181427, training accuracy: 0.67283203125
2023-10-14 01:56:54,850 - __main__ - INFO - Epoch [47/64], Step [801/2503], training loss: 1.3906571865081787, training accuracy: 0.67466796875
2023-10-14 01:59:55,496 - __main__ - INFO - Epoch [47/64], Step [901/2503], training loss: 1.4285287857055664, training accuracy: 0.67275390625
2023-10-14 02:02:56,343 - __main__ - INFO - Epoch [47/64], Step [1001/2503], training loss: 1.3482803106307983, training accuracy: 0.67642578125
2023-10-14 02:06:02,136 - __main__ - INFO - Epoch [47/64], Step [1101/2503], training loss: 1.4392610788345337, training accuracy: 0.6747265625
2023-10-14 02:09:10,616 - __main__ - INFO - Epoch [47/64], Step [1201/2503], training loss: 1.389193058013916, training accuracy: 0.670625
2023-10-14 02:12:22,057 - __main__ - INFO - Epoch [47/64], Step [1301/2503], training loss: 1.4620307683944702, training accuracy: 0.67490234375
2023-10-14 02:15:30,760 - __main__ - INFO - Epoch [47/64], Step [1401/2503], training loss: 1.425243854522705, training accuracy: 0.674609375
2023-10-14 02:18:43,248 - __main__ - INFO - Epoch [47/64], Step [1501/2503], training loss: 1.4567471742630005, training accuracy: 0.66953125
2023-10-14 02:21:51,631 - __main__ - INFO - Epoch [47/64], Step [1601/2503], training loss: 1.349630355834961, training accuracy: 0.67375
2023-10-14 02:24:52,984 - __main__ - INFO - Epoch [47/64], Step [1701/2503], training loss: 1.430443286895752, training accuracy: 0.6712890625
2023-10-14 02:27:46,141 - __main__ - INFO - Epoch [47/64], Step [1801/2503], training loss: 1.2088133096694946, training accuracy: 0.67259765625
2023-10-14 02:30:44,630 - __main__ - INFO - Epoch [47/64], Step [1901/2503], training loss: 1.412273645401001, training accuracy: 0.6760546875
2023-10-14 02:34:00,945 - __main__ - INFO - Epoch [47/64], Step [2001/2503], training loss: 1.254672646522522, training accuracy: 0.672578125
2023-10-14 02:37:05,010 - __main__ - INFO - Epoch [47/64], Step [2101/2503], training loss: 1.3373758792877197, training accuracy: 0.67404296875
2023-10-14 02:39:56,572 - __main__ - INFO - Epoch [47/64], Step [2201/2503], training loss: 1.440505862236023, training accuracy: 0.672890625
2023-10-14 02:43:01,973 - __main__ - INFO - Epoch [47/64], Step [2301/2503], training loss: 1.4158459901809692, training accuracy: 0.67439453125
2023-10-14 02:46:18,486 - __main__ - INFO - Epoch [47/64], Step [2401/2503], training loss: 1.3143891096115112, training accuracy: 0.672890625
2023-10-14 02:49:00,734 - __main__ - INFO - Epoch [47/64], Step [2501/2503], training loss: 1.4137263298034668, training accuracy: 0.67333984375
2023-10-14 02:54:29,768 - __main__ - INFO - Epoch [48/64], accuracy: 0.6798
2023-10-14 02:54:58,555 - __main__ - INFO - Epoch [48/64], Step [1/2503], training loss: 1.4968798160552979, training accuracy: 0.6469580119965724
2023-10-14 02:57:29,508 - __main__ - INFO - Epoch [48/64], Step [101/2503], training loss: 1.3297538757324219, training accuracy: 0.67509765625
2023-10-14 03:00:19,825 - __main__ - INFO - Epoch [48/64], Step [201/2503], training loss: 1.2531836032867432, training accuracy: 0.67568359375
2023-10-14 03:03:07,994 - __main__ - INFO - Epoch [48/64], Step [301/2503], training loss: 1.3265687227249146, training accuracy: 0.676328125
2023-10-14 03:05:49,835 - __main__ - INFO - Epoch [48/64], Step [401/2503], training loss: 1.3276294469833374, training accuracy: 0.67255859375
2023-10-14 03:08:40,959 - __main__ - INFO - Epoch [48/64], Step [501/2503], training loss: 1.3077642917633057, training accuracy: 0.67603515625
2023-10-14 03:11:17,419 - __main__ - INFO - Epoch [48/64], Step [601/2503], training loss: 1.4691061973571777, training accuracy: 0.6742578125
2023-10-14 03:13:56,586 - __main__ - INFO - Epoch [48/64], Step [701/2503], training loss: 1.3928416967391968, training accuracy: 0.67177734375
2023-10-14 03:16:27,109 - __main__ - INFO - Epoch [48/64], Step [801/2503], training loss: 1.162039041519165, training accuracy: 0.6746484375
2023-10-14 03:19:05,066 - __main__ - INFO - Epoch [48/64], Step [901/2503], training loss: 1.3964906930923462, training accuracy: 0.67705078125
2023-10-14 03:21:44,062 - __main__ - INFO - Epoch [48/64], Step [1001/2503], training loss: 1.286972999572754, training accuracy: 0.67330078125
2023-10-14 03:24:13,541 - __main__ - INFO - Epoch [48/64], Step [1101/2503], training loss: 1.443732500076294, training accuracy: 0.67017578125
2023-10-14 03:26:35,525 - __main__ - INFO - Epoch [48/64], Step [1201/2503], training loss: 1.4815776348114014, training accuracy: 0.67607421875
2023-10-14 03:29:10,496 - __main__ - INFO - Epoch [48/64], Step [1301/2503], training loss: 1.5226372480392456, training accuracy: 0.6726171875
2023-10-14 03:31:43,849 - __main__ - INFO - Epoch [48/64], Step [1401/2503], training loss: 1.6226003170013428, training accuracy: 0.67318359375
2023-10-14 03:34:14,208 - __main__ - INFO - Epoch [48/64], Step [1501/2503], training loss: 1.411598801612854, training accuracy: 0.675078125
2023-10-14 03:36:37,141 - __main__ - INFO - Epoch [48/64], Step [1601/2503], training loss: 1.4531183242797852, training accuracy: 0.67341796875
2023-10-14 03:39:16,394 - __main__ - INFO - Epoch [48/64], Step [1701/2503], training loss: 1.3878902196884155, training accuracy: 0.670859375
2023-10-14 03:41:42,681 - __main__ - INFO - Epoch [48/64], Step [1801/2503], training loss: 1.3737713098526, training accuracy: 0.673359375
2023-10-14 03:44:13,473 - __main__ - INFO - Epoch [48/64], Step [1901/2503], training loss: 1.6134148836135864, training accuracy: 0.672109375
2023-10-14 03:46:46,318 - __main__ - INFO - Epoch [48/64], Step [2001/2503], training loss: 1.3761087656021118, training accuracy: 0.6688671875
2023-10-14 03:49:16,515 - __main__ - INFO - Epoch [48/64], Step [2101/2503], training loss: 1.445085048675537, training accuracy: 0.67734375
2023-10-14 03:51:35,453 - __main__ - INFO - Epoch [48/64], Step [2201/2503], training loss: 1.3795526027679443, training accuracy: 0.67216796875
2023-10-14 03:54:02,845 - __main__ - INFO - Epoch [48/64], Step [2301/2503], training loss: 1.2641196250915527, training accuracy: 0.67416015625
2023-10-14 03:56:28,196 - __main__ - INFO - Epoch [48/64], Step [2401/2503], training loss: 1.4137898683547974, training accuracy: 0.6715625
2023-10-14 03:58:48,105 - __main__ - INFO - Epoch [48/64], Step [2501/2503], training loss: 1.308872938156128, training accuracy: 0.6758203125
2023-10-14 04:03:00,361 - __main__ - INFO - Epoch [49/64], accuracy: 0.68016
2023-10-14 04:03:21,756 - __main__ - INFO - Epoch [49/64], Step [1/2503], training loss: 1.3835726976394653, training accuracy: 0.675235646958012
2023-10-14 04:05:10,602 - __main__ - INFO - Epoch [49/64], Step [101/2503], training loss: 1.251817226409912, training accuracy: 0.67306640625
2023-10-14 04:07:02,531 - __main__ - INFO - Epoch [49/64], Step [201/2503], training loss: 1.3620941638946533, training accuracy: 0.67111328125
2023-10-14 04:08:45,223 - __main__ - INFO - Epoch [49/64], Step [301/2503], training loss: 1.3543331623077393, training accuracy: 0.669453125
2023-10-14 04:10:39,784 - __main__ - INFO - Epoch [49/64], Step [401/2503], training loss: 1.345684289932251, training accuracy: 0.67548828125
2023-10-14 04:12:36,603 - __main__ - INFO - Epoch [49/64], Step [501/2503], training loss: 1.4185584783554077, training accuracy: 0.67294921875
2023-10-14 04:15:05,001 - __main__ - INFO - Epoch [49/64], Step [601/2503], training loss: 1.459091305732727, training accuracy: 0.67642578125
2023-10-14 04:17:28,795 - __main__ - INFO - Epoch [49/64], Step [701/2503], training loss: 1.2417057752609253, training accuracy: 0.674375
2023-10-14 04:19:55,087 - __main__ - INFO - Epoch [49/64], Step [801/2503], training loss: 1.5836238861083984, training accuracy: 0.6737890625
2023-10-14 04:22:11,661 - __main__ - INFO - Epoch [49/64], Step [901/2503], training loss: 1.4257676601409912, training accuracy: 0.67541015625
2023-10-14 04:24:33,298 - __main__ - INFO - Epoch [49/64], Step [1001/2503], training loss: 1.414094090461731, training accuracy: 0.670234375
2023-10-14 04:26:59,102 - __main__ - INFO - Epoch [49/64], Step [1101/2503], training loss: 1.3619238138198853, training accuracy: 0.67298828125
2023-10-14 04:29:15,592 - __main__ - INFO - Epoch [49/64], Step [1201/2503], training loss: 1.3789868354797363, training accuracy: 0.674375
2023-10-14 04:31:36,200 - __main__ - INFO - Epoch [49/64], Step [1301/2503], training loss: 1.3959896564483643, training accuracy: 0.6753125
2023-10-14 04:34:06,735 - __main__ - INFO - Epoch [49/64], Step [1401/2503], training loss: 1.2791047096252441, training accuracy: 0.6746875
2023-10-14 04:36:35,134 - __main__ - INFO - Epoch [49/64], Step [1501/2503], training loss: 1.4483845233917236, training accuracy: 0.6722265625
2023-10-14 04:39:00,639 - __main__ - INFO - Epoch [49/64], Step [1601/2503], training loss: 1.4023579359054565, training accuracy: 0.67818359375
2023-10-14 04:41:22,795 - __main__ - INFO - Epoch [49/64], Step [1701/2503], training loss: 1.4769757986068726, training accuracy: 0.67107421875
2023-10-14 04:43:45,960 - __main__ - INFO - Epoch [49/64], Step [1801/2503], training loss: 1.2891114950180054, training accuracy: 0.6695703125
2023-10-14 04:46:26,031 - __main__ - INFO - Epoch [49/64], Step [1901/2503], training loss: 1.3940455913543701, training accuracy: 0.6755078125
2023-10-14 04:48:50,339 - __main__ - INFO - Epoch [49/64], Step [2001/2503], training loss: 1.5268553495407104, training accuracy: 0.67306640625
2023-10-14 04:51:20,973 - __main__ - INFO - Epoch [49/64], Step [2101/2503], training loss: 1.336069107055664, training accuracy: 0.67484375
2023-10-14 04:53:43,229 - __main__ - INFO - Epoch [49/64], Step [2201/2503], training loss: 1.3469340801239014, training accuracy: 0.67490234375
2023-10-14 04:56:12,077 - __main__ - INFO - Epoch [49/64], Step [2301/2503], training loss: 1.3973313570022583, training accuracy: 0.67380859375
2023-10-14 04:58:36,210 - __main__ - INFO - Epoch [49/64], Step [2401/2503], training loss: 1.473532795906067, training accuracy: 0.67205078125
2023-10-14 05:00:47,923 - __main__ - INFO - Epoch [49/64], Step [2501/2503], training loss: 1.3147213459014893, training accuracy: 0.67189453125
2023-10-14 05:04:44,761 - __main__ - INFO - Epoch [50/64], accuracy: 0.67984
2023-10-14 05:05:06,339 - __main__ - INFO - Epoch [50/64], Step [1/2503], training loss: 1.3562242984771729, training accuracy: 0.6709511568123393
2023-10-14 05:07:01,836 - __main__ - INFO - Epoch [50/64], Step [101/2503], training loss: 1.3726308345794678, training accuracy: 0.6741015625
2023-10-14 05:09:24,084 - __main__ - INFO - Epoch [50/64], Step [201/2503], training loss: 1.3803166151046753, training accuracy: 0.67568359375
2023-10-14 05:11:37,121 - __main__ - INFO - Epoch [50/64], Step [301/2503], training loss: 1.4181568622589111, training accuracy: 0.67630859375
2023-10-14 05:13:58,536 - __main__ - INFO - Epoch [50/64], Step [401/2503], training loss: 1.2883516550064087, training accuracy: 0.674765625
2023-10-14 05:16:21,592 - __main__ - INFO - Epoch [50/64], Step [501/2503], training loss: 1.3737468719482422, training accuracy: 0.6733984375
2023-10-14 05:18:41,525 - __main__ - INFO - Epoch [50/64], Step [601/2503], training loss: 1.477839469909668, training accuracy: 0.67271484375
2023-10-14 05:20:59,262 - __main__ - INFO - Epoch [50/64], Step [701/2503], training loss: 1.313018560409546, training accuracy: 0.67900390625
2023-10-14 05:23:31,344 - __main__ - INFO - Epoch [50/64], Step [801/2503], training loss: 1.3257578611373901, training accuracy: 0.6723046875
2023-10-14 05:25:51,655 - __main__ - INFO - Epoch [50/64], Step [901/2503], training loss: 1.277871012687683, training accuracy: 0.6742578125
2023-10-14 05:28:20,561 - __main__ - INFO - Epoch [50/64], Step [1001/2503], training loss: 1.4346528053283691, training accuracy: 0.67509765625
2023-10-14 05:30:56,294 - __main__ - INFO - Epoch [50/64], Step [1101/2503], training loss: 1.3652054071426392, training accuracy: 0.67376953125
2023-10-14 05:33:25,126 - __main__ - INFO - Epoch [50/64], Step [1201/2503], training loss: 1.4016194343566895, training accuracy: 0.6716796875
2023-10-14 05:35:59,122 - __main__ - INFO - Epoch [50/64], Step [1301/2503], training loss: 1.5728741884231567, training accuracy: 0.6691015625
2023-10-14 05:38:34,100 - __main__ - INFO - Epoch [50/64], Step [1401/2503], training loss: 1.391809105873108, training accuracy: 0.6732421875
2023-10-14 05:41:07,187 - __main__ - INFO - Epoch [50/64], Step [1501/2503], training loss: 1.3924751281738281, training accuracy: 0.67271484375
2023-10-14 05:43:37,883 - __main__ - INFO - Epoch [50/64], Step [1601/2503], training loss: 1.3864301443099976, training accuracy: 0.67083984375
2023-10-14 05:46:19,009 - __main__ - INFO - Epoch [50/64], Step [1701/2503], training loss: 1.167872667312622, training accuracy: 0.67498046875
2023-10-14 05:49:05,191 - __main__ - INFO - Epoch [50/64], Step [1801/2503], training loss: 1.4707951545715332, training accuracy: 0.67154296875
2023-10-14 05:51:43,360 - __main__ - INFO - Epoch [50/64], Step [1901/2503], training loss: 1.2616018056869507, training accuracy: 0.672890625
2023-10-14 05:54:07,491 - __main__ - INFO - Epoch [50/64], Step [2001/2503], training loss: 1.4128077030181885, training accuracy: 0.67072265625
2023-10-14 05:56:40,727 - __main__ - INFO - Epoch [50/64], Step [2101/2503], training loss: 1.253171682357788, training accuracy: 0.67357421875
2023-10-14 05:59:20,169 - __main__ - INFO - Epoch [50/64], Step [2201/2503], training loss: 1.2263590097427368, training accuracy: 0.67591796875
2023-10-14 06:01:45,939 - __main__ - INFO - Epoch [50/64], Step [2301/2503], training loss: 1.2826097011566162, training accuracy: 0.6739453125
2023-10-14 06:04:24,329 - __main__ - INFO - Epoch [50/64], Step [2401/2503], training loss: 1.377573847770691, training accuracy: 0.6721484375
2023-10-14 06:06:42,039 - __main__ - INFO - Epoch [50/64], Step [2501/2503], training loss: 1.3982412815093994, training accuracy: 0.67419921875
2023-10-14 06:11:23,432 - __main__ - INFO - Epoch [51/64], accuracy: 0.67996
2023-10-14 06:11:49,221 - __main__ - INFO - Epoch [51/64], Step [1/2503], training loss: 1.2021386623382568, training accuracy: 0.6743787489288775
2023-10-14 06:13:57,080 - __main__ - INFO - Epoch [51/64], Step [101/2503], training loss: 1.2472347021102905, training accuracy: 0.6776953125
2023-10-14 06:16:26,105 - __main__ - INFO - Epoch [51/64], Step [201/2503], training loss: 1.3946655988693237, training accuracy: 0.67298828125
2023-10-14 06:18:55,683 - __main__ - INFO - Epoch [51/64], Step [301/2503], training loss: 1.4709237813949585, training accuracy: 0.6764453125
2023-10-14 06:21:26,704 - __main__ - INFO - Epoch [51/64], Step [401/2503], training loss: 1.2404396533966064, training accuracy: 0.67498046875
2023-10-14 06:23:52,379 - __main__ - INFO - Epoch [51/64], Step [501/2503], training loss: 1.3608900308609009, training accuracy: 0.67673828125
2023-10-14 06:26:24,411 - __main__ - INFO - Epoch [51/64], Step [601/2503], training loss: 1.3310085535049438, training accuracy: 0.67681640625
2023-10-14 06:28:50,264 - __main__ - INFO - Epoch [51/64], Step [701/2503], training loss: 1.4049298763275146, training accuracy: 0.67205078125
2023-10-14 06:31:27,956 - __main__ - INFO - Epoch [51/64], Step [801/2503], training loss: 1.4027243852615356, training accuracy: 0.677734375
2023-10-14 06:33:55,139 - __main__ - INFO - Epoch [51/64], Step [901/2503], training loss: 1.4200847148895264, training accuracy: 0.6723828125
2023-10-14 06:36:22,255 - __main__ - INFO - Epoch [51/64], Step [1001/2503], training loss: 1.3804278373718262, training accuracy: 0.67505859375
2023-10-14 06:38:45,371 - __main__ - INFO - Epoch [51/64], Step [1101/2503], training loss: 1.392510175704956, training accuracy: 0.67451171875
2023-10-14 06:41:18,900 - __main__ - INFO - Epoch [51/64], Step [1201/2503], training loss: 1.3355848789215088, training accuracy: 0.6771484375
2023-10-14 06:44:00,219 - __main__ - INFO - Epoch [51/64], Step [1301/2503], training loss: 1.4147082567214966, training accuracy: 0.67166015625
2023-10-14 06:46:32,201 - __main__ - INFO - Epoch [51/64], Step [1401/2503], training loss: 1.4429341554641724, training accuracy: 0.67599609375
2023-10-14 06:49:04,252 - __main__ - INFO - Epoch [51/64], Step [1501/2503], training loss: 1.287878155708313, training accuracy: 0.67376953125
2023-10-14 06:51:46,104 - __main__ - INFO - Epoch [51/64], Step [1601/2503], training loss: 1.2517280578613281, training accuracy: 0.67755859375
2023-10-14 06:54:31,634 - __main__ - INFO - Epoch [51/64], Step [1701/2503], training loss: 1.2428280115127563, training accuracy: 0.6775
2023-10-14 06:57:02,564 - __main__ - INFO - Epoch [51/64], Step [1801/2503], training loss: 1.3214294910430908, training accuracy: 0.66970703125
2023-10-14 06:59:30,076 - __main__ - INFO - Epoch [51/64], Step [1901/2503], training loss: 1.585817575454712, training accuracy: 0.673515625
2023-10-14 07:02:02,071 - __main__ - INFO - Epoch [51/64], Step [2001/2503], training loss: 1.3092448711395264, training accuracy: 0.67404296875
2023-10-14 07:04:46,450 - __main__ - INFO - Epoch [51/64], Step [2101/2503], training loss: 1.4106146097183228, training accuracy: 0.67564453125
2023-10-14 07:07:20,118 - __main__ - INFO - Epoch [51/64], Step [2201/2503], training loss: 1.3631477355957031, training accuracy: 0.6749609375
2023-10-14 07:09:59,910 - __main__ - INFO - Epoch [51/64], Step [2301/2503], training loss: 1.391408085823059, training accuracy: 0.67333984375
2023-10-14 07:12:35,266 - __main__ - INFO - Epoch [51/64], Step [2401/2503], training loss: 1.2707303762435913, training accuracy: 0.67322265625
2023-10-14 07:14:57,023 - __main__ - INFO - Epoch [51/64], Step [2501/2503], training loss: 1.382086157798767, training accuracy: 0.6723046875
2023-10-14 07:19:23,129 - __main__ - INFO - Epoch [52/64], accuracy: 0.68016
2023-10-14 07:19:44,439 - __main__ - INFO - Epoch [52/64], Step [1/2503], training loss: 1.3961262702941895, training accuracy: 0.6555269922879178
2023-10-14 07:21:27,513 - __main__ - INFO - Epoch [52/64], Step [101/2503], training loss: 1.4613310098648071, training accuracy: 0.67388671875
2023-10-14 07:23:16,972 - __main__ - INFO - Epoch [52/64], Step [201/2503], training loss: 1.4263614416122437, training accuracy: 0.6726171875
2023-10-14 07:25:13,976 - __main__ - INFO - Epoch [52/64], Step [301/2503], training loss: 1.365938425064087, training accuracy: 0.67529296875
2023-10-14 07:27:18,830 - __main__ - INFO - Epoch [52/64], Step [401/2503], training loss: 1.472940444946289, training accuracy: 0.67220703125
2023-10-14 07:29:21,653 - __main__ - INFO - Epoch [52/64], Step [501/2503], training loss: 1.4963017702102661, training accuracy: 0.6694921875
2023-10-14 07:31:12,368 - __main__ - INFO - Epoch [52/64], Step [601/2503], training loss: 1.497257113456726, training accuracy: 0.67337890625
2023-10-14 07:33:15,468 - __main__ - INFO - Epoch [52/64], Step [701/2503], training loss: 1.4871752262115479, training accuracy: 0.6778515625
2023-10-14 07:35:13,893 - __main__ - INFO - Epoch [52/64], Step [801/2503], training loss: 1.3663088083267212, training accuracy: 0.6748828125
2023-10-14 07:37:22,259 - __main__ - INFO - Epoch [52/64], Step [901/2503], training loss: 1.4227122068405151, training accuracy: 0.6715234375
2023-10-14 07:39:21,485 - __main__ - INFO - Epoch [52/64], Step [1001/2503], training loss: 1.2621852159500122, training accuracy: 0.6756640625
2023-10-14 07:41:25,665 - __main__ - INFO - Epoch [52/64], Step [1101/2503], training loss: 1.4129612445831299, training accuracy: 0.67400390625
2023-10-14 07:43:18,159 - __main__ - INFO - Epoch [52/64], Step [1201/2503], training loss: 1.2374300956726074, training accuracy: 0.67564453125
2023-10-14 07:45:31,702 - __main__ - INFO - Epoch [52/64], Step [1301/2503], training loss: 1.551723837852478, training accuracy: 0.67390625
2023-10-14 07:48:02,751 - __main__ - INFO - Epoch [52/64], Step [1401/2503], training loss: 1.4570473432540894, training accuracy: 0.67611328125
2023-10-14 07:50:38,477 - __main__ - INFO - Epoch [52/64], Step [1501/2503], training loss: 1.3011267185211182, training accuracy: 0.672265625
2023-10-14 07:53:02,323 - __main__ - INFO - Epoch [52/64], Step [1601/2503], training loss: 1.350441813468933, training accuracy: 0.675859375
2023-10-14 07:55:23,123 - __main__ - INFO - Epoch [52/64], Step [1701/2503], training loss: 1.362043857574463, training accuracy: 0.671484375
2023-10-14 07:57:40,894 - __main__ - INFO - Epoch [52/64], Step [1801/2503], training loss: 1.4875855445861816, training accuracy: 0.67548828125
2023-10-14 08:00:08,200 - __main__ - INFO - Epoch [52/64], Step [1901/2503], training loss: 1.4144407510757446, training accuracy: 0.6753125
2023-10-14 08:02:44,620 - __main__ - INFO - Epoch [52/64], Step [2001/2503], training loss: 1.5324628353118896, training accuracy: 0.6762109375
2023-10-14 08:05:15,309 - __main__ - INFO - Epoch [52/64], Step [2101/2503], training loss: 1.5153024196624756, training accuracy: 0.6725390625
2023-10-14 08:07:45,855 - __main__ - INFO - Epoch [52/64], Step [2201/2503], training loss: 1.3711395263671875, training accuracy: 0.67419921875
2023-10-14 08:10:23,330 - __main__ - INFO - Epoch [52/64], Step [2301/2503], training loss: 1.3702142238616943, training accuracy: 0.67435546875
2023-10-14 08:13:02,473 - __main__ - INFO - Epoch [52/64], Step [2401/2503], training loss: 1.2796435356140137, training accuracy: 0.6730859375
2023-10-14 08:15:20,370 - __main__ - INFO - Epoch [52/64], Step [2501/2503], training loss: 1.3950128555297852, training accuracy: 0.67927734375
2023-10-14 08:19:00,097 - __main__ - INFO - Epoch [53/64], accuracy: 0.68048
2023-10-14 08:19:23,195 - __main__ - INFO - Epoch [53/64], Step [1/2503], training loss: 1.2794396877288818, training accuracy: 0.6666666666666666
2023-10-14 08:21:15,605 - __main__ - INFO - Epoch [53/64], Step [101/2503], training loss: 1.435107707977295, training accuracy: 0.67396484375
2023-10-14 08:23:02,036 - __main__ - INFO - Epoch [53/64], Step [201/2503], training loss: 1.4456524848937988, training accuracy: 0.67318359375
2023-10-14 08:24:54,387 - __main__ - INFO - Epoch [53/64], Step [301/2503], training loss: 1.3719643354415894, training accuracy: 0.674921875
2023-10-14 08:26:53,383 - __main__ - INFO - Epoch [53/64], Step [401/2503], training loss: 1.2742998600006104, training accuracy: 0.67576171875
2023-10-14 08:28:47,142 - __main__ - INFO - Epoch [53/64], Step [501/2503], training loss: 1.315227746963501, training accuracy: 0.673984375
2023-10-14 08:30:45,701 - __main__ - INFO - Epoch [53/64], Step [601/2503], training loss: 1.3266899585723877, training accuracy: 0.67333984375
2023-10-14 08:33:15,034 - __main__ - INFO - Epoch [53/64], Step [701/2503], training loss: 1.3567169904708862, training accuracy: 0.6722265625
2023-10-14 08:35:53,675 - __main__ - INFO - Epoch [53/64], Step [801/2503], training loss: 1.2951066493988037, training accuracy: 0.6769140625
2023-10-14 08:38:20,288 - __main__ - INFO - Epoch [53/64], Step [901/2503], training loss: 1.428354263305664, training accuracy: 0.67697265625
2023-10-14 08:40:43,189 - __main__ - INFO - Epoch [53/64], Step [1001/2503], training loss: 1.4184911251068115, training accuracy: 0.67419921875
2023-10-14 08:43:24,744 - __main__ - INFO - Epoch [53/64], Step [1101/2503], training loss: 1.4429773092269897, training accuracy: 0.6721875
2023-10-14 08:45:52,864 - __main__ - INFO - Epoch [53/64], Step [1201/2503], training loss: 1.295776128768921, training accuracy: 0.6770703125
2023-10-14 08:48:29,680 - __main__ - INFO - Epoch [53/64], Step [1301/2503], training loss: 1.2789514064788818, training accuracy: 0.671875
2023-10-14 08:51:03,468 - __main__ - INFO - Epoch [53/64], Step [1401/2503], training loss: 1.1922115087509155, training accuracy: 0.67416015625
2023-10-14 08:53:35,848 - __main__ - INFO - Epoch [53/64], Step [1501/2503], training loss: 1.3370784521102905, training accuracy: 0.6743359375
2023-10-14 08:56:07,901 - __main__ - INFO - Epoch [53/64], Step [1601/2503], training loss: 1.3197507858276367, training accuracy: 0.6743359375
2023-10-14 08:58:39,247 - __main__ - INFO - Epoch [53/64], Step [1701/2503], training loss: 1.3740558624267578, training accuracy: 0.67876953125
2023-10-14 09:01:08,910 - __main__ - INFO - Epoch [53/64], Step [1801/2503], training loss: 1.4061875343322754, training accuracy: 0.66841796875
2023-10-14 09:03:37,004 - __main__ - INFO - Epoch [53/64], Step [1901/2503], training loss: 1.4707597494125366, training accuracy: 0.672890625
2023-10-14 09:06:08,458 - __main__ - INFO - Epoch [53/64], Step [2001/2503], training loss: 1.4256796836853027, training accuracy: 0.673125
2023-10-14 09:08:47,559 - __main__ - INFO - Epoch [53/64], Step [2101/2503], training loss: 1.5256240367889404, training accuracy: 0.673359375
2023-10-14 09:11:15,190 - __main__ - INFO - Epoch [53/64], Step [2201/2503], training loss: 1.3835629224777222, training accuracy: 0.677734375
2023-10-14 09:13:40,336 - __main__ - INFO - Epoch [53/64], Step [2301/2503], training loss: 1.562142252922058, training accuracy: 0.67048828125
2023-10-14 09:16:05,480 - __main__ - INFO - Epoch [53/64], Step [2401/2503], training loss: 1.3415578603744507, training accuracy: 0.67455078125
2023-10-14 09:18:24,334 - __main__ - INFO - Epoch [53/64], Step [2501/2503], training loss: 1.306519865989685, training accuracy: 0.6726953125
2023-10-14 09:22:28,251 - __main__ - INFO - Epoch [54/64], accuracy: 0.68044
2023-10-14 09:22:51,596 - __main__ - INFO - Epoch [54/64], Step [1/2503], training loss: 1.398503303527832, training accuracy: 0.6563838903170522
2023-10-14 09:24:44,987 - __main__ - INFO - Epoch [54/64], Step [101/2503], training loss: 1.5260593891143799, training accuracy: 0.6759765625
2023-10-14 09:26:36,561 - __main__ - INFO - Epoch [54/64], Step [201/2503], training loss: 1.5671316385269165, training accuracy: 0.670703125
2023-10-14 09:28:36,647 - __main__ - INFO - Epoch [54/64], Step [301/2503], training loss: 1.4457032680511475, training accuracy: 0.67017578125
2023-10-14 09:30:53,289 - __main__ - INFO - Epoch [54/64], Step [401/2503], training loss: 1.3284238576889038, training accuracy: 0.6741015625
2023-10-14 09:32:50,352 - __main__ - INFO - Epoch [54/64], Step [501/2503], training loss: 1.280569314956665, training accuracy: 0.67576171875
2023-10-14 09:34:50,708 - __main__ - INFO - Epoch [54/64], Step [601/2503], training loss: 1.3073080778121948, training accuracy: 0.67310546875
2023-10-14 09:36:44,078 - __main__ - INFO - Epoch [54/64], Step [701/2503], training loss: 1.3805311918258667, training accuracy: 0.67388671875
2023-10-14 09:38:56,633 - __main__ - INFO - Epoch [54/64], Step [801/2503], training loss: 1.4918574094772339, training accuracy: 0.67341796875
2023-10-14 09:40:56,579 - __main__ - INFO - Epoch [54/64], Step [901/2503], training loss: 1.3995331525802612, training accuracy: 0.67302734375
2023-10-14 09:42:55,961 - __main__ - INFO - Epoch [54/64], Step [1001/2503], training loss: 1.3151888847351074, training accuracy: 0.67845703125
2023-10-14 09:44:56,041 - __main__ - INFO - Epoch [54/64], Step [1101/2503], training loss: 1.317551851272583, training accuracy: 0.675
2023-10-14 09:47:13,381 - __main__ - INFO - Epoch [54/64], Step [1201/2503], training loss: 1.3809622526168823, training accuracy: 0.674375
2023-10-14 09:49:26,154 - __main__ - INFO - Epoch [54/64], Step [1301/2503], training loss: 1.4298522472381592, training accuracy: 0.6755859375
2023-10-14 09:51:35,392 - __main__ - INFO - Epoch [54/64], Step [1401/2503], training loss: 1.4952130317687988, training accuracy: 0.67490234375
2023-10-14 09:53:52,457 - __main__ - INFO - Epoch [54/64], Step [1501/2503], training loss: 1.2958751916885376, training accuracy: 0.66904296875
2023-10-14 09:56:20,134 - __main__ - INFO - Epoch [54/64], Step [1601/2503], training loss: 1.3890000581741333, training accuracy: 0.67365234375
2023-10-14 09:58:34,798 - __main__ - INFO - Epoch [54/64], Step [1701/2503], training loss: 1.309865117073059, training accuracy: 0.67314453125
2023-10-14 10:01:16,247 - __main__ - INFO - Epoch [54/64], Step [1801/2503], training loss: 1.4162482023239136, training accuracy: 0.67509765625
2023-10-14 10:04:09,327 - __main__ - INFO - Epoch [54/64], Step [1901/2503], training loss: 1.4095357656478882, training accuracy: 0.67423828125
2023-10-14 10:07:34,628 - __main__ - INFO - Epoch [54/64], Step [2001/2503], training loss: 1.4871405363082886, training accuracy: 0.6733984375
2023-10-14 10:10:29,250 - __main__ - INFO - Epoch [54/64], Step [2101/2503], training loss: 1.5132577419281006, training accuracy: 0.67865234375
2023-10-14 10:13:39,841 - __main__ - INFO - Epoch [54/64], Step [2201/2503], training loss: 1.40346360206604, training accuracy: 0.6745703125
2023-10-14 10:16:59,153 - __main__ - INFO - Epoch [54/64], Step [2301/2503], training loss: 1.3496931791305542, training accuracy: 0.67291015625
2023-10-14 10:19:55,675 - __main__ - INFO - Epoch [54/64], Step [2401/2503], training loss: 1.3258849382400513, training accuracy: 0.67181640625
2023-10-14 10:23:00,924 - __main__ - INFO - Epoch [54/64], Step [2501/2503], training loss: 1.3901278972625732, training accuracy: 0.6764453125
2023-10-14 10:29:34,381 - __main__ - INFO - Epoch [55/64], accuracy: 0.68066
2023-10-14 10:30:06,123 - __main__ - INFO - Epoch [55/64], Step [1/2503], training loss: 1.2956420183181763, training accuracy: 0.6735218508997429
2023-10-14 10:33:09,640 - __main__ - INFO - Epoch [55/64], Step [101/2503], training loss: 1.366918683052063, training accuracy: 0.6744921875
2023-10-14 10:36:29,789 - __main__ - INFO - Epoch [55/64], Step [201/2503], training loss: 1.2172890901565552, training accuracy: 0.67201171875
2023-10-14 10:39:42,608 - __main__ - INFO - Epoch [55/64], Step [301/2503], training loss: 1.3378503322601318, training accuracy: 0.6709765625
2023-10-14 10:43:16,386 - __main__ - INFO - Epoch [55/64], Step [401/2503], training loss: 1.345512866973877, training accuracy: 0.67173828125
2023-10-14 10:46:45,734 - __main__ - INFO - Epoch [55/64], Step [501/2503], training loss: 1.5174741744995117, training accuracy: 0.673984375
2023-10-14 10:50:04,082 - __main__ - INFO - Epoch [55/64], Step [601/2503], training loss: 1.2433605194091797, training accuracy: 0.67392578125
2023-10-14 10:53:01,232 - __main__ - INFO - Epoch [55/64], Step [701/2503], training loss: 1.3216139078140259, training accuracy: 0.6769140625
2023-10-14 10:56:23,964 - __main__ - INFO - Epoch [55/64], Step [801/2503], training loss: 1.372543454170227, training accuracy: 0.67447265625
2023-10-14 10:59:19,438 - __main__ - INFO - Epoch [55/64], Step [901/2503], training loss: 1.287428617477417, training accuracy: 0.67265625
2023-10-14 11:02:21,427 - __main__ - INFO - Epoch [55/64], Step [1001/2503], training loss: 1.4715064764022827, training accuracy: 0.6742578125
2023-10-14 11:05:26,053 - __main__ - INFO - Epoch [55/64], Step [1101/2503], training loss: 1.4529136419296265, training accuracy: 0.67560546875
2023-10-14 11:08:41,165 - __main__ - INFO - Epoch [55/64], Step [1201/2503], training loss: 1.3265596628189087, training accuracy: 0.6736328125
2023-10-14 11:11:30,875 - __main__ - INFO - Epoch [55/64], Step [1301/2503], training loss: 1.3588271141052246, training accuracy: 0.67392578125
2023-10-14 11:14:28,393 - __main__ - INFO - Epoch [55/64], Step [1401/2503], training loss: 1.2840418815612793, training accuracy: 0.67591796875
2023-10-14 11:17:26,828 - __main__ - INFO - Epoch [55/64], Step [1501/2503], training loss: 1.3840118646621704, training accuracy: 0.6749609375
2023-10-14 11:20:40,927 - __main__ - INFO - Epoch [55/64], Step [1601/2503], training loss: 1.3768960237503052, training accuracy: 0.6775390625
2023-10-14 11:23:42,391 - __main__ - INFO - Epoch [55/64], Step [1701/2503], training loss: 1.4078114032745361, training accuracy: 0.6739453125
2023-10-14 11:26:54,849 - __main__ - INFO - Epoch [55/64], Step [1801/2503], training loss: 1.454910397529602, training accuracy: 0.67611328125
2023-10-14 11:30:08,087 - __main__ - INFO - Epoch [55/64], Step [1901/2503], training loss: 1.452727198600769, training accuracy: 0.67431640625
2023-10-14 11:33:27,498 - __main__ - INFO - Epoch [55/64], Step [2001/2503], training loss: 1.415616512298584, training accuracy: 0.67560546875
2023-10-14 11:36:26,702 - __main__ - INFO - Epoch [55/64], Step [2101/2503], training loss: 1.4441508054733276, training accuracy: 0.6770703125
2023-10-14 11:39:34,130 - __main__ - INFO - Epoch [55/64], Step [2201/2503], training loss: 1.2387194633483887, training accuracy: 0.676015625
2023-10-14 11:42:29,774 - __main__ - INFO - Epoch [55/64], Step [2301/2503], training loss: 1.5863462686538696, training accuracy: 0.674609375
2023-10-14 11:45:29,311 - __main__ - INFO - Epoch [55/64], Step [2401/2503], training loss: 1.362007737159729, training accuracy: 0.67423828125
2023-10-14 11:48:22,338 - __main__ - INFO - Epoch [55/64], Step [2501/2503], training loss: 1.4285969734191895, training accuracy: 0.66955078125
2023-10-14 11:54:06,617 - __main__ - INFO - Epoch [56/64], accuracy: 0.681
2023-10-14 11:54:36,821 - __main__ - INFO - Epoch [56/64], Step [1/2503], training loss: 1.365098476409912, training accuracy: 0.662382176520994
2023-10-14 11:56:51,000 - __main__ - INFO - Epoch [56/64], Step [101/2503], training loss: 1.4828611612319946, training accuracy: 0.67599609375
2023-10-14 11:58:55,387 - __main__ - INFO - Epoch [56/64], Step [201/2503], training loss: 1.450085997581482, training accuracy: 0.6729296875
2023-10-14 12:01:06,499 - __main__ - INFO - Epoch [56/64], Step [301/2503], training loss: 1.4378509521484375, training accuracy: 0.67294921875
2023-10-14 12:03:35,802 - __main__ - INFO - Epoch [56/64], Step [401/2503], training loss: 1.440785527229309, training accuracy: 0.676015625
2023-10-14 12:05:59,470 - __main__ - INFO - Epoch [56/64], Step [501/2503], training loss: 1.574992060661316, training accuracy: 0.6758984375
2023-10-14 12:08:17,862 - __main__ - INFO - Epoch [56/64], Step [601/2503], training loss: 1.3603339195251465, training accuracy: 0.676796875
2023-10-14 12:10:33,345 - __main__ - INFO - Epoch [56/64], Step [701/2503], training loss: 1.4909433126449585, training accuracy: 0.673984375
2023-10-14 12:13:06,843 - __main__ - INFO - Epoch [56/64], Step [801/2503], training loss: 1.1744272708892822, training accuracy: 0.67541015625
2023-10-14 12:16:01,429 - __main__ - INFO - Epoch [56/64], Step [901/2503], training loss: 1.262484073638916, training accuracy: 0.67322265625
2023-10-14 12:18:37,609 - __main__ - INFO - Epoch [56/64], Step [1001/2503], training loss: 1.3356449604034424, training accuracy: 0.677265625
2023-10-14 12:21:18,716 - __main__ - INFO - Epoch [56/64], Step [1101/2503], training loss: 1.4156984090805054, training accuracy: 0.6766015625
2023-10-14 12:23:59,372 - __main__ - INFO - Epoch [56/64], Step [1201/2503], training loss: 1.4769006967544556, training accuracy: 0.67634765625
2023-10-14 12:26:39,352 - __main__ - INFO - Epoch [56/64], Step [1301/2503], training loss: 1.4113404750823975, training accuracy: 0.67478515625
2023-10-14 12:29:12,146 - __main__ - INFO - Epoch [56/64], Step [1401/2503], training loss: 1.262252688407898, training accuracy: 0.67837890625
2023-10-14 12:31:57,113 - __main__ - INFO - Epoch [56/64], Step [1501/2503], training loss: 1.2979360818862915, training accuracy: 0.67330078125
2023-10-14 12:34:31,800 - __main__ - INFO - Epoch [56/64], Step [1601/2503], training loss: 1.2985305786132812, training accuracy: 0.67255859375
2023-10-14 12:37:10,498 - __main__ - INFO - Epoch [56/64], Step [1701/2503], training loss: 1.4345269203186035, training accuracy: 0.67333984375
2023-10-14 12:39:45,898 - __main__ - INFO - Epoch [56/64], Step [1801/2503], training loss: 1.2452099323272705, training accuracy: 0.67572265625
2023-10-14 12:42:22,288 - __main__ - INFO - Epoch [56/64], Step [1901/2503], training loss: 1.3960421085357666, training accuracy: 0.67615234375
2023-10-14 12:44:59,344 - __main__ - INFO - Epoch [56/64], Step [2001/2503], training loss: 1.3917728662490845, training accuracy: 0.67462890625
2023-10-14 12:47:35,844 - __main__ - INFO - Epoch [56/64], Step [2101/2503], training loss: 1.2488558292388916, training accuracy: 0.67673828125
2023-10-14 12:50:07,630 - __main__ - INFO - Epoch [56/64], Step [2201/2503], training loss: 1.5370359420776367, training accuracy: 0.67505859375
2023-10-14 12:52:38,550 - __main__ - INFO - Epoch [56/64], Step [2301/2503], training loss: 1.3228390216827393, training accuracy: 0.67392578125
2023-10-14 12:55:08,565 - __main__ - INFO - Epoch [56/64], Step [2401/2503], training loss: 1.521297812461853, training accuracy: 0.6739453125
2023-10-14 12:57:45,593 - __main__ - INFO - Epoch [56/64], Step [2501/2503], training loss: 1.3586628437042236, training accuracy: 0.67576171875
2023-10-14 13:02:22,551 - __main__ - INFO - Epoch [57/64], accuracy: 0.67994
2023-10-14 13:02:47,053 - __main__ - INFO - Epoch [57/64], Step [1/2503], training loss: 1.3393747806549072, training accuracy: 0.675235646958012
2023-10-14 13:04:58,585 - __main__ - INFO - Epoch [57/64], Step [101/2503], training loss: 1.2640933990478516, training accuracy: 0.67423828125
2023-10-14 13:07:37,986 - __main__ - INFO - Epoch [57/64], Step [201/2503], training loss: 1.5314446687698364, training accuracy: 0.672890625
2023-10-14 13:10:15,666 - __main__ - INFO - Epoch [57/64], Step [301/2503], training loss: 1.3117058277130127, training accuracy: 0.6729296875
2023-10-14 13:13:03,445 - __main__ - INFO - Epoch [57/64], Step [401/2503], training loss: 1.3340312242507935, training accuracy: 0.67552734375
2023-10-14 13:15:34,924 - __main__ - INFO - Epoch [57/64], Step [501/2503], training loss: 1.3044430017471313, training accuracy: 0.67474609375
2023-10-14 13:18:05,943 - __main__ - INFO - Epoch [57/64], Step [601/2503], training loss: 1.4872878789901733, training accuracy: 0.67625
2023-10-14 13:20:43,643 - __main__ - INFO - Epoch [57/64], Step [701/2503], training loss: 1.4650609493255615, training accuracy: 0.6748828125
2023-10-14 13:23:27,645 - __main__ - INFO - Epoch [57/64], Step [801/2503], training loss: 1.3246359825134277, training accuracy: 0.67400390625
2023-10-14 13:26:04,445 - __main__ - INFO - Epoch [57/64], Step [901/2503], training loss: 1.4952716827392578, training accuracy: 0.67548828125
2023-10-14 13:28:47,397 - __main__ - INFO - Epoch [57/64], Step [1001/2503], training loss: 1.3007620573043823, training accuracy: 0.672734375
2023-10-14 13:31:18,086 - __main__ - INFO - Epoch [57/64], Step [1101/2503], training loss: 1.4363327026367188, training accuracy: 0.67580078125
2023-10-14 13:34:12,952 - __main__ - INFO - Epoch [57/64], Step [1201/2503], training loss: 1.3821145296096802, training accuracy: 0.67470703125
2023-10-14 13:36:50,051 - __main__ - INFO - Epoch [57/64], Step [1301/2503], training loss: 1.3917479515075684, training accuracy: 0.67201171875
2023-10-14 13:39:37,220 - __main__ - INFO - Epoch [57/64], Step [1401/2503], training loss: 1.3845508098602295, training accuracy: 0.67521484375
2023-10-14 13:42:22,837 - __main__ - INFO - Epoch [57/64], Step [1501/2503], training loss: 1.301145076751709, training accuracy: 0.67306640625
2023-10-14 13:45:12,825 - __main__ - INFO - Epoch [57/64], Step [1601/2503], training loss: 1.4153367280960083, training accuracy: 0.673515625
2023-10-14 13:47:46,429 - __main__ - INFO - Epoch [57/64], Step [1701/2503], training loss: 1.4400463104248047, training accuracy: 0.674140625
2023-10-14 13:50:22,702 - __main__ - INFO - Epoch [57/64], Step [1801/2503], training loss: 1.2635996341705322, training accuracy: 0.67529296875
2023-10-14 13:53:01,512 - __main__ - INFO - Epoch [57/64], Step [1901/2503], training loss: 1.3319060802459717, training accuracy: 0.673203125
2023-10-14 13:55:50,921 - __main__ - INFO - Epoch [57/64], Step [2001/2503], training loss: 1.4858540296554565, training accuracy: 0.67796875
2023-10-14 13:58:20,159 - __main__ - INFO - Epoch [57/64], Step [2101/2503], training loss: 1.4011310338974, training accuracy: 0.67611328125
2023-10-14 14:00:57,442 - __main__ - INFO - Epoch [57/64], Step [2201/2503], training loss: 1.2624620199203491, training accuracy: 0.6765234375
2023-10-14 14:03:35,487 - __main__ - INFO - Epoch [57/64], Step [2301/2503], training loss: 1.3622183799743652, training accuracy: 0.67421875
2023-10-14 14:06:25,944 - __main__ - INFO - Epoch [57/64], Step [2401/2503], training loss: 1.3127238750457764, training accuracy: 0.67349609375
2023-10-14 14:08:50,756 - __main__ - INFO - Epoch [57/64], Step [2501/2503], training loss: 1.2883131504058838, training accuracy: 0.679296875
2023-10-14 14:12:49,470 - __main__ - INFO - Epoch [58/64], accuracy: 0.68028
2023-10-14 14:13:14,970 - __main__ - INFO - Epoch [58/64], Step [1/2503], training loss: 1.4007458686828613, training accuracy: 0.6495287060839761
2023-10-14 14:15:09,322 - __main__ - INFO - Epoch [58/64], Step [101/2503], training loss: 1.507980465888977, training accuracy: 0.6724609375
2023-10-14 14:17:10,930 - __main__ - INFO - Epoch [58/64], Step [201/2503], training loss: 1.3719323873519897, training accuracy: 0.67677734375
2023-10-14 14:19:14,252 - __main__ - INFO - Epoch [58/64], Step [301/2503], training loss: 1.347473382949829, training accuracy: 0.674375
2023-10-14 14:21:21,499 - __main__ - INFO - Epoch [58/64], Step [401/2503], training loss: 1.334886908531189, training accuracy: 0.67619140625
2023-10-14 14:23:24,858 - __main__ - INFO - Epoch [58/64], Step [501/2503], training loss: 1.3599330186843872, training accuracy: 0.67462890625
2023-10-14 14:25:17,865 - __main__ - INFO - Epoch [58/64], Step [601/2503], training loss: 1.4280011653900146, training accuracy: 0.67541015625
2023-10-14 14:27:30,188 - __main__ - INFO - Epoch [58/64], Step [701/2503], training loss: 1.3075138330459595, training accuracy: 0.67033203125
2023-10-14 14:29:41,947 - __main__ - INFO - Epoch [58/64], Step [801/2503], training loss: 1.306057095527649, training accuracy: 0.675234375
2023-10-14 14:31:46,871 - __main__ - INFO - Epoch [58/64], Step [901/2503], training loss: 1.2771086692810059, training accuracy: 0.67337890625
2023-10-14 14:33:52,271 - __main__ - INFO - Epoch [58/64], Step [1001/2503], training loss: 1.4277092218399048, training accuracy: 0.67291015625
2023-10-14 14:35:58,360 - __main__ - INFO - Epoch [58/64], Step [1101/2503], training loss: 1.364240050315857, training accuracy: 0.67826171875
2023-10-14 14:38:07,969 - __main__ - INFO - Epoch [58/64], Step [1201/2503], training loss: 1.3588544130325317, training accuracy: 0.675703125
2023-10-14 14:40:12,183 - __main__ - INFO - Epoch [58/64], Step [1301/2503], training loss: 1.3681495189666748, training accuracy: 0.67353515625
2023-10-14 14:42:12,798 - __main__ - INFO - Epoch [58/64], Step [1401/2503], training loss: 1.295582890510559, training accuracy: 0.67748046875
2023-10-14 14:44:04,419 - __main__ - INFO - Epoch [58/64], Step [1501/2503], training loss: 1.3652479648590088, training accuracy: 0.67806640625
2023-10-14 14:46:25,741 - __main__ - INFO - Epoch [58/64], Step [1601/2503], training loss: 1.359861969947815, training accuracy: 0.67744140625
2023-10-14 14:48:22,142 - __main__ - INFO - Epoch [58/64], Step [1701/2503], training loss: 1.414052963256836, training accuracy: 0.6723828125
2023-10-14 14:50:29,796 - __main__ - INFO - Epoch [58/64], Step [1801/2503], training loss: 1.5311626195907593, training accuracy: 0.6709375
2023-10-14 14:52:31,939 - __main__ - INFO - Epoch [58/64], Step [1901/2503], training loss: 1.3149312734603882, training accuracy: 0.6763671875
2023-10-14 14:54:50,045 - __main__ - INFO - Epoch [58/64], Step [2001/2503], training loss: 1.3608187437057495, training accuracy: 0.681015625
2023-10-14 14:57:07,362 - __main__ - INFO - Epoch [58/64], Step [2101/2503], training loss: 1.3486382961273193, training accuracy: 0.67466796875
2023-10-14 14:59:34,359 - __main__ - INFO - Epoch [58/64], Step [2201/2503], training loss: 1.517696738243103, training accuracy: 0.672734375
2023-10-14 15:02:04,598 - __main__ - INFO - Epoch [58/64], Step [2301/2503], training loss: 1.3348650932312012, training accuracy: 0.67201171875
2023-10-14 15:04:49,675 - __main__ - INFO - Epoch [58/64], Step [2401/2503], training loss: 1.3256402015686035, training accuracy: 0.6721875
2023-10-14 15:06:56,989 - __main__ - INFO - Epoch [58/64], Step [2501/2503], training loss: 1.2983566522598267, training accuracy: 0.670546875
2023-10-14 15:11:00,934 - __main__ - INFO - Epoch [59/64], accuracy: 0.6811
2023-10-14 15:11:23,896 - __main__ - INFO - Epoch [59/64], Step [1/2503], training loss: 1.264631986618042, training accuracy: 0.6829477292202228
2023-10-14 15:13:35,607 - __main__ - INFO - Epoch [59/64], Step [101/2503], training loss: 1.2844231128692627, training accuracy: 0.6733203125
2023-10-14 15:16:02,351 - __main__ - INFO - Epoch [59/64], Step [201/2503], training loss: 1.3782944679260254, training accuracy: 0.67375
2023-10-14 15:18:29,059 - __main__ - INFO - Epoch [59/64], Step [301/2503], training loss: 1.3745912313461304, training accuracy: 0.67609375
2023-10-14 15:21:01,367 - __main__ - INFO - Epoch [59/64], Step [401/2503], training loss: 1.3289380073547363, training accuracy: 0.676953125
2023-10-14 15:23:27,380 - __main__ - INFO - Epoch [59/64], Step [501/2503], training loss: 1.419653296470642, training accuracy: 0.673359375
2023-10-14 15:26:04,473 - __main__ - INFO - Epoch [59/64], Step [601/2503], training loss: 1.2795929908752441, training accuracy: 0.6765625
2023-10-14 15:28:29,187 - __main__ - INFO - Epoch [59/64], Step [701/2503], training loss: 1.4363315105438232, training accuracy: 0.673515625
2023-10-14 15:31:06,461 - __main__ - INFO - Epoch [59/64], Step [801/2503], training loss: 1.2961957454681396, training accuracy: 0.6723046875
2023-10-14 15:33:33,169 - __main__ - INFO - Epoch [59/64], Step [901/2503], training loss: 1.4005913734436035, training accuracy: 0.669921875
2023-10-14 15:35:51,627 - __main__ - INFO - Epoch [59/64], Step [1001/2503], training loss: 1.189316749572754, training accuracy: 0.67197265625
2023-10-14 15:38:18,181 - __main__ - INFO - Epoch [59/64], Step [1101/2503], training loss: 1.5074838399887085, training accuracy: 0.6753515625
2023-10-14 15:40:54,981 - __main__ - INFO - Epoch [59/64], Step [1201/2503], training loss: 1.3794300556182861, training accuracy: 0.675234375
2023-10-14 15:43:23,939 - __main__ - INFO - Epoch [59/64], Step [1301/2503], training loss: 1.4322346448898315, training accuracy: 0.67525390625
2023-10-14 15:45:57,205 - __main__ - INFO - Epoch [59/64], Step [1401/2503], training loss: 1.3168041706085205, training accuracy: 0.678828125
2023-10-14 15:48:24,158 - __main__ - INFO - Epoch [59/64], Step [1501/2503], training loss: 1.3894938230514526, training accuracy: 0.67572265625
2023-10-14 15:51:05,990 - __main__ - INFO - Epoch [59/64], Step [1601/2503], training loss: 1.5000696182250977, training accuracy: 0.678984375
2023-10-14 15:53:39,745 - __main__ - INFO - Epoch [59/64], Step [1701/2503], training loss: 1.3058663606643677, training accuracy: 0.6710546875
2023-10-14 15:56:13,258 - __main__ - INFO - Epoch [59/64], Step [1801/2503], training loss: 1.3195948600769043, training accuracy: 0.6747265625
2023-10-14 15:58:40,743 - __main__ - INFO - Epoch [59/64], Step [1901/2503], training loss: 1.5261541604995728, training accuracy: 0.67603515625
2023-10-14 16:01:17,298 - __main__ - INFO - Epoch [59/64], Step [2001/2503], training loss: 1.325984239578247, training accuracy: 0.67373046875
2023-10-14 16:03:43,818 - __main__ - INFO - Epoch [59/64], Step [2101/2503], training loss: 1.2682744264602661, training accuracy: 0.675234375
2023-10-14 16:06:13,802 - __main__ - INFO - Epoch [59/64], Step [2201/2503], training loss: 1.397782564163208, training accuracy: 0.67451171875
2023-10-14 16:08:42,856 - __main__ - INFO - Epoch [59/64], Step [2301/2503], training loss: 1.4220476150512695, training accuracy: 0.67697265625
2023-10-14 16:11:24,836 - __main__ - INFO - Epoch [59/64], Step [2401/2503], training loss: 1.3081445693969727, training accuracy: 0.67662109375
2023-10-14 16:13:41,731 - __main__ - INFO - Epoch [59/64], Step [2501/2503], training loss: 1.4164178371429443, training accuracy: 0.67787109375
2023-10-14 16:17:32,670 - __main__ - INFO - Epoch [60/64], accuracy: 0.68074
2023-10-14 16:17:55,282 - __main__ - INFO - Epoch [60/64], Step [1/2503], training loss: 1.3275682926177979, training accuracy: 0.6863753213367609
2023-10-14 16:20:03,653 - __main__ - INFO - Epoch [60/64], Step [101/2503], training loss: 1.5550216436386108, training accuracy: 0.67046875
2023-10-14 16:22:30,390 - __main__ - INFO - Epoch [60/64], Step [201/2503], training loss: 1.372689127922058, training accuracy: 0.67357421875
2023-10-14 16:24:56,169 - __main__ - INFO - Epoch [60/64], Step [301/2503], training loss: 1.2436076402664185, training accuracy: 0.6748828125
2023-10-14 16:27:29,183 - __main__ - INFO - Epoch [60/64], Step [401/2503], training loss: 1.4057515859603882, training accuracy: 0.6737109375
2023-10-14 16:30:08,659 - __main__ - INFO - Epoch [60/64], Step [501/2503], training loss: 1.2424721717834473, training accuracy: 0.67822265625
2023-10-14 16:32:39,537 - __main__ - INFO - Epoch [60/64], Step [601/2503], training loss: 1.2912579774856567, training accuracy: 0.67845703125
2023-10-14 16:35:05,758 - __main__ - INFO - Epoch [60/64], Step [701/2503], training loss: 1.4614757299423218, training accuracy: 0.67669921875
2023-10-14 16:37:41,555 - __main__ - INFO - Epoch [60/64], Step [801/2503], training loss: 1.5217664241790771, training accuracy: 0.67734375
2023-10-14 16:40:01,638 - __main__ - INFO - Epoch [60/64], Step [901/2503], training loss: 1.4494138956069946, training accuracy: 0.6759375
2023-10-14 16:42:30,731 - __main__ - INFO - Epoch [60/64], Step [1001/2503], training loss: 1.3993784189224243, training accuracy: 0.675078125
2023-10-14 16:44:57,349 - __main__ - INFO - Epoch [60/64], Step [1101/2503], training loss: 1.2523653507232666, training accuracy: 0.67705078125
2023-10-14 16:47:25,717 - __main__ - INFO - Epoch [60/64], Step [1201/2503], training loss: 1.3311256170272827, training accuracy: 0.67341796875
2023-10-14 16:49:55,460 - __main__ - INFO - Epoch [60/64], Step [1301/2503], training loss: 1.339410424232483, training accuracy: 0.677421875
2023-10-14 16:52:20,304 - __main__ - INFO - Epoch [60/64], Step [1401/2503], training loss: 1.4457927942276, training accuracy: 0.67470703125
2023-10-14 16:55:01,323 - __main__ - INFO - Epoch [60/64], Step [1501/2503], training loss: 1.3042521476745605, training accuracy: 0.673828125
2023-10-14 16:57:29,496 - __main__ - INFO - Epoch [60/64], Step [1601/2503], training loss: 1.3420854806900024, training accuracy: 0.67580078125
2023-10-14 17:00:08,276 - __main__ - INFO - Epoch [60/64], Step [1701/2503], training loss: 1.4485615491867065, training accuracy: 0.671328125
2023-10-14 17:02:43,023 - __main__ - INFO - Epoch [60/64], Step [1801/2503], training loss: 1.2940434217453003, training accuracy: 0.6735546875
2023-10-14 17:05:11,317 - __main__ - INFO - Epoch [60/64], Step [1901/2503], training loss: 1.3863193988800049, training accuracy: 0.67267578125
2023-10-14 17:07:33,794 - __main__ - INFO - Epoch [60/64], Step [2001/2503], training loss: 1.2716503143310547, training accuracy: 0.67515625
2023-10-14 17:10:16,679 - __main__ - INFO - Epoch [60/64], Step [2101/2503], training loss: 1.4366472959518433, training accuracy: 0.67658203125
2023-10-14 17:12:42,740 - __main__ - INFO - Epoch [60/64], Step [2201/2503], training loss: 1.43157160282135, training accuracy: 0.6746484375
2023-10-14 17:15:12,571 - __main__ - INFO - Epoch [60/64], Step [2301/2503], training loss: 1.368794560432434, training accuracy: 0.67435546875
2023-10-14 17:17:44,505 - __main__ - INFO - Epoch [60/64], Step [2401/2503], training loss: 1.339971899986267, training accuracy: 0.6733203125
2023-10-14 17:20:12,514 - __main__ - INFO - Epoch [60/64], Step [2501/2503], training loss: 1.3300085067749023, training accuracy: 0.677734375
2023-10-14 17:24:04,518 - __main__ - INFO - Epoch [61/64], accuracy: 0.681
2023-10-14 17:24:27,678 - __main__ - INFO - Epoch [61/64], Step [1/2503], training loss: 1.4531277418136597, training accuracy: 0.6538131962296486
2023-10-14 17:26:34,090 - __main__ - INFO - Epoch [61/64], Step [101/2503], training loss: 1.490370273590088, training accuracy: 0.67298828125
2023-10-14 17:28:58,038 - __main__ - INFO - Epoch [61/64], Step [201/2503], training loss: 1.3709181547164917, training accuracy: 0.67416015625
2023-10-14 17:31:28,506 - __main__ - INFO - Epoch [61/64], Step [301/2503], training loss: 1.3100289106369019, training accuracy: 0.6734765625
2023-10-14 17:33:55,609 - __main__ - INFO - Epoch [61/64], Step [401/2503], training loss: 1.376693606376648, training accuracy: 0.67556640625
2023-10-14 17:36:25,000 - __main__ - INFO - Epoch [61/64], Step [501/2503], training loss: 1.4829109907150269, training accuracy: 0.67541015625
2023-10-14 17:38:58,598 - __main__ - INFO - Epoch [61/64], Step [601/2503], training loss: 1.3658313751220703, training accuracy: 0.6753515625
2023-10-14 17:41:19,834 - __main__ - INFO - Epoch [61/64], Step [701/2503], training loss: 1.3599828481674194, training accuracy: 0.6716796875
2023-10-14 17:43:51,699 - __main__ - INFO - Epoch [61/64], Step [801/2503], training loss: 1.2673958539962769, training accuracy: 0.6771875
2023-10-14 17:46:14,454 - __main__ - INFO - Epoch [61/64], Step [901/2503], training loss: 1.4943326711654663, training accuracy: 0.675
2023-10-14 17:48:41,652 - __main__ - INFO - Epoch [61/64], Step [1001/2503], training loss: 1.242120385169983, training accuracy: 0.67361328125
2023-10-14 17:51:04,868 - __main__ - INFO - Epoch [61/64], Step [1101/2503], training loss: 1.4067494869232178, training accuracy: 0.6763671875
2023-10-14 17:53:40,454 - __main__ - INFO - Epoch [61/64], Step [1201/2503], training loss: 1.488537073135376, training accuracy: 0.67005859375
2023-10-14 17:56:11,594 - __main__ - INFO - Epoch [61/64], Step [1301/2503], training loss: 1.2721573114395142, training accuracy: 0.67150390625
2023-10-14 17:58:43,731 - __main__ - INFO - Epoch [61/64], Step [1401/2503], training loss: 1.3324683904647827, training accuracy: 0.67431640625
2023-10-14 18:01:20,486 - __main__ - INFO - Epoch [61/64], Step [1501/2503], training loss: 1.3669357299804688, training accuracy: 0.67482421875
2023-10-14 18:03:59,132 - __main__ - INFO - Epoch [61/64], Step [1601/2503], training loss: 1.354245901107788, training accuracy: 0.678203125
2023-10-14 18:06:26,028 - __main__ - INFO - Epoch [61/64], Step [1701/2503], training loss: 1.1877641677856445, training accuracy: 0.67357421875
2023-10-14 18:08:47,331 - __main__ - INFO - Epoch [61/64], Step [1801/2503], training loss: 1.2676644325256348, training accuracy: 0.67419921875
2023-10-14 18:11:12,017 - __main__ - INFO - Epoch [61/64], Step [1901/2503], training loss: 1.308280110359192, training accuracy: 0.67537109375
2023-10-14 18:13:49,959 - __main__ - INFO - Epoch [61/64], Step [2001/2503], training loss: 1.273665428161621, training accuracy: 0.6766796875
2023-10-14 18:16:16,718 - __main__ - INFO - Epoch [61/64], Step [2101/2503], training loss: 1.5011622905731201, training accuracy: 0.6754296875
2023-10-14 18:18:44,353 - __main__ - INFO - Epoch [61/64], Step [2201/2503], training loss: 1.509246587753296, training accuracy: 0.67580078125
2023-10-14 18:21:12,455 - __main__ - INFO - Epoch [61/64], Step [2301/2503], training loss: 1.4164050817489624, training accuracy: 0.6741796875
2023-10-14 18:23:46,956 - __main__ - INFO - Epoch [61/64], Step [2401/2503], training loss: 1.4449106454849243, training accuracy: 0.67576171875
2023-10-14 18:25:58,923 - __main__ - INFO - Epoch [61/64], Step [2501/2503], training loss: 1.3212660551071167, training accuracy: 0.680546875
2023-10-14 18:30:01,475 - __main__ - INFO - Epoch [62/64], accuracy: 0.68056
2023-10-14 18:30:22,792 - __main__ - INFO - Epoch [62/64], Step [1/2503], training loss: 1.3934403657913208, training accuracy: 0.6829477292202228
2023-10-14 18:32:32,794 - __main__ - INFO - Epoch [62/64], Step [101/2503], training loss: 1.480036735534668, training accuracy: 0.67525390625
2023-10-14 18:34:53,832 - __main__ - INFO - Epoch [62/64], Step [201/2503], training loss: 1.3429518938064575, training accuracy: 0.672734375
2023-10-14 18:37:18,297 - __main__ - INFO - Epoch [62/64], Step [301/2503], training loss: 1.5288517475128174, training accuracy: 0.67466796875
2023-10-14 18:39:45,626 - __main__ - INFO - Epoch [62/64], Step [401/2503], training loss: 1.2552827596664429, training accuracy: 0.67431640625
2023-10-14 18:42:15,221 - __main__ - INFO - Epoch [62/64], Step [501/2503], training loss: 1.3074836730957031, training accuracy: 0.676640625
2023-10-14 18:44:40,377 - __main__ - INFO - Epoch [62/64], Step [601/2503], training loss: 1.4877318143844604, training accuracy: 0.67458984375
2023-10-14 18:47:11,441 - __main__ - INFO - Epoch [62/64], Step [701/2503], training loss: 1.4145092964172363, training accuracy: 0.67068359375
2023-10-14 18:49:38,150 - __main__ - INFO - Epoch [62/64], Step [801/2503], training loss: 1.4205060005187988, training accuracy: 0.67640625
2023-10-14 18:52:01,387 - __main__ - INFO - Epoch [62/64], Step [901/2503], training loss: 1.4347797632217407, training accuracy: 0.6736328125
2023-10-14 18:54:23,077 - __main__ - INFO - Epoch [62/64], Step [1001/2503], training loss: 1.5011622905731201, training accuracy: 0.67537109375
2023-10-14 18:56:47,284 - __main__ - INFO - Epoch [62/64], Step [1101/2503], training loss: 1.1870020627975464, training accuracy: 0.67453125
2023-10-14 18:59:15,187 - __main__ - INFO - Epoch [62/64], Step [1201/2503], training loss: 1.469400405883789, training accuracy: 0.67193359375
2023-10-14 19:01:46,229 - __main__ - INFO - Epoch [62/64], Step [1301/2503], training loss: 1.4868413209915161, training accuracy: 0.67494140625
2023-10-14 19:04:12,631 - __main__ - INFO - Epoch [62/64], Step [1401/2503], training loss: 1.4113761186599731, training accuracy: 0.6740625
2023-10-14 19:06:38,986 - __main__ - INFO - Epoch [62/64], Step [1501/2503], training loss: 1.4055458307266235, training accuracy: 0.67759765625
2023-10-14 19:09:13,465 - __main__ - INFO - Epoch [62/64], Step [1601/2503], training loss: 1.348403811454773, training accuracy: 0.6737109375
2023-10-14 19:11:44,417 - __main__ - INFO - Epoch [62/64], Step [1701/2503], training loss: 1.245440125465393, training accuracy: 0.67451171875
2023-10-14 19:14:26,730 - __main__ - INFO - Epoch [62/64], Step [1801/2503], training loss: 1.4657320976257324, training accuracy: 0.6762890625
2023-10-14 19:16:56,635 - __main__ - INFO - Epoch [62/64], Step [1901/2503], training loss: 1.4851347208023071, training accuracy: 0.67640625
2023-10-14 19:19:21,856 - __main__ - INFO - Epoch [62/64], Step [2001/2503], training loss: 1.1996794939041138, training accuracy: 0.67369140625
2023-10-14 19:21:55,917 - __main__ - INFO - Epoch [62/64], Step [2101/2503], training loss: 1.4270637035369873, training accuracy: 0.68005859375
2023-10-14 19:24:36,125 - __main__ - INFO - Epoch [62/64], Step [2201/2503], training loss: 1.3701177835464478, training accuracy: 0.673125
2023-10-14 19:27:02,942 - __main__ - INFO - Epoch [62/64], Step [2301/2503], training loss: 1.3344576358795166, training accuracy: 0.67166015625
2023-10-14 19:29:31,634 - __main__ - INFO - Epoch [62/64], Step [2401/2503], training loss: 1.3561822175979614, training accuracy: 0.67607421875
2023-10-14 19:31:53,466 - __main__ - INFO - Epoch [62/64], Step [2501/2503], training loss: 1.5257683992385864, training accuracy: 0.67478515625
2023-10-14 19:35:44,637 - __main__ - INFO - Epoch [63/64], accuracy: 0.681
2023-10-14 19:36:08,291 - __main__ - INFO - Epoch [63/64], Step [1/2503], training loss: 1.2859495878219604, training accuracy: 0.700942587832048
2023-10-14 19:37:46,776 - __main__ - INFO - Epoch [63/64], Step [101/2503], training loss: 1.3755966424942017, training accuracy: 0.67283203125
2023-10-14 19:39:29,119 - __main__ - INFO - Epoch [63/64], Step [201/2503], training loss: 1.565248966217041, training accuracy: 0.67404296875
2023-10-14 19:41:22,405 - __main__ - INFO - Epoch [63/64], Step [301/2503], training loss: 1.3800022602081299, training accuracy: 0.6741015625
2023-10-14 19:43:44,660 - __main__ - INFO - Epoch [63/64], Step [401/2503], training loss: 1.3898428678512573, training accuracy: 0.6722265625
2023-10-14 19:45:58,252 - __main__ - INFO - Epoch [63/64], Step [501/2503], training loss: 1.4735857248306274, training accuracy: 0.67509765625
2023-10-14 19:48:04,954 - __main__ - INFO - Epoch [63/64], Step [601/2503], training loss: 1.5061780214309692, training accuracy: 0.67287109375
2023-10-14 19:50:10,742 - __main__ - INFO - Epoch [63/64], Step [701/2503], training loss: 1.2960293292999268, training accuracy: 0.6746875
2023-10-14 19:52:23,240 - __main__ - INFO - Epoch [63/64], Step [801/2503], training loss: 1.404038667678833, training accuracy: 0.676640625
2023-10-14 19:54:53,981 - __main__ - INFO - Epoch [63/64], Step [901/2503], training loss: 1.383357286453247, training accuracy: 0.6762890625
2023-10-14 19:57:25,631 - __main__ - INFO - Epoch [63/64], Step [1001/2503], training loss: 1.2880949974060059, training accuracy: 0.67837890625
2023-10-14 19:59:54,966 - __main__ - INFO - Epoch [63/64], Step [1101/2503], training loss: 1.4052857160568237, training accuracy: 0.67513671875
2023-10-14 20:02:43,237 - __main__ - INFO - Epoch [63/64], Step [1201/2503], training loss: 1.42913818359375, training accuracy: 0.671484375
2023-10-14 20:05:11,881 - __main__ - INFO - Epoch [63/64], Step [1301/2503], training loss: 1.2691086530685425, training accuracy: 0.67435546875
2023-10-14 20:07:43,571 - __main__ - INFO - Epoch [63/64], Step [1401/2503], training loss: 1.2541651725769043, training accuracy: 0.6761328125
2023-10-14 20:10:13,037 - __main__ - INFO - Epoch [63/64], Step [1501/2503], training loss: 1.2308192253112793, training accuracy: 0.6769140625
2023-10-14 20:12:51,500 - __main__ - INFO - Epoch [63/64], Step [1601/2503], training loss: 1.4756516218185425, training accuracy: 0.67349609375
2023-10-14 20:15:15,440 - __main__ - INFO - Epoch [63/64], Step [1701/2503], training loss: 1.2682126760482788, training accuracy: 0.677421875
2023-10-14 20:17:49,713 - __main__ - INFO - Epoch [63/64], Step [1801/2503], training loss: 1.338234305381775, training accuracy: 0.67615234375
2023-10-14 20:20:14,044 - __main__ - INFO - Epoch [63/64], Step [1901/2503], training loss: 1.535986304283142, training accuracy: 0.67435546875
2023-10-14 20:22:49,793 - __main__ - INFO - Epoch [63/64], Step [2001/2503], training loss: 1.3920979499816895, training accuracy: 0.67705078125
2023-10-14 20:25:33,925 - __main__ - INFO - Epoch [63/64], Step [2101/2503], training loss: 1.3309698104858398, training accuracy: 0.67443359375
2023-10-14 20:28:00,986 - __main__ - INFO - Epoch [63/64], Step [2201/2503], training loss: 1.4361544847488403, training accuracy: 0.6737890625
2023-10-14 20:30:23,431 - __main__ - INFO - Epoch [63/64], Step [2301/2503], training loss: 1.46933114528656, training accuracy: 0.67279296875
2023-10-14 20:32:37,791 - __main__ - INFO - Epoch [63/64], Step [2401/2503], training loss: 1.5375723838806152, training accuracy: 0.67189453125
2023-10-14 20:34:51,980 - __main__ - INFO - Epoch [63/64], Step [2501/2503], training loss: 1.3112905025482178, training accuracy: 0.67603515625
2023-10-14 20:38:23,209 - __main__ - INFO - Epoch [64/64], accuracy: 0.68184
2023-10-14 20:38:43,910 - __main__ - INFO - Epoch [64/64], Step [1/2503], training loss: 1.4207112789154053, training accuracy: 0.6700942587832048
2023-10-14 20:40:34,835 - __main__ - INFO - Epoch [64/64], Step [101/2503], training loss: 1.3177549839019775, training accuracy: 0.6762109375
2023-10-14 20:43:06,180 - __main__ - INFO - Epoch [64/64], Step [201/2503], training loss: 1.5130963325500488, training accuracy: 0.6730859375
2023-10-14 20:45:27,504 - __main__ - INFO - Epoch [64/64], Step [301/2503], training loss: 1.244854211807251, training accuracy: 0.67685546875
2023-10-14 20:47:51,383 - __main__ - INFO - Epoch [64/64], Step [401/2503], training loss: 1.3827238082885742, training accuracy: 0.67326171875
2023-10-14 20:50:14,389 - __main__ - INFO - Epoch [64/64], Step [501/2503], training loss: 1.4287314414978027, training accuracy: 0.6745703125
2023-10-14 20:52:28,561 - __main__ - INFO - Epoch [64/64], Step [601/2503], training loss: 1.179986596107483, training accuracy: 0.676015625
2023-10-14 20:54:53,653 - __main__ - INFO - Epoch [64/64], Step [701/2503], training loss: 1.496775507926941, training accuracy: 0.67638671875
2023-10-14 20:57:36,009 - __main__ - INFO - Epoch [64/64], Step [801/2503], training loss: 1.4788973331451416, training accuracy: 0.67345703125
2023-10-14 21:00:18,731 - __main__ - INFO - Epoch [64/64], Step [901/2503], training loss: 1.3177378177642822, training accuracy: 0.6787890625
2023-10-14 21:02:46,030 - __main__ - INFO - Epoch [64/64], Step [1001/2503], training loss: 1.4846241474151611, training accuracy: 0.6743359375
2023-10-14 21:05:03,596 - __main__ - INFO - Epoch [64/64], Step [1101/2503], training loss: 1.4054051637649536, training accuracy: 0.67609375
2023-10-14 21:07:47,150 - __main__ - INFO - Epoch [64/64], Step [1201/2503], training loss: 1.420305848121643, training accuracy: 0.6740234375
2023-10-14 21:10:10,947 - __main__ - INFO - Epoch [64/64], Step [1301/2503], training loss: 1.3426563739776611, training accuracy: 0.6716796875
2023-10-14 21:12:38,477 - __main__ - INFO - Epoch [64/64], Step [1401/2503], training loss: 1.484145164489746, training accuracy: 0.675625
2023-10-14 21:15:07,152 - __main__ - INFO - Epoch [64/64], Step [1501/2503], training loss: 1.3987993001937866, training accuracy: 0.6771484375
2023-10-14 21:17:39,375 - __main__ - INFO - Epoch [64/64], Step [1601/2503], training loss: 1.3272396326065063, training accuracy: 0.67482421875
2023-10-14 21:20:05,571 - __main__ - INFO - Epoch [64/64], Step [1701/2503], training loss: 1.383082389831543, training accuracy: 0.675078125
2023-10-14 21:22:46,102 - __main__ - INFO - Epoch [64/64], Step [1801/2503], training loss: 1.5287566184997559, training accuracy: 0.67583984375
2023-10-14 21:25:12,397 - __main__ - INFO - Epoch [64/64], Step [1901/2503], training loss: 1.2302069664001465, training accuracy: 0.67439453125
2023-10-14 21:27:46,076 - __main__ - INFO - Epoch [64/64], Step [2001/2503], training loss: 1.4178950786590576, training accuracy: 0.6741015625
2023-10-14 21:30:10,455 - __main__ - INFO - Epoch [64/64], Step [2101/2503], training loss: 1.4240529537200928, training accuracy: 0.67408203125
2023-10-14 21:32:45,350 - __main__ - INFO - Epoch [64/64], Step [2201/2503], training loss: 1.5053004026412964, training accuracy: 0.670390625
2023-10-14 21:35:04,573 - __main__ - INFO - Epoch [64/64], Step [2301/2503], training loss: 1.488050937652588, training accuracy: 0.67619140625
2023-10-14 21:37:35,028 - __main__ - INFO - Epoch [64/64], Step [2401/2503], training loss: 1.230034589767456, training accuracy: 0.67716796875
2023-10-14 21:39:34,564 - __main__ - INFO - Epoch [64/64], Step [2501/2503], training loss: 1.4411615133285522, training accuracy: 0.67583984375
